<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Rust Algorithm Club</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Learn algorithms and data structures with Rust">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
            tex2jax: {
              inlineMath: [['$','$']],
            },
          });
        </script>
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG"></script>
        
    </head>
    <body class="light">
        <!-- Provide site root to javascript -->
        <script type="text/javascript">var path_to_root = "";</script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = 'light'; }
            document.body.className = theme;
            document.querySelector('html').className = theme + ' js';
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <ol class="chapter"><li class="affix"><a href="index.html">Rust Algorithm Club</a></li><li class="spacer"></li><li><a href="concepts/index.html">基礎概念</a></li><li><ol class="section"><li><a href="concepts/asymptotic-notation/index.html">漸進符號 Asymptotic Notation</a></li></ol></li><li><a href="searching/index.html">搜尋</a></li><li><ol class="section"><li><a href="searching/linear_search/index.html">線性搜尋 Linear search</a></li><li><a href="searching/binary_search/index.html">二元搜尋 Binary search</a></li><li><a href="searching/interpolation_search/index.html">🚧 內插搜尋 Interpolation search</a></li><li><a href="searching/exponential_search/index.html">指數搜尋 Exponential search</a></li></ol></li><li><a href="sorting/index.html">排序</a></li><li><ol class="section"><li><a href="sorting/simple-sorts.html">簡單排序</a></li><li><ol class="section"><li><a href="sorting/insertion_sort/index.html">插入排序 Insertion sort</a></li><li><a href="sorting/selection_sort/index.html">選擇排序 Selection sort</a></li><li><a href="sorting/bubble_sort/index.html">氣泡排序 Bubble sort</a></li><li><a href="sorting/shellsort/index.html">希爾排序 Shellsort</a></li></ol></li><li><a href="sorting/efficient-sorts.html">高效排序</a></li><li><ol class="section"><li><a href="sorting/heapsort/index.html">堆積排序 Heapsort</a></li><li><a href="sorting/quicksort/index.html">快速排序 Quicksort</a></li><li><a href="sorting/mergesort/index.html">合併排序 Mergesort</a></li></ol></li><li><a href="sorting/hybrid-sorts.html">混合排序</a></li><li><ol class="section"><li><a href="sorting/introsort/index.html">🚧 內省排序 Introsort</a></li><li><a href="sorting/timsort/index.html">🚧 自適應合併排序 Timsort</a></li><li><a href="sorting/pdqsort/index.html">🚧 模式消除快速排序 Pdqsort</a></li></ol></li><li><a href="sorting/special-purpose-sorts.html">特殊排序</a></li><li><ol class="section"><li><a href="sorting/counting_sort/index.html">計數排序 Counting sort</a></li><li><a href="sorting/bucket_sort/index.html">桶排序 Bucket sort</a></li><li><a href="sorting/radix_sort/index.html">基數排序 Radix sort</a></li></ol></li></ol></li><li><a href="collections/index.html">資料結構</a></li><li><ol class="section"><li><a href="collections/stack-queue.html">堆疊與佇列</a></li><li><ol class="section"><li><a href="collections/stack/index.html">🚧 堆疊 Stack</a></li><li><a href="collections/queue/index.html">🚧 佇列 Queue</a></li><li><a href="collections/deque/index.html">🚧 雙端佇列 Deque</a></li></ol></li><li><a href="collections/linked_list/index.html">鏈結串列</a></li><li><ol class="section"><li><a href="collections/singly_linked_list/index.html">單向鏈結串列 Singly linked list</a></li><li><a href="collections/doubly_linked_list/index.html">🚧 雙向鏈結串列 Doubly linked list</a></li><li><a href="collections/circular_linked_list/index.html">🚧 循環鏈結串列 Circular linked list</a></li></ol></li><li><a href="collections/associative-container/index.html">關聯容器</a></li><li><ol class="section"><li><a href="collections/hash_map/index.html">雜湊表 Hash map</a></li><li><a href="collections/ordered_map/index.html">🚧 有序映射表 Ordered map</a></li><li><a href="collections/multimap/index.html">🚧 多重映射表 Multimap</a></li><li><a href="collections/set/index.html">🚧 集合 Set</a></li><li class="spacer"></li></ol></li></ol></li><li><a href="CONTRIBUTING.html">貢獻指南</a></li></ol>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light <span class="default">(default)</span></button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">Rust Algorithm Club</h1>

                        <div class="right-buttons">
                            <a href="https://github.com/weihanglo/rust-algorithm-club" title="Edit" aria-label="Edit on GitHub">
                                <i id="print-button" class="fa fa-github"> Edit</i>
                            </a>
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p align="center">
  <img src="logo.svg" alt="logo">
<p>
<a class="header" href="#rust-algorithm-club" id="rust-algorithm-club"><h1>Rust Algorithm Club</h1></a>
<p>歡迎來到 Rust 演算法俱樂部！本專案受 <a href="https://github.com/raywenderlich/swift-algorithm-club">Swift Algorithm Club</a> 啟發，專案中的演算法皆使用 <a href="https://www.rust-lang.org/">Rust 程式語言</a>撰寫說明與實作！您可以在 <a href="https://rust-algo.club">Rust Algorithm Club</a> 一站，依您的意願，挑選有興趣的演算法知識學習；若您夠大膽，推薦您閱讀<a href="https://rust-algo.club/doc/rust_algorithm_club/">自動生成的 API 文件</a>，直接單挑程式原始碼。</p>
<p>本專案原始碼放在 <a href="https://github.com/weihanglo/rust-algorithm-club">GitHub</a> 上，非常期待您的貢獻。</p>
<p><a href="https://rust-lang-nursery.github.io/edition-guide/rust-2018"><img src="https://img.shields.io/badge/Rust_Edition-2018-green.svg" alt="Rust Edition" /></a>
<a href="https://travis-ci.com/weihanglo/rust-algorithm-club"><img src="https://travis-ci.com/weihanglo/rust-algorithm-club.svg?token=jBygxQ3kLkkfxSeAJnP2&amp;branch=master" alt="Build Status" /></a>
<a href="https://rust-algo.club/doc/rust_algorithm_club/"><img src="https://img.shields.io/badge/doc-available-blue.svg" alt="Documentation" /></a></p>
<a class="header" href="#a基礎概念" id="a基礎概念"><h2>基礎概念</h2></a>
<ul>
<li><a href="concepts/asymptotic-notation">漸進符號 Asymptotic Notation</a></li>
</ul>
<a class="header" href="#a演算法" id="a演算法"><h2>演算法</h2></a>
<a class="header" href="#a搜尋" id="a搜尋"><h3>搜尋</h3></a>
<ul>
<li><a href="searching/linear_search">線性搜尋 Linear search</a></li>
<li><a href="searching/binary_search">二元搜尋 Binary search</a></li>
<li><a href="searching/interpolation_search">🚧 內插搜尋 Interpolation search</a></li>
<li><a href="searching/exponential_search">指數搜尋 Exponential search</a></li>
</ul>
<a class="header" href="#a排序" id="a排序"><h3>排序</h3></a>
<p>簡單排序：</p>
<ul>
<li><a href="sorting/insertion_sort">插入排序 Insertion sort</a></li>
<li><a href="sorting/selection_sort">選擇排序 Selection sort</a></li>
<li><a href="sorting/bubble_sort">氣泡排序 Bubble sort</a></li>
<li><a href="sorting/shellsort">希爾排序 Shellsort</a></li>
</ul>
<p>高效排序：</p>
<ul>
<li><a href="sorting/heapsort">堆積排序 Heapsort</a></li>
<li><a href="sorting/quicksort">快速排序 Quicksort</a></li>
<li><a href="sorting/mergesort">合併排序 Mergesort</a></li>
</ul>
<p>混合排序（更高效）：</p>
<ul>
<li>🚧 <a href="sorting/introsort">內省排序 Introsort</a></li>
<li>🚧 <a href="sorting/timsort">自適應的合併排序 Timsort</a></li>
<li>🚧 <a href="sorting/pdqsort">模式消除快速排序 Pdqsort</a></li>
</ul>
<p>特殊排序：</p>
<ul>
<li><a href="sorting/counting_sort">計數排序 Counting sort</a></li>
<li><a href="sorting/bucket_sort">桶排序 Bucket sort</a></li>
<li><a href="sorting/radix_sort">基數排序 Radix sort</a></li>
</ul>
<a class="header" href="#a資料結構" id="a資料結構"><h2>資料結構</h2></a>
<a class="header" href="#a堆疊與佇列" id="a堆疊與佇列"><h3>堆疊與佇列</h3></a>
<ul>
<li><a href="collections/stack">🚧 堆疊 Stack</a></li>
<li><a href="collections/queue">🚧 佇列 Queue</a></li>
<li><a href="collections/deque">🚧 雙端佇列 Deque</a></li>
</ul>
<a class="header" href="#a鏈結串列" id="a鏈結串列"><h3>鏈結串列</h3></a>
<p><a href="collections/linked_list">鏈結串列概述</a></p>
<ul>
<li><a href="collections/singly_linked_list">單向鏈結串列 Singly linked list</a></li>
<li><a href="collections/doubly_linked_list">🚧 雙向鏈結串列 Doubly linked list</a></li>
<li><a href="collections/circular_linked_list">🚧 循環鏈結串列 Circular linked list</a></li>
</ul>
<a class="header" href="#a關聯容器" id="a關聯容器"><h3>關聯容器</h3></a>
<p><a href="collections/associative-container">關聯容器概述</a></p>
<ul>
<li><a href="collections/hash_map">雜湊表 Hash map</a></li>
<li><a href="collections/ordered_map">🚧 有序映射表 Ordered map</a></li>
<li><a href="collections/multimap">🚧 多重映射表 Multimap</a></li>
<li><a href="collections/set">🚧 集合 Set</a></li>
</ul>
<a class="header" href="#a學習資源" id="a學習資源"><h2>學習資源</h2></a>
<p>有許多優秀的網站與學習資源，分享給大家學習演算法。</p>
<ul>
<li><a href="https://visualgo.net/">VisuAlgo</a> - 也許是最好的演算法視覺化專案。</li>
<li><a href="http://bigocheatsheet.com/">Big-O Cheat Sheet</a> - 最全面的 Big O cheat sheet。</li>
<li><a href="http://rosettacode.org">Rosetta Code</a> - 使用各種程式語言，解答上百種不同程式問題。</li>
<li><a href="https://cses.fi/book.html">Competitive Programmer’s Handbook</a> - 讓你更有競爭力。這書本身也很有競爭力。</li>
</ul>
<a class="header" href="#a如何貢獻" id="a如何貢獻"><h2>如何貢獻</h2></a>
<p>歡迎各式各樣的貢獻，修正錯字也行！開始動手之前，請先閱讀<a href="CONTRIBUTING.html">貢獻指南</a>。</p>
<a class="header" href="#a維護者" id="a維護者"><h2>維護者</h2></a>
<ul>
<li><a href="https://github.com/weihanglo">@weihanglo</a></li>
</ul>
<a class="header" href="#a授權條款" id="a授權條款"><h2>授權條款</h2></a>
<p>本專案分為兩部分授權：</p>
<ul>
<li>程式碼與函式庫依據 <a href="https://github.com/weihanglo/rust-algorithm-club/blob/master/LICENSE">The MIT License (MIT)</a> 授權條款發佈。</li>
<li>文章與相關著作依據 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons 4.0 (CC BY-NC-SA 4.0)</a> 授權條款發佈。</li>
</ul>
<p>Copyright © 2017 - 2018 Weihang Lo</p>
<a class="header" href="#a基礎概念-1" id="a基礎概念-1"><h1>基礎概念</h1></a>
<ul>
<li><a href="asymptotic-notation">漸進符號 Asymptotic Notation</a></li>
</ul>
<a class="header" href="#a漸進符號-asymptotic-notation" id="a漸進符號-asymptotic-notation"><h1>漸進符號 Asymptotic Notation</h1></a>
<p>日常生活中，你會如何描述處理事情的效率？</p>
<p>「原來她五分鐘內可以吃掉一頭牛！」</p>
<p>「房間這麼小你還能擺一堆雜物？還不快收拾！」</p>
<p>這些描述方法，著重在處理事情的花費時間，或單位空間內的儲存量。描述演算法的效率也如此，就是「測量演算法的執行成本」，例如這個排序法花了 10 秒鐘跑完兩萬筆資料，或是這個模擬演算法很吃資源需要 32 GB 的記憶體。</p>
<p>然而，在不同的機器規格、環境溫濕度、程式語言、實作方式，以及有沒有放乖乖的變異影響下，相同演算法的執行成本常常不一致。為了消弭這些外部因素，讓分析演算法能夠更科學化。科學家抽絲剝繭，發明一個方法：</p>
<p><strong>「統計演算法內所需操作步驟的數目。」</strong></p>
<p>這是最簡單，最粗淺比較不同演算法效率的作法。</p>
<a class="header" href="#a用數學表示演算法效率" id="a用數學表示演算法效率"><h2>用數學表示演算法效率</h2></a>
<p>「計算步驟數目」很像中小學的數學題目：某公司有三個能力相異的工程師，有的工程師一天解決一個 bug，有的工程師連續工作後效率大幅滑落。每個工程師的除蟲效率可以畫成「bug 數 - 解決 bug 所需時數」函數，橫軸為待處理的臭蟲數，縱軸為解決臭蟲所需時數，如圖一與表所示。</p>
<table><thead><tr><th> 時數       </th><th> $\log N$ </th><th> $N$ </th><th> $N \log N$ </th></tr></thead><tbody>
<tr><td> $N=5$  </td><td> 2.236        </td><td> 5       </td><td> 8.046          </td></tr>
<tr><td> $N=30$ </td><td> 5.477        </td><td> 30      </td><td> 102.036        </td></tr>
</tbody></table>
<p><img src="fig1.png" alt="Fig. 1" /></p>
<p>不論從圖或表，我們都可以明確看出，當 bug 數目小時，每個工程師耗時差不多；當 bug 數目成長到一定程度時，效率好與效率差的工程師差距就很明顯了。</p>
<p>我們把場景拉回演算法的範疇，再闡明一次。上述的除蟲效率函數關係，可以簡單視為為「輸入資料量 - 運算成本」關係之函數。例如 $f(x)=x^2+3x+6$。當輸入資料量增大時，成本也隨之上升，這個用來描述演算法執行成本與輸入資料量之關係的函數，我們稱之為該演算法的「複雜度」。</p>
<a class="header" href="#a何謂漸進符號" id="a何謂漸進符號"><h2>何謂漸進符號</h2></a>
<p>了解每個演算法的時間複雜度之後，就能比較何者效率佳。但往往天不從人願，給了我們兩個演算法進行比較。</p>
<p>$$f(x)=\sqrt{\frac{182777}{286}}\pi x^4+5\log_{3}^{26}88x^3-e^{777^{log_2^9}}$$</p>
<p>$$g(x)=3x^6-2x^2$$</p>
<p>「天啊！這樣要怎麼分析執行效率呀！」</p>
<p>為了有統一的加薪標準，我們不能假定產品只會產生特定數量的臭蟲，也不能以單一天的工作表現判定員工能力，我們知道老舊系統有無限多個 bug，因此，優秀的老闆關心的是工程師長期處理「海量臭蟲」，在極限下的<strong>成長趨勢</strong>，這些成長趨勢才是衡量 KPI 的關鍵。再次強調，優秀老闆關心如何榨出是工程師的「極限成長趨勢」，而非一時半刻賣弄學識。</p>
<p>同樣地，有太多因素干擾影響一個演算法的複雜度，假使我們只觀察當輸入資料量 $n$ 接近無窮大時，演算法的成長趨勢為何，就很接近所謂漸進符號（asymptotic notation）的定義。漸進符號 只關心演算法在極限下的漸進行為，不同的演算法可能使用相同的漸進符號表示。</p>
<p>我們比較兩個簡單函數，$f(x) = 10x + 29$ 以及 $g(x) = x^2 + 1$。從圖二可以看出一開始 $g(x)$ 的執行時間比 $f(x)$ 多了不少，但隨著輸入資料量 $n$ 增多，$g(x)$ 的執行時間成長愈來愈快速，最後遠遠大於 $f(x)$。</p>
<p><img src="fig2.png" alt="Fig. 2" /></p>
<p>若以 $an^2 + bn + c$  表示複雜度，就是當存在一個 $a &gt; 0$ 時，一定會有 $n$ 符合 $an^2 &gt; bn + c$，這個差距隨著 $n$ 越大越明顯，這是因為首項（leading term），也就是帶有最高指數的那一項，隨著 輸入大小改變，執行時間變化幅度較大。因此，可捨去複雜度函數中其他較不重要的次項與常數，留下最大次項，「<strong>透過簡單的函數來表述函數接近極限的行為</strong>」,讓複雜度函數更易理解，這就是「漸進符號」的概念。</p>
<p>這裡介紹常見的幾種漸進符號：</p>
<a class="header" href="#obig-o" id="obig-o"><h3>$O$：Big O</h3></a>
<p>當我們談論演算法複雜度時，通常關心的是演算法「最糟糕的情況下」，「最多」需要執行多久。Big O 就是描述演算法複雜度上界的漸進符號，當一個演算法「實際」的複雜度（或執行成本對輸入資料量函數）為 $f(n)$ 時，欲以 Big O 描述其複雜度上界時，必須滿足以下定義：</p>
<p>$$f(n) = O(g(n)) \colon {\exists k&gt;0\ \exists n_0\ \forall n&gt;n_0\ |f(n)| \leq k \cdot g(n)}$$</p>
<p>假設有一演算法實際複雜度為 $f(n) = 3n + 4$，有一組 $k = 4;\ g(n) = n;\ n_0 = 4$ 滿足</p>
<p>$$\forall n &gt; 4,\ 0 \leq f(n) = 3n + 4 \leq 4n$$</p>
<p>意思是「$f(n)$ 的複雜度上界成長趨勢最終不會超過 $g(n) = 4n$ 」，再代入 $O(g(n))$，可得演算法最差複雜度為 $f(n) = O(n)$，也就是「該演算法的成長趨勢不會比 $g(n)$ 來得快」（見圖三）。</p>
<p><img src="fig3.png" alt="Fig. 3" /></p>
<p>再多看一個例子，若 $f(n) = 4n^2 + n$ 有一組 $k = 5;\ g(n) = n^2;\ n_0 = 5$ 滿足</p>
<p>$$\forall n &gt; 5,\ 0 \leq f(n) = 4n^2 + n \leq 5n^2$$</p>
<p>則此函數的複雜度為 $f(n) = O(n^2)$。</p>
<blockquote>
<p>注意：也寫作 $f(n) \in O(g(n))$，因為實際上 $O(g(n))$ 是所有可描述演算法成長趨勢，並滿足上述條件的函數之「集合」。</p>
</blockquote>
<a class="header" href="#omegabig-omega" id="omegabig-omega"><h3>$\Omega$：Big Omega</h3></a>
<p>相較於 Big O 描述演算法成長趨勢的上界，Big Omega 則是對應成長趨勢的「下界」，定義如下：</p>
<p>$$f(n) = \Omega(g(n)) \colon {\exists k&gt;0\ \exists n_0\ \forall n&gt;n_0\ |f(n)| \geq k \cdot g(n)}$$</p>
<p>以 $f(n) = 3n + 4$ 為例，有一組 $k = 2;\ g(n) = n;\ n_0 = 0$ 滿足上式，因此這個演算法在輸入資料夠大時，「至少」會達到 $\Omega(n)$ 的複雜度，也就是「該演算法的成長趨勢不會比 $g(n)$ 來得慢」。</p>
<a class="header" href="#thetabig-theta" id="thetabig-theta"><h3>$\Theta$：Big Theta</h3></a>
<p>Big Theta 則是 Big O 與 Big Omega 兩個漸進上下界所夾出的範圍，表示該演算法在輸入資料夠大時，最終的複雜度會成長到這個範圍中。其定義如下：</p>
<p>$$f(n) = \Theta(g(n)) \colon {\exists k_1&gt;0\ \exists k_2&gt;0\ \exists n_0\ \forall n&gt;n_0\ k_1 \cdot g(n) \leq |f(n)| \leq k_2 \cdot g(n)}$$</p>
<p>繼續以 $f(n) = 3n + 4$ 為例，同樣有一組 $k_1 = 1;\ k_2 = 5;\ g(n) = n;\ n_0 = 2$，滿足</p>
<p>$$\forall n \geq 2,\ n \leq f(n) = 3n + 4 \leq 5n$$</p>
<p>可得知，$f(n) = 3n + 4 \in \Theta(n)$，表示「該演算法的成長趨勢與 $g(n) = n$ 相同」（見圖四）。</p>
<p><img src="fig4.png" alt="Fig. 4" /></p>
<a class="header" href="#a常見的複雜度" id="a常見的複雜度"><h2>常見的複雜度</h2></a>
<p>看完了讓人昏昏欲睡的數學定義，現在來認識一些常見的複雜度，從最快最有效率，到最慢最拖台錢的通通一起認識。</p>
<ul>
<li>$O(1)$：常數時間，演算法執行時間與資料量毫無瓜葛。例如讀取 array 首個元素。</li>
<li>$O(\log n)$：執行時間隨資料量呈對數比例成長。常見的例子是<a href="../../searching/binary_search">二元搜索（Binary search）</a>。</li>
<li>$O(n)$：執行時間隨資料量呈線性成長，例如在無序的 array 中尋找特定值。</li>
<li>$O(n \log n)$：執行時間隨資料量呈線性對數成長，常見的<a href="../../sorting/mergesort">合併排序（Mergesort）</a>的複雜度即如斯。</li>
<li>$O(n^2)$：執行時間隨資料量呈平方成長，例如一些效率不彰的排序法如<a href="../../sorting/bubble_sort">氣泡排序（Bubble sort）</a>。</li>
<li>$O(n^3)$：執行時間隨資料量呈立方成長，常見例子為 naïve 實作的矩陣乘法。</li>
<li>$O(c^n)$：執行時間隨資料量呈指數成長。</li>
<li>$O(n!)$：執行時間隨資料量呈階乘成長，大部分情況下，這是非常差勁的複雜度。</li>
</ul>
<p>若想一窺各種常見演算法的複雜度，可以參考這個最全面的 <a href="http://bigocheatsheet.com/">Big-O Cheat Sheet</a>，圖表非常精美直觀！</p>
<blockquote>
<p>再次強調，漸進符號也可以代表其他執行成本如記憶體空間，並不一定代表執行時間。</p>
</blockquote>
<!-- -->
<blockquote>
<p>其他的漸進符號還有 little-o、little-omega 等等，有興趣的朋友可以參考文末的資料。</p>
</blockquote>
<a class="header" href="#a你可能不適合漸進符號" id="a你可能不適合漸進符號"><h2>你可能不適合漸進符號</h2></a>
<p>善用漸進符號，可以讓原本複雜艱澀的實際複雜度，簡化至人類容易理解的簡單數學符號，也讓分析演算法效率更為客觀。但實際上，漸進符號省略了常數項與低次項，僅保留最高次項，這種「漸進行為下」的效能表現，在真實世界中，若輸入資料量不夠大，實際複雜度的低次項係數又比高次項大上許多，很可能這個演算法實際上根本沒辦法使用。</p>
<p>另外，漸進符號僅考慮最差與最佳複雜度，沒有考慮到平均複雜度。舉例來說，<a href="../../sorting/quicksort">Quicksort</a> 最差複雜度為 $O(n^2)$，乍看之下不是很理想，但這種情況非常稀少；其平均複雜度落在 $O(n \log n)$，且其係數相對較低，額外開銷少，自然成為最熱門的排序法之一。</p>
<p>還有，漸進符號也沒有考慮到不同語言、平台的基礎操作開銷，例如實作排序法時，有些語言「比較」兩個元素的開銷比「置換」來得大，實作上就需要盡量減少置換元素。同樣的，CPU 快取也非常容易忽略，一些快速的搜尋法很可能因為不是<a href="../../searching/linear_search">線性搜尋</a>，沒辦法充分利用 CPU cache，效能不一定理想。</p>
<p>總之，漸進符號只能告訴你「當輸入資料量夠大時，演算法的複雜度表現如何」，並不總是適用每個情境，端看你怎麼使用他。</p>
<a class="header" href="#a參考資料" id="a參考資料"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Time_complexity">Wiki: Time complexity</a></li>
<li><a href="https://en.wikipedia.org/wiki/Big_O_notation">Wiki: Big O notation</a></li>
<li><a href="https://brilliant.org/wiki/big-o-notation/">Brilliant: Big O Notation</a></li>
<li><a href="http://program-lover.blogspot.com/2008/10/complexity-analysis.html">Infinite Loop: Complexity Analysis</a></li>
</ul>
<a class="header" href="#a搜尋演算法" id="a搜尋演算法"><h1>搜尋演算法</h1></a>
<p>記錄常見的搜尋演算法。</p>
<a class="header" href="#a線性搜尋-linear-search" id="a線性搜尋-linear-search"><h1>線性搜尋 Linear Search</h1></a>
<p>線性搜尋，又稱為循序搜尋（sequential search），是一個在序列中找尋目標的方法。正如字面上的意義，線性搜尋會按照順序迭代序列，挨家挨戶比對每個元素與目標值是否相等，若相等則停止迭代，並回傳搜尋所得結果。</p>
<p>線性搜尋乍看之下，是最簡單實作也最 naïve 的實作，效能應該不怎麼好。事實上，在資料量不多時（少於 100 個元素），線性搜尋的效能也不會太差，因為其他搜尋演算法可能需要建立特殊資料結構，就會導致時空間初始開銷暴增，複雜度的常數項成本變大。</p>
<a class="header" href="#a效能" id="a效能"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n)$     </td></tr>
<tr><td> Best         </td><td> $O(1)$     </td></tr>
<tr><td> Average      </td><td> $O(n)$     </td></tr>
<tr><td> Worst space  </td><td> $O(1)$     </td></tr>
</tbody></table>
<p>若序列中總共有 $n$ 個元素，則線性搜尋最差的狀況為元素不在序列中，就是全部元素都比較一次，共比較 $n - 1$ 次，最差複雜度為  $O(n)$。</p>
<a class="header" href="#a實作" id="a實作"><h2>實作</h2></a>
<p>線性搜尋就是用一個 for-loop 解決。要注意的是，<code>T</code> 泛型參數至少要實作 <code>PartialEq</code> 才能比較。程式碼中使用了迭代器的 <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.enumerate">enumerate</a>，建立一個新迭代器，每次迭代產生迭代次數與對應的值。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn linear_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Option&lt;usize&gt;
    where T: PartialEq
{
    for (index, item) in arr.iter().enumerate() {
        if item == target {
            return Some(index);
        }
    }
    None
}
#}</code></pre></pre>
<p>事實上，若利用 Rust 內建的 <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.position"><code>iterator.position</code></a>，程式碼也許會更簡潔。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn linear_search&lt;T&gt;(arr: &amp;[T], obj: &amp;T) -&gt; Option&lt;usize&gt;
    where T: PartialEq
{
    arr.iter().position(|x| x == obj)
}
#}</code></pre></pre>
<a class="header" href="#a參考資料-1" id="a參考資料-1"><h2>參考資料</h2></a>
<p><a href="https://en.wikipedia.org/wiki/Linear_search">Wiki: Linear search</a></p>
<a class="header" href="#a二元搜尋-binary-search" id="a二元搜尋-binary-search"><h1>二元搜尋 Binary Search</h1></a>
<p>Binary search，又稱對數搜尋（logarithmic search），是一個在已排序的序列中，快速找出特定元素的搜尋演算法。二元搜尋的步驟就像玩猜數字，先猜一個數字，告訴你你的猜測比正確答案大或小，再繼續往對的方向猜，捨棄猜錯的另一半。這樣持續進行好幾次猜測，每猜一次，搜尋範圍就縮小一半，因此稱為「二元」搜尋。</p>
<p>二元搜尋有以下幾個特點：</p>
<ul>
<li>概念簡單，搜尋高效，達到對數執行時間 $O(\log n)$。</li>
<li>不需額外實作資料結構或配置記憶體空間。</li>
<li>只能搜尋<strong>已排序</strong>的序列。</li>
</ul>
<a class="header" href="#a步驟" id="a步驟"><h2>步驟</h2></a>
<ol>
<li>從序列中間的元素開始，比較其與目標值</li>
<li>若該元素為搜尋目標，則結束搜尋。</li>
<li>若該元素較大或小，則將序列切一半，往較小或較大的一半搜尋。</li>
<li>繼續從一半的序列中間的元素開始，重複步驟一到三，直到欲搜尋的序列為空。</li>
</ol>
<a class="header" href="#a說明" id="a說明"><h2>說明</h2></a>
<p>這裡有一個排好序的序列，共有 15 個元素，現在要找尋 9 是否在序列中。</p>
<pre><code>                       *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]
</code></pre>
<p>首先，先找到中間的元素 15 / 2 ~= 8，第八個元素為 13，比 9 大，因此捨棄第八個元素之後的所有元素。</p>
<pre><code>          *
[2, 3, 3, 6, 6, 7, 9, _, _, _, _, _, _, _, _]
</code></pre>
<p>接下來繼續對半搜尋，8 / 2 = 4，找尋第四個元素來比對，6 比 9 小，，因此捨棄第四個元素前的所有元素。</p>
<pre><code>             *
[_, _, _, 6, 6, 7, 9, _, _, _, _, _, _, _, _]
</code></pre>
<p>對剩下的元素二元搜尋，4 / 2 = 2，並從第四個元素開始計算中點 4 + 2 = 6，取得第六個元素為 7，比 9 小，捨棄 7 之前的元素。</p>
<pre><code>                   *
[_, _, _, _, _, 7, 9, _, _, _, _, _, _, _, _]
</code></pre>
<p>繼續切一半來搜尋，繼續找中間的元素 2 / 2 = 1，並從第六個元素計算索引位置 6 + 1 = 7，查看第七個元素是 9，終於找到了！</p>
<a class="header" href="#a效能-1" id="a效能-1"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity  </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(\log n)$ </td></tr>
<tr><td> Best         </td><td> $O(1)$      </td></tr>
<tr><td> Average      </td><td> $O(\log n)$ </td></tr>
<tr><td> Worst space  </td><td> $O(1)$      </td></tr>
</tbody></table>
<p>二元搜尋可以透過分治法（Divide and conquer）遞迴求解，而遞迴的終止條件是序列不能在切兩半。由此可知，二元搜尋的複雜度奠基在要切幾次，子序列長度才會等於 1。設 $n$ 為資料數目，$k$ 為要切幾次才會達成終止條件，可得：</p>
<p>$$ \frac{n}{2^k} = 1 $$</p>
<p>接下來同乘 $2^k$ 並取對數。
$$
\frac{n}{2^k} = 1 \\
\Rightarrow 2^k = n \\
$$</p>
<p>再將左式整理一下，得到 $k$。</p>
<p>$$
\log_2 2^k = log_2 n \\
\Rightarrow k \cdot \log_2 2 = log_2 n \\
\Rightarrow k = log_2 n
$$</p>
<p>於是，我們得到二元搜尋時間複雜度為 $O(k) = O(\log_2 n) = O(\log n)$。</p>
<p>寫這種式子也許不好理解，我們可以把搜尋過程和每個分支寫成樹狀圖，方便觀察。假設一個數列有七個元素 <code>[1, 2, 3, 4, 5, 6, 7]</code>，其二元搜尋所有可能路徑的樹狀圖如下：</p>
<pre><code>          +---+
          | 4 |
          +---+
        /       \
     +---+      +---+
     | 2 |      | 6 |
     +---+      +---+
    /    \      /   \
+---+  +---+  +---+  +---+
| 1 |  | 3 |  | 5 |  | 7 |
+---+  +---+  +---+  +---+
</code></pre>
<p>樹中每一條路徑都代表任意搜尋會經過的步驟，總共有 7 種不同的搜尋路徑，最短路徑僅需要 $\lfloor{\log_2 n} = 3 \rfloor$ 個操作，也就是需要執行「樹高」次的操作。</p>
<a class="header" href="#a實作-1" id="a實作-1"><h2>實作</h2></a>
<a class="header" href="#a函式宣告" id="a函式宣告"><h3>函式宣告</h3></a>
<p>二元搜尋概念看似簡單，實際上誤區一堆，不易寫出完全正確的演算法。我們參考 <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.binary_search">Rust slice binary_search</a> 的實作。先來看看 function signature（函式的宣告）。</p>
<pre><code>pub fn binary_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Result&lt;usize, usize&gt;
    where T: PartialOrd
</code></pre>
<p>二元搜尋函式宣告中，回傳值大概是最特別的部分。如果有找到目標元素，<code>Result</code> 會是 <code>Ok(目標索引位置)</code>，如果沒有找到則回傳 <code>Err(目標值若插入後，不會影響序列排序的位置)</code>。<code>Err</code> 回傳值提供了插入點，非常方便。</p>
<p>再來，<code>T</code> 泛型參數需是 <a href="https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html"><code>PartialOrd</code></a>，這是由於二元搜尋使用排序過後的元素，比起線性搜尋，仍需元素之間相互比較。</p>
<a class="header" href="#a函式主體" id="a函式主體"><h3>函式主體</h3></a>
<p>市面上常見的實作通常以兩個變數 <code>l</code> 與 <code>r</code> 記錄搜尋範圍的上下界，而我們另闢蹊徑，記錄了</p>
<ul>
<li><code>base</code>：搜尋範圍的下界，</li>
<li><code>size</code>：搜尋範圍的長度。</li>
</ul>
<p>以下是完整實作：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn binary_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Result&lt;usize, usize&gt;
    where T: PartialOrd
{
    let mut size = arr.len();       // 1
    if size == 0 {
        return Err(0);
    }
    let mut base = 0_usize;

    while size &gt; 1 {                // 2
        // mid: [base..size)
        let half = size / 2;        // 2.1
        let mid = base + half;
        if arr[mid] &lt;= *target {    // 2.2
            base = mid
        }
        size -= half;               // 2.3
    }

    if arr[base] == *target {       // 3
        Ok(base)
    } else {
        Err(base + (arr[base] &lt; *target) as usize)
    }
}
#}</code></pre></pre>
<ol>
<li>第一部分先取得搜尋範圍 <code>size</code> 以及確定下界為 <code>0_usize</code>。這裡同時檢查若序列長度為零，直接回傳 <code>Err(0)</code>，告知呼叫端可直接在 index 0 新增元素。</li>
<li>第二部分就是精髓了，將終止條件設在 <code>size &lt;= 1</code>，以確保迴圈能夠正常結束。
<ol>
<li>先將搜尋範圍對半切，再與下界 <code>base</code> 相加，算出中點。</li>
<li>另中間元素與目標值比較，如果比較小，則移動下界至中點。</li>
<li>將 <code>size</code> 減半，縮小搜尋範圍。</li>
</ol>
</li>
<li>到了第三部分，<code>base</code> 已經是切到長度為一的序列了，若匹配目標值就直接回傳；若否，需要傳可供目標值插入的位置，將 bool 判斷是轉型成 <code>usize</code>，若 <code>arr[base]</code> 比目標值小，則目標值要加到其後 +1 位置，反之則加在其前 -1 位置。</li>
</ol>
<a class="header" href="#a常見誤區與解法" id="a常見誤區與解法"><h2>常見誤區與解法</h2></a>
<ol>
<li>
<p>只適用已排序序列： 這是使用二元搜尋的前提，千萬不能忽略這重要特性，否則後果絕對大錯特錯。</p>
</li>
<li>
<p>處理重複元素：一般的實作通常是回傳任意符合目標值的索引位置，就算有重複的元素，仍然不可預期。若要回傳特定位置（leftmost 或 rightmost），則需特別處理。</p>
</li>
<li>
<p>整數溢位：部分二元搜尋實作會 以兩個變數儲存搜尋範圍上下界的索引位置，而取中點時千萬不可直接將上下界相加再除二，否則很可能整數溢位（integer overflow）。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mid = (end + start) / 2           // Wrong: integer overflow
let mid = start + (end - start) / 2   // Correct
#}</code></pre></pre>
</li>
<li>
<p>終止條件錯誤：無論如何實作，請將終止條件設為「搜尋範圍為空」，也就是下界大於上界，而不要只比較上下界是否相等。其實搜尋範圍低於一定長度，即可使用線性搜尋替代，避免處理邊界值的麻煩，實務上也幾乎沒有太多效能損失。</p>
</li>
</ol>
<a class="header" href="#a變形與衍生" id="a變形與衍生"><h2>變形與衍生</h2></a>
<a class="header" href="#interpolation-search" id="interpolation-search"><h3>Interpolation Search</h3></a>
<p><a href="../interpolation_search">Interpolation search</a> 改良自二元搜尋，差別在於，二元搜尋選擇中間的元素作為二分點，而 interpolation search 人如其名，以內插法找尋二分點。在資料平均分佈時，比二元搜尋更高效。欲知後續，待下回<a href="../interpolation_search">內插搜尋 Interpolation search</a> 分曉。</p>
<a class="header" href="#exponential-search" id="exponential-search"><h3>Exponential Search</h3></a>
<p><a href="../exponential_search">Exponential search</a> 是一種特殊的二元搜尋，主要用在搜尋無限、無邊界的已排序序列，由於邊界未知長度就未知，無法以傳統二元搜尋找尋中點。Exponential 顧名思義就是不斷比較在 $2^0$，$2^1$ 直到 $2^n$ 的位置上資料是否比目標值大，若較大，再從該位置執行二元搜尋回頭找。詳情請看<a href="../exponential_search">指數搜尋 Exponential search</a>。</p>
<a class="header" href="#binary-insertion-sort" id="binary-insertion-sort"><h3>Binary Insertion Sort</h3></a>
<p>Insertion sort 有一個步驟是在前面已經排完序的資料中，找到適合的地方插入待排序的元素，這部分可透過二元搜尋加快在已排序資料搜尋的速度。詳情請參考 <a href="../../sorting/insertion_sort/#binary-insertion-sort">Binary insertion sort</a>。</p>
<a class="header" href="#a參考資料-2" id="a參考資料-2"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">Wiki: Binary search algorithm</a></li>
<li><a href="https://www.zhihu.com/question/36132386">知乎：二分查找有几种写法？它们的区别是什么？</a></li>
</ul>
<a class="header" href="#a內插搜尋-interpolation-search" id="a內插搜尋-interpolation-search"><h1>內插搜尋 Interpolation Search</h1></a>
<p>Interpolation search 改良自[二元搜尋][../binary_search]，差別在於二分點的選擇方法，二元搜尋選擇中間的元素作為二分點，而內插搜尋則名副其實，以內插法找尋二分點。</p>
<p>內插搜尋的特色如下：</p>
<ul>
<li>資料需要是可計算內插的數值資料。</li>
<li>對資料分佈敏感，資料均勻分佈時，效能比二元搜尋佳。</li>
<li>資料分佈不均勻時，最差複雜度高達 $O(n)$。</li>
</ul>
<a class="header" href="#a效能-2" id="a效能-2"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity  </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(\log i)$ </td></tr>
<tr><td> Best         </td><td> $O(1)$      </td></tr>
<tr><td> Average      </td><td> $O(\log i)$ </td></tr>
<tr><td> Worst space  </td><td> $O(1)$      </td></tr>
</tbody></table>
<a class="header" href="#a參考資料-3" id="a參考資料-3"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Interpolation_search">Wiki: Interpolation search</a></li>
<li><a href="http://program-lover.blogspot.com/2008/12/interpolation-search.html">Infinite Loop: Interpolation Search</a></li>
</ul>
<a class="header" href="#a指數搜尋-exponential-search" id="a指數搜尋-exponential-search"><h1>指數搜尋 Exponential Search</h1></a>
<p>指數搜尋，又稱為 galloping search，是一種特殊的<a href="../binary_search">二元搜尋</a>，主要用在搜尋無限、無邊界的已排序序列。由於邊界未知長度就未知，無法以傳統二元搜尋來找中點。而 Exponential 顧名思義就是從底數為 2，指數為 0 的索引（$2^0$ ）開始，不斷比較在 $2^1$、$2^2$ 直到 $2^k$ 位置上的值，若比目標值大，則停止指數成長，直接從該位置執行二元搜尋，回頭尋找目標值。</p>
<p>指數搜尋的特點如下：</p>
<ul>
<li>可以搜尋邊界未知的已排序序列。</li>
<li>縮小搜尋範圍，可比 naïve 的二元搜尋效率高些。</li>
<li>若目標值實際位置很靠近序列前端，效率會非常棒。</li>
</ul>
<a class="header" href="#a步驟-1" id="a步驟-1"><h2>步驟</h2></a>
<p>指數搜尋的步驟只有非常簡單的兩步驟：</p>
<ol>
<li>依照目標值大小，劃出搜尋範圍。</li>
<li>在上述範圍內執行二元搜尋。</li>
</ol>
<p>而劃出搜尋範圍這部分也很直觀：</p>
<ol>
<li>選定一個底數 $k$，通常為 2。</li>
<li>比較 $k^i$ 索引下的值是否比目標值大，$i$ 從零開始。</li>
<li>若較小，指數加一 $k^{i + 1}$ 後繼續重複步驟二比較。</li>
<li>若較大，停止比較，得搜尋範圍為 $k^{i - 1}$ 到 $k^i$。</li>
</ol>
<a class="header" href="#a說明-1" id="a說明-1"><h2>說明</h2></a>
<p>這裡有個排好序的序列，我們要尋找其中是否有 22 這個數字。</p>
<pre><code>    *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]
</code></pre>
<p>首先，先尋找 $2^0 = 1$ 位置上的數字是否超過 22。<code>3 &lt; 22</code>，很明顯沒有。</p>
<pre><code>       *     *            *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]
</code></pre>
<p>再來，連續看看</p>
<ul>
<li>$2^1$：<code>3 &lt; 22</code></li>
<li>$2^2$：<code>6 &lt; 22</code></li>
<li>$2^3$：<code>15 &lt; 22</code></li>
</ul>
<p>也都沒有超越 22。</p>
<pre><code>                                                           *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]  _,  _
</code></pre>
<p>最後，一口氣將指數加到 4，看看$2^4$ 上的數字是否大於 22。哎呀，$2^4 = 16$，的位置已經超出序列長度，因此取至序列最後一個數字作為比較對象。<code>25 &gt; 22</code>，找到了！</p>
<p>得到搜尋的範圍是 $$2^{4-1} &lt; x &lt; \text{array.length} &lt; 2^{4}$$</p>
<a class="header" href="#a效能-3" id="a效能-3"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity  </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(\log i)$ </td></tr>
<tr><td> Best         </td><td> $O(1)$      </td></tr>
<tr><td> Average      </td><td> $O(\log i)$ </td></tr>
<tr><td> Worst space  </td><td> $O(1)$      </td></tr>
</tbody></table>
<blockquote>
<p>$i$：目標值在序列中實際的索引位置。</p>
</blockquote>
<p>指數搜尋的複雜度分為兩部分分析：</p>
<a class="header" href="#a劃定搜尋範圍" id="a劃定搜尋範圍"><h3>劃定搜尋範圍</h3></a>
<p>設 $i$ 為目標值在序列中實際的索引位置，則搜尋上界，指數增加的操作需執行 $\lceil \log(i) \rceil$ 次，例如匹配目標值的搜尋結果位於序列第 9 個，則指數需增加 $\lceil \log(9) \rceil = 4$ 次，上界才會超過目標值。我們設這部分的複雜度為 $O(log i)$。</p>
<a class="header" href="#a執行二元搜尋" id="a執行二元搜尋"><h3>執行二元搜尋</h3></a>
<p>第二部分就是二元搜尋，複雜度為 $O(log n)$，$n$ 為搜尋範圍的長度。根據第一部分，可以得知範圍長度為 $2^{\log i} - 2^{\log{i - 1}} = 2^{log{i - 1}}$ 個元素，帶入二元搜尋的複雜度，計算出第二部分的複雜度為 $log (2^{\log{i - 1}}) = \log{(i)} - 1 = O(\log i)$。</p>
<p>最後，將兩部分的複雜度合起來，就是指數搜尋的時間複雜度了。</p>
<p>$$O(\log i) + O(\log i) = 2 O(\log i) = O(\log i)$$</p>
<a class="header" href="#a實作-2" id="a實作-2"><h2>實作</h2></a>
<p>本次實作有邊界的指數搜尋，主要分為三個部分：</p>
<ol>
<li>處理空序列的狀況。</li>
<li>利用指數，決定搜尋範圍。</li>
<li>執行二元搜尋，並將輸出結果映射回原始序列。</li>
</ol>
<p>話不多說，直接看程式碼。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
use crate::searching::binary_search;

pub fn exponential_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Result&lt;usize, usize&gt;
    where T: PartialOrd
{
    // 1. Handle empty scenario.
    let size = arr.len();
    if size == 0 {
        return Err(0);
    }

    // 2. Determine searching boundaries.
    let mut hi = 1_usize; // Upper bound.
    while hi &lt; size &amp;&amp; arr[hi] &lt; *target {
        hi &lt;&lt;= 1;
    }
    let lo = hi &gt;&gt; 1; // Lower bound.

    // 3. Do binary search.
    binary_search(&amp;arr[lo..size.min(hi + 1)], target)
        .map(|index| lo + index)
        .map_err(|index| lo + index)
}
#}</code></pre></pre>
<ol>
<li>和二元搜尋同，遇到空序列就返回 <code>Err(0)</code> 告知呼叫端可新增資料在位置 0。</li>
<li>決定搜尋上下界，只要 上界不超過序列長度，且 <code>arr[hi]</code> 小於目標值，就讓上界指數成長。這裡用位元左移運算子（bitwise left shift）實作乘以 2。<br />
找到上界後，再將上界除以 2（位元右移），就是下界了。</li>
<li>確定範圍後，利用上下界切序列的 sub slice 作為引數，傳遞給二元搜尋。要注意的是，為了避免 sub slice 超出邊界，上界需在 <code>size</code> 與 <code>hi + 1</code> 之間找最小值。<br />
由於回傳結果的位置是以 sub slice 起始，需加上位移量（下界 <code>lo</code>）才會對應原始 slice 的位置。</li>
</ol>
<a class="header" href="#a參考資料-4" id="a參考資料-4"><h2>參考資料</h2></a>
<p><a href="https://en.wikipedia.org/wiki/Exponential_search">Wiki: Exponential search</a></p>
<a class="header" href="#a排序演算法" id="a排序演算法"><h1>排序演算法</h1></a>
<p>記錄常見的排序演算法。</p>
<a class="header" href="#a編排慣例" id="a編排慣例"><h2>編排慣例</h2></a>
<p>為了避免泛型宣告降低程式碼可讀性，部分文章內的示範程式不撰寫泛型，排序結果訂為「由小至大」。若需要了解如何撰寫泛型排序演算法，請逕行閱讀對應的 Rust 程式碼。</p>
<a class="header" href="#a簡單排序" id="a簡單排序"><h1>簡單排序</h1></a>
<ul>
<li><a href="insertion_sort">插入排序 Insertion sort</a></li>
<li><a href="selection_sort">選擇排序 Selection sort</a></li>
<li><a href="bubble_sort">氣泡排序 Bubble sort</a></li>
<li><a href="shellsort">希爾排序 Shellsort</a></li>
</ul>
<a class="header" href="#a插入排序-insertion-sort" id="a插入排序-insertion-sort"><h1>插入排序 Insertion Sort</h1></a>
<p>Insertion sort 是最簡單的排序法之一，比起 quicksort 等高效的排序法，對大資料的處理效能較不理想。其演算法是將欲排序元素直接插入正確位置，因而得名。</p>
<p>Insertion sort 基本特性如下：</p>
<ul>
<li>實作簡單易理解。</li>
<li>資料量少時較高效，且比其他 $O(n^2) $ 的排序法高效（selection sort/bubble sort）。</li>
<li><strong>自適應排序</strong>：可根據當前資料排序情形加速排序，資料越接近排序完成，效率越高。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
<li><strong>即時演算法</strong>：可處理逐步輸入的資料，不需等資料完全備妥。</li>
</ul>
<a class="header" href="#a步驟-2" id="a步驟-2"><h2>步驟</h2></a>
<p>將序列分為未排序與部分排序兩個區域。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/3/32/Insertionsort-before.png" alt="" /></p>
<ol>
<li><strong>取第一個元素</strong>，將該元素視為已排序。</li>
<li><strong>取出下一元素</strong>，該元素將插入序列的部分排序區域。</li>
<li><strong>尋找正確位置</strong>：若部分排序元素比新元素大，則互換位置。並重複步驟 2 - 3，直到部分排序元素小於等於新元素。</li>
<li><strong>插入元素</strong>：將新元素<strong>插入</strong>最後的位置。</li>
<li>重複步驟 2 - 4，直到排序完成。</li>
</ol>
<p>簡而言之，即是每次取一個元素，尋找並插入該元素在部分排序區域的排序位置，再逐步把序列單邊排序完成。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/d9/Insertionsort-after.png" alt="" /></p>
<p>Insertion sort 非常簡單，看動畫就能明瞭。
<img src="https://upload.wikimedia.org/wikipedia/commons/0/0f/Insertion-sort-example-300px.gif" alt="" /></p>
<a class="header" href="#a效能-4" id="a效能-4"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity    </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ </td></tr>
<tr><td> Best         </td><td> $O(n) $   </td></tr>
<tr><td> Average      </td><td> $O(n^2) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<p>最佳時間複雜度發生在資料已完成排序的狀況下，insertion sort 只需執行最外層的迴圈 $n $ 次。</p>
<p>最差時間複雜度發生在資料完全相反時，insertion sort 每取得一個新元素是，都需將資料插入序列最前面，，因此所需的操作如下（ $c $ 為任意常數）：</p>
<p>$$ c \cdot 1 + c \cdot 2 + c \cdot 3 \cdots + c \cdot (n - 1) = \frac{c(n - 1 + 1)(n - 1)}{2}$$</p>
<p>最後等於</p>
<p>$$\frac{cn^2}{2} - \frac{cn}{2}$$</p>
<p>捨去低次項，得到時間複雜度為 $O(n^2) $。</p>
<a class="header" href="#a實作-3" id="a實作-3"><h2>實作</h2></a>
<p>簡單實作的程式碼如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn insertion_sort(arr: &amp;mut [i32]) {
    for i in 1..arr.len() {                   // 1
        let mut j = i;
        while j &gt; 0 &amp;&amp; arr[j - 1] &gt; arr[j] {  // 2
            arr.swap(j - 1, j);
            j -= 1;
        }
    }
}
#}</code></pre></pre>
<ol>
<li>外層迴圈迭代整個序列。並取出 index <code>i</code>，<code>arr[i]</code> 是待排序的元素，index 比 <code>i</code> 小的元素則組成已排序的部分序列。</li>
<li>內層迴圈負責元素比較，決定待排序元素該從何處插入，若前一個元素比待排元素大，則置換兩元素，並繼續往下尋找正確的插入點。直到 <code>j == 0</code> 或待排元素比任何已排序元素都大為止。</li>
</ol>
<a class="header" href="#a變形" id="a變形"><h2>變形</h2></a>
<a class="header" href="#binary-insertion-sort-1" id="binary-insertion-sort-1"><h3>Binary Insertion Sort</h3></a>
<p>在一般演算法討論中，通常以簡單的型別如 <code>i32</code> 來探討並實作。在真實世界中，做哪種操作，用哪種語言，都會影響到實際效能。例如 Python 的比較操作相對於置換元素，成本高出不少，是因為每個物件在 Python 的比較需動態檢查是否實作 <code>__lt__</code> <code>__gt__</code> 等方法才能進行比較。所以 Python 排序法實作就要特別注意減少比較操作的次數。</p>
<p>Binary insertion sort 的目的就是減少內層迴圈的比較次數。在內層迴圈開始之前，使用 <a href="https://en.wikipedia.org/wiki/Binary_search">binary search</a> 搜尋新元素應要插入哪個位置，最多僅需 $\log_2n $ 次比較。但 binary insertion sort 的複雜度依舊是 $O(n^2) $，因為除了比較之外，仍需置換（swap）、賦值（assign）等基礎操作。</p>
<p>Binary insertion sort 的程式碼和一般的 insertion sort 差不了多少，我們這裡使用 <code>slice</code> 內建的 <code>binary_search</code> 來找尋插入點。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn binary_insertion_sort(arr: &amp;mut [i32]) {
    for i in 1..arr.len() {
        let val = arr[i];
        let mut j = i;
        let pos = match arr[..i].binary_search(&amp;val) { // 1
            Ok(pos) =&gt; pos,                            // 2
            Err(pos) =&gt; pos,
        };
        while j &gt; pos {                                // 3
            arr.swap(j - 1, j);
            j -= 1;
        }
    }
}
#}</code></pre></pre>
<ol>
<li>先限制 <code>binary_search</code> 範圍，取出 sorted pile <code>arr[..i]</code>。再對 slice 執行 <code>binary_search</code>。</li>
<li><code>binary_search</code> 回傳一個 <code>Result&lt;usize, usize&gt;</code> 型別，找到時回傳 <code>Ok(index 值)</code>，找無時回傳 <code>Err(不影響排序穩定度的插入點)</code>，這個 <code>Err</code> 的設計巧妙解決新值插入的問題。</li>
<li>和普通 insertion sort 雷同，從插入點至 sorted pile 迭代到末端以進行排序，省下不少比較操作。</li>
</ol>
<a class="header" href="#a參考資料-5" id="a參考資料-5"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Insertion_sort">Wiki: Insertion sort</a></li>
<li><a href="https://github.com/python/cpython/blob/15f44ab043b37c064d6891c7864205fed9fb0dd1/Objects/listsort.txt#L686-L703">CPython: listsort note</a></li>
<li>Sorting GIF by Swfung8 (Own work) <a href="https://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a選擇排序-selection-sort" id="a選擇排序-selection-sort"><h1>選擇排序 Selection sort</h1></a>
<p>Selection sort 是最易實作的入門排序法之一，會將資料分為 sorted pile 與 unsorted pile，每次從 unsorted pile 尋找最大／最小值，加入 sorted pile 中。</p>
<p>Selection sort 的特性如下：</p>
<ul>
<li>最簡單的排序法之一。</li>
<li>對小資料序列排序效率較高。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
</ul>
<a class="header" href="#a步驟-3" id="a步驟-3"><h2>步驟</h2></a>
<ol>
<li>將資料分為 sorted pile 與 unsorted pile。</li>
<li>從 unsorted pile 尋找最小值。</li>
<li>置換該最小值元素與 unsorted pile 第一個元素。</li>
<li>重複步驟 2 - 3，直到排序完成。</li>
</ol>
<blockquote>
<p>注意，這個 naïve 的 selection sort 實作為<strong>不穩定排序</strong>。</p>
</blockquote>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/9/94/Selection-Sort-Animation.gif" alt="" /></p>
<p><em>Joestape89 - CC BY-SA 3.0</em></p>
<a class="header" href="#a說明-2" id="a說明-2"><h2>說明</h2></a>
<p>為什麼 naïve 的 selection sort 會是不穩定排序？</p>
<p>假定有一個序列要遞增排序，其中有重複的 <code>2</code> 元素，我們將其標上 <code>2a</code>、<code>2b</code> 以利辨識。</p>
<pre><code>[2a, 3, 4, 2b, 1]
</code></pre>
<p>開始迭代找出最小值並指環。</p>
<pre><code class="language-bash"> *             *
[1, 3, 4, 2b, 2a] # 1. 置換 2a, 1

     *     *
[1, 2b, 4, 3, 2a] # 2. 置換 3, 2b

        *       *
[1, 2b, 2a, 3, 4] # 3. 置換 4, 2a
</code></pre>
<p>有沒有發現，<code>2a</code> 與 <code>2b</code> 的相對順序顛倒了呢？</p>
<p>首先，回想一下穩定排序的定義：<strong>相同鍵值的元素，排序後相對位置不改變。</strong></p>
<p>問題出在 naïve selection sort 是以置換的方式排序每次迭代的最小值。若我們將置換（swap）改為插入（insert），那麼 selection sort 就會是穩定排序，但相對地，需要位移剩餘未排序的元素，除非使用 linked list 或其他提供 $O(1) $ insertion 的資料結構，不然就會多出額外 $O(n^2) $ 的寫入成本。</p>
<a class="header" href="#a效能-5" id="a效能-5"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity    </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ </td></tr>
<tr><td> Best         </td><td> $O(n^2) $ </td></tr>
<tr><td> Average      </td><td> $O(n^2) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<p>對於接近排序完成的序列，selector sort 並無法有自適應的方式加快排序迭代。第一個元素要做 $n - 1 $ 次比較，第二個 $n - 2 $ 次，總比較次數如下：</p>
<p>$$ (n -1) + (n-2) + \cdots + 1 = \sum_{i=1}^{n-1} i = \frac{n(n - 1)}{2}$$</p>
<p>因此無論序列是否排序完成，selection sort 仍需執行 $n^2 $ 次比較，時間複雜度為 $O(n^2) $。</p>
<a class="header" href="#a實作-4" id="a實作-4"><h2>實作</h2></a>
<p>簡單實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn selection_sort(arr: &amp;mut [i32]) {
    let len = arr.len();
    for i in 0..len {                     // 1
        let mut temp = i;
        for j in (i + 1)..len {           // 2
            if arr[temp] &gt; arr[j] {
                temp = j;
            }
        }
        arr.swap(i, temp);                // 3
    }
}
#}</code></pre></pre>
<ol>
<li>外層迴圈負責儲存當前要排序的 index <code>i</code> 的位置。</li>
<li>內層迴圈負責在 unsorted pile 範圍 [<code>i</code>, <code>len</code>) 找最小值。</li>
<li>外層迴圈在找到最小值之後，置換兩元素。</li>
</ol>
<p>眼尖的人會發現，內外兩層迴圈的 upper bound 都是 <code>len</code>，這樣是否內側迴圈會 out of bound？Rust 的 range operator（<code>core::ops::Range</code>）實作 <a href="https://doc.rust-lang.org/core/ops/struct.Range.html#impl-Iterator"><code>Iterator</code></a> trait 時，有檢查 <code>range.start &lt; range.end</code>，因此這個寫法並不會有出界問題，但會多跑一次無意義的迭代。</p>
<a class="header" href="#a變形-1" id="a變形-1"><h2>變形</h2></a>
<a class="header" href="#heapsort" id="heapsort"><h3>Heapsort</h3></a>
<p><a href="../heapsort/">Heapsort</a> 是一個高效的排序法，使用 selection sort 融合 <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> 這種半排序的資料結構，讓時間複雜度進化至 $O(n \log n) $。更多詳情可以參考<a href="../heapsort/">這篇介紹</a>。</p>
<a class="header" href="#a參考資料-6" id="a參考資料-6"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Selection_sort">Wiki: Selection sort</a></li>
<li><a href="https://stackoverflow.com/questions/20761396/">Why Selection sort can be stable or unstable</a></li>
<li>Sorting GIF by Joestape89 <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a氣泡排序-bubble-sort" id="a氣泡排序-bubble-sort"><h1>氣泡排序 Bubble sort</h1></a>
<p>Bubble sort 是最簡單的排序法之一，由於排序時每個元素會如同泡泡般，一個一個浮出序列頂部，因而得名。由於其簡單好理解，名稱又有趣，常作為第一個學習的入門排序法。不過其效率不彰，甚至不如同為 quardratic time 的 insertion sort。Bubble sort 的原理很平凡，就是相鄰兩兩元素互相比較，如果大小順序錯了，就置換位置。再往下一個 pair 比較。</p>
<p>Bubble sort 的特性如下：</p>
<ul>
<li>又稱為 <strong>sinking sort</strong>。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
</ul>
<a class="header" href="#a步驟-4" id="a步驟-4"><h2>步驟</h2></a>
<ol>
<li>比較兩個相鄰元素，若首個元素比次個元素大，置換兩者的位置。</li>
<li>依序對相鄰元素執行步驟一，直到抵達序列頂端，此時頂端元素排序完成。</li>
<li>重複步驟 1 - 2 的整個序列迭代，直到任何一次迭代沒有執行元素置換。</li>
</ol>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/c/c8/Bubble-sort-example-300px.gif" alt="" />
<em>Swfung8 - CC BY-SA 3.0</em></p>
<a class="header" href="#a說明-3" id="a說明-3"><h2>說明</h2></a>
<p>給定一組序列 <code>[5, 3, 8, 7, 2]</code>，以 bubble sort 遞增排序。以 ASCII diagram 表示：</p>
<p><strong>第一次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[5, 3, 8, 7, 4] -&gt; [3, 5, 8, 7, 4] # 置換 3 與 5

    *  *               *  *
[3, 5, 8, 7, 4] -&gt; [3, 5, 8, 7, 4] # 不需置換

       *  *               *  *
[3, 5, 8, 7, 4] -&gt; [3, 5, 7, 8, 4] # 置換 7 與 8

          *  *               *  *
[3, 5, 7, 8, 4] -&gt; [3, 5, 7, 4, 8] # 置換 4 與 8，8 已排好序
</code></pre>
<p><strong>第二次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[3, 5, 7, 4, 8] -&gt; [3, 5, 7, 4, 8] # 不需置換

    *  *               *  *
[3, 5, 7, 4, 8] -&gt; [3, 5, 7, 4, 8] # 不需置換

       *  *               *  *
[3, 5, 7, 4, 8] -&gt; [3, 5, 4, 7, 8] # 置換 4 與 7

          *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 5, 4, 7, 8] # 不需置換
</code></pre>
<blockquote>
<p>naïve bubble sort 會跑完整個序列，即是已排序完成。</p>
</blockquote>
<p><strong>第三次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 5, 4, 7, 8] # 不需置換

    *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 4, 5, 7, 8] # 置換 4 與 5

       *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

          *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換
</code></pre>
<p><strong>第四次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

    *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

       *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

          *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換
</code></pre>
<p>很簡單的排序法！</p>
<a class="header" href="#a效能-6" id="a效能-6"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity    </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ </td></tr>
<tr><td> Best         </td><td> $O(n) $   </td></tr>
<tr><td> Average      </td><td> $O(n^2) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<a class="header" href="#time-complexity" id="time-complexity"><h3>Time complexity</h3></a>
<p>Bubble sort 總共需要 $n - 1 $ 次迭代，每次迭代至少需要執行 $n - 1 - i $ 置換（ $i $ 為第幾次迭代），總共需要迭代</p>
<p>$$\sum_{i=0}^{n-1} (n - i - 1) = n^2 - \sum_{i=0}^{n-1}i - n = n^2 - \frac{n(n - 1)}{2} - n = \frac{n^2}{2} - \frac{n}{2}$$</p>
<p>次，因此，時間複雜度為 $O(n^2) $。</p>
<p>Bubble sort 在已排序完成的序列上，只需要迭代序列一次，發現完全沒有置換任何元素，即停止排序，可達到最佳時間複雜度。</p>
<a class="header" href="#a實作-5" id="a實作-5"><h2>實作</h2></a>
<p>Bubble sort 簡單實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bubble_sort(arr: &amp;mut [i32]) {
    let mut swapped = true;                 // 1
    while swapped {
        swapped = false;
        for i in 1..arr.len() {             // 2
            if arr[i - 1] &gt; arr[i] {
                arr.swap(i - 1, i);
                swapped = true              // 3
            }
        }
    }
}
#}</code></pre></pre>
<ol>
<li>建立一個旗標，標誌該次迭代是否有元素置換。</li>
<li>內層迴圈依序比較兩兩相鄰元素。</li>
<li>若有任何置換動作，將旗標標誌為「已置換（<code>true</code>）」。</li>
</ol>
<p>倘若記錄已排好序的元素位置，雖然複雜度仍是 $O(n^2) $，但如此以來，每次迭代都可少一次元素比較，對比較操作成本高的語言或實作來說，仍不失為最佳化的方法。程式碼如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bubble_sort_optimized(arr: &amp;mut [i32]) {
    let mut new_len: usize;
    let mut len = arr.len();            // 1
    loop {
        new_len = 0;
        for i in 1..len {
            if arr[i - 1] &gt; arr[i] {
                arr.swap(i - 1, i);
                new_len = i;            // 2
            }
        }
        if new_len == 0 {               // 3
            break;
        }
        len = new_len;                  // 4
    }
}
#}</code></pre></pre>
<ol>
<li>將當前的序列長度記錄到 <code>len</code>。</li>
<li>內層迴圈負責比較、置換，以及記錄未排序部分的序列長度到 <code>new_len</code>。</li>
<li>若未排序部分 <code>new_len</code> 為零，代表排序完成。</li>
<li>外層迴圈將新長度值 <code>new_len</code> 賦予 <code>len</code>，下一次迭代就可少做一次比較。</li>
</ol>
<a class="header" href="#a參考資料-7" id="a參考資料-7"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bubble_sort">Wiki: Bubble sort</a></li>
<li>Sorting GIF was created by Swfung8 (Own work) <a href="https://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a希爾排序-shellsort" id="a希爾排序-shellsort"><h1>希爾排序 Shellsort</h1></a>
<p>眾所周知，<a href="../insertion_sort">Insertion sort</a> 用在幾乎完成排序的序列上非常高效，換句話說，當元素置換不需移動太遠時，效率很高。反之，如果有元素錯位非常遙遠，效能就會大打折扣。Shellsort 以一個 gap sequence 將資料依指定的間隔（gap）分組進行 insertion sort，使得較遠的元素能夠快速歸位，下一次的排序就會因前次排序結果愈來愈接近完成而加速。</p>
<p>Shellsort 最後一個 gap 必定是 1，也就是排序會退化成 insertion sort，此時大部分元素皆排序完成，insertion sort 會非常高效。</p>
<p>Shellsort 特性如下：</p>
<ul>
<li><strong>自適應排序</strong>：可根據當前資料排序情形加速排序，資料越接近排序完成，效率越高。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
<li>可視為一般化（Generalizaion）的 <a href="../insertion_sort">insertion sort</a>。</li>
</ul>
<a class="header" href="#a步驟-5" id="a步驟-5"><h2>步驟</h2></a>
<p>Shellsort 分為兩個步驟：</p>
<ol>
<li>決定一組 gap sequence。</li>
<li>迭代 gap sequence 進行分組排序，每次執行有間隔的 insertion sort。也就是每個元素與其相鄰 gap 的元素比較與置換。</li>
</ol>
<blockquote>
<p>最後一次排序（gap = 1）會退化為 insertion sort，完成整個排序。</p>
</blockquote>
<a class="header" href="#gap-sequneces" id="gap-sequneces"><h3>Gap Sequneces</h3></a>
<p>Shellsort 的效率取決於 gap sequence 的選擇，這邊舉幾個常見的 gap sequence：</p>
<table><thead><tr><th>              </th><th> Sequence                        </th></tr></thead><tbody>
<tr><td> Marcin Ciura </td><td> 1, 4, 10, 23, 57, 132, 301, 701 </td></tr>
<tr><td> $2^{k} - 1 $  </td><td> 1, 3, 7, 15, 31, 63,...         </td></tr>
<tr><td> $\lfloor {\frac {N}{2^k}} \rfloor $ </td><td> $\lfloor {\frac {N}{2}} \rfloor $, $\lfloor {\frac {N}{4}} \rfloor $, ..., 1</td></tr>
</tbody></table>
<p>感受一下 gap sequence 為 23, 10, 4, 1 的 shellsort 吧。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/d8/Sorting_shellsort_anim.gif" alt="" /></p>
<a class="header" href="#a說明-4" id="a說明-4"><h2>說明</h2></a>
<p>Shellsort 其實就是進行好幾次不同 gap 的 insertion sort，以下用 ASCII diagram 解釋。</p>
<p>假定這裡有一個序列需要遞增排序。</p>
<pre><code>[5, 3, 8, 7, 4, 9, 6, 2]
</code></pre>
<p>我們選擇最簡單的 $\lfloor {\frac {N}{2^k}} \rfloor $ gap sequence 來排序。我們以<strong>星號</strong>標示出每次 insertion sort 對應排序</p>
<p>首先算出第一個 gap 為 $8 / 2^1 = 4 $。開始 insertion sort。</p>
<pre><code> *           *
[5, 3, 8, 7, 4, 9, 6, 2]

-&gt; (sort subsequence [5, 4])

    *           *
[4, 3, 8, 7, 5, 9, 6, 2]

-&gt; (skip)
       *           *
[4, 3, 8, 7, 5, 9, 6, 2]

-&gt; (sort subsequence [8, 6])
          *           *
[4, 3, 6, 7, 5, 9, 8, 2]

-&gt; (sort subsequence [7, 2])

[4, 3, 8, 2, 5, 9, 6, 7]
</code></pre>
<p>再來算出第二個 gap 為 $8 / 2^2 = 2 $。開始 insertion sort。</p>
<pre><code> *     *
[4, 3, 8, 2, 5, 9, 6, 7]

-&gt; (skip)
    *     *
[4, 3, 8, 2, 5, 9, 6, 7]

-&gt; (sort subsequence [3, 2])
 *     *     *
[4, 2, 8, 3, 5, 9, 6, 7]

-&gt; (sort subsequence [4, 8, 5])
    *     *     *
[4, 2, 5, 3, 8, 9, 6, 7]

-&gt; (skip)
 *     *     *     *
[4, 2, 5, 3, 8, 9, 6, 7]

-&gt; (sort subsequence [4, 5, 8, 6])
    *     *     *     *
[4, 2, 5, 3, 6, 9, 8, 7]

-&gt; (sort subsequence [2, 3, 9, 7])
[4, 2, 5, 3, 6, 7, 8, 9]
</code></pre>
<p>再來進行第三次排序。gap 為 $8 / 2^3 = 1 $，shellsort 退化至 insertion sort，但前一次結果已經很接近排序完成，insertion sort 可以幾乎在 one pass 完成排序。</p>
<blockquote>
<p>Insertion sort 的 ASCII diagram 我們就不展示了，請參考 <a href="../insertion_sort">Insertion sort</a>。</p>
</blockquote>
<a class="header" href="#a效能-7" id="a效能-7"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity                                            </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ ~  $O(n \log^2 n) $ (Depends on gap sequence) </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $                                    </td></tr>
<tr><td> Average      </td><td> Depends on gap sequence                               </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary                                 </td></tr>
</tbody></table>
<p>Shellsort 的複雜度不容易計算，取決於 gap sequence 怎麼安排，太少 gap 會讓速度太接近 insertion sort，太多 gap 則會有過多額外開銷。目前已知的 gap sequence 中，最差時間複雜度可以達到 $O(n \log^2 n) $，有著不錯的表現。有興趣可以參考<a href="http://www.dtic.mil/get-tr-doc/pdf?AD=AD0740110">這篇文章</a>。</p>
<a class="header" href="#a實作-6" id="a實作-6"><h2>實作</h2></a>
<p>我們這裡以 <a href="http://sun.aei.polsl.pl/%7Emciura/publikacje/shellsort.pdf">Marcin 的 Paper</a> 中提到的經驗式為例，首先，先建立一個 gap sequence 的常數。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Marcin Ciura's gap sequence.
pub const MARCIN_GAPS: [usize; 8] = [701, 301, 132, 57, 23, 10, 4, 1];
#}</code></pre></pre>
<p>再來就是主程式的部分，總共會有三個迴圈，</p>
<ul>
<li>最外層是迭代 gap sequence，</li>
<li>中間層是迭代整個資料序列，</li>
<li>內層就是每個元素的插入排序動作。</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Shellsort
pub fn shellsort(arr: &amp;mut [i32]) {
    let len = arr.len();
    for gap in MARCIN_GAPS.iter() {                     // 1
        let mut i = *gap;                               // 4
        while i &lt; len {                                 // 2
            let mut j = i;
            while j &gt;= *gap &amp;&amp; arr[j - gap] &gt; arr[j] {  // 3
                arr.swap(j - *gap, j);
                j -= *gap;
            }
            i += 1;
        }
    }
}
#}</code></pre></pre>
<ol>
<li>最外層的迴圈，利用 <code>iter()</code> trait 產生迭代器，迭代 gap sequence。</li>
<li>中間層迴圈，控制 <code>i</code> 是否超出資料序列，以迭代整合資料序列。</li>
<li>最內層迴圈，執行插入動作，將每個元素置換到正確位置。</li>
<li>由於 <code>gap</code> 的型別是 <code>&amp;usize</code>，需透過 <code>*gap</code> dereference 得到 <code>usize</code> 型別。</li>
</ol>
<a class="header" href="#a參考資料-8" id="a參考資料-8"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Shellsort">Wiki: Shellsort</a></li>
<li><a href="http://sun.aei.polsl.pl/%7Emciura/publikacje/shellsort.pdf">Best Increments for the Average Case of Shellsort, M. Ciura, 2001</a></li>
<li><a href="http://www.dtic.mil/get-tr-doc/pdf?AD=AD0740110">Shellsort and Sorting Networks (Outstanding Dissertations in the Computer Sciences)</a></li>
</ul>
<a class="header" href="#a高效排序" id="a高效排序"><h1>高效排序</h1></a>
<ul>
<li><a href="heapsort">堆積排序 Heapsort</a></li>
<li><a href="quicksort">快速排序 Quicksort</a></li>
<li><a href="mergesort">合併排序 Mergesort</a></li>
</ul>
<a class="header" href="#a堆積排序-heapsort" id="a堆積排序-heapsort"><h1>堆積排序 Heapsort</h1></a>
<p>Heapsort（堆積排序）可以看作是 <a href="../selection_sort">selection sort</a> 的變形，同樣會將資料分為 sorted pile 與 unsorted pile，並在 unsorted pile 中尋找最大值（或最小值），加入 sorted pile 中。</p>
<p>和 selection sort 不同之處是，heapsort 利用<a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">堆積（heap）</a>這種半排序（partially sorted）的資料結構輔助並加速排序。</p>
<p>Heapsort 的特性如下：</p>
<ul>
<li>使用 <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> 資料結構輔助，通常使用 <a href="https://en.wikipedia.org/wiki/Binary_heap">binary heap</a>。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
<li><strong>較差的 CPU 快取</strong>：heap 不連續存取位址的特性，不利於 <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU 快取</a>。</li>
</ul>
<a class="header" href="#a步驟-6" id="a步驟-6"><h2>步驟</h2></a>
<p>Heapsort 的演算法分為兩大步驟：</p>
<ol>
<li>將資料轉換為 heap 資料結構（遞增排序用 max-heap, 遞減排序選擇 min-heap）。</li>
<li>逐步取出最大／最小值，並與最後一個元素置換。具體步驟如下：
<ol>
<li>交換 heap 的 root 與最後一個 node，縮小 heap 的範圍（排序一筆資料，故 heap 長度 -1）。</li>
<li>更新剩下的資料，使其滿足 heap 的特性，稱為 heap ordering property。</li>
<li>重複前兩個步驟，直到 heap 中剩最後一個未排序的資料。</li>
</ol>
</li>
</ol>
<p>透過 GIF 動畫感受一下 heapsort 的威力吧！</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/1/1b/Sorting_heapsort_anim.gif" alt="" /></p>
<a class="header" href="#a說明-5" id="a說明-5"><h2>說明</h2></a>
<p>在開始之前，定義幾個 heap 常用名詞：</p>
<ul>
<li><strong>Heap ordering property</strong>：一個 heap 必須要滿足的條件。以 heap 種類不同有幾種變形。
<ul>
<li><strong>min-heap property</strong>：每個結點皆大於等於其父節點的值，且最小值在 heap root。</li>
<li><strong>max-heap property</strong>：每個結點皆小於等於其父節點的值，且最大值在 heap root。</li>
</ul>
</li>
</ul>
<p>而 heapsort 主要分為兩個部分：</p>
<ol>
<li><strong>Heapify</strong>：將陣列轉換為 heap 資料結構（heapify）。</li>
<li><strong>Sorting</strong>：不斷置換 heap root 與最後一個元素來排序，並修正剩餘未排序資料使其符合 heap order。</li>
</ol>
<p>這裡有一個未排序的序列，將以遞增方向排序之。</p>
<pre><code>[17, 20, 2, 1, 3, 21]
</code></pre>
<p>首先，將資料轉換為 heap 資料結構，這個步驟即時 <strong>heapify</strong>。由於是遞增排序，我們採用 max-heap（最大元素在 root）。</p>
<pre><code>[21, 20, 17, 1, 3, 2]
</code></pre>
<p>對應的二元樹（binary tree）的圖形如下：</p>
<p><img src="tree.png" height="300px" /></p>
<p>再來就是<strong>排序的部分</strong>，Max-heap 會將最大的元素擺在 root 的位置，我們先將最後一個 node 與 root 進行交換，完成第一個排序步驟。</p>
<blockquote>
<p>若不熟悉 heap，可以閱讀 <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">Wiki 的介紹</a>，其實 heap 就是用陣列實作的二元樹。</p>
</blockquote>
<pre><code>[21, 20, 17, 1, 3, 2]
 *                 *
(swap) --&gt;

        unsorted | sorted
[2, 20, 17, 1, 3 | 21]
</code></pre>
<p>接下來，將未排序的資料區塊重整為符合 max-heap 的結構。</p>
<pre><code>[2, 20, 17, 1, 3 | 21]

(sift down) --&gt;

[20, 3, 17, 1, 2 | 21]
</code></pre>
<p>有沒有看出一些端倪？</p>
<p>只要不斷將 root 和最後一個 node 交換，並將剩餘資料修正至滿足 heap ordering，就完成排序了。</p>
<pre><code>[20, 3, 17, 1, 2 | 21]
 *             *
(swap) --&gt;

[2, 3, 17, 1 | 20, 21]

(sift down)--&gt;

[17, 3, 2, 1 | 20, 21]
 *         *
(swap) --&gt;

[1, 3, 2 | 17, 20, 21]

(sift down)--&gt;

[3, 1, 2 | 17, 20, 21]
 *     *
(swap) --&gt;

[1, 2 | 3, 17, 20, 21]

(Done!)
</code></pre>
<p>以上便是 heapsort 演算法的簡單流程，是不是和 selection sort 非常相似呢！</p>
<a class="header" href="#a效能-8" id="a效能-8"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n \log n) $ </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $ </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<p>Heapsort 最佳、最差、平均的時間複雜度皆為 $O(n \log n) $，同樣分為兩部分簡單解釋。</p>
<a class="header" href="#build-heap-heapify" id="build-heap-heapify"><h3>Build heap (heapify)</h3></a>
<p>建立一個 binary heap 有兩種方法，一種是一個個元素慢慢加入 heap 來建立；另一種則是給定隨意的序列，再透過 heapify 演算法修正序列為有效的 heap。一般來說 heapsort 常用實作後者。</p>
<p><strong>Heapify</strong> 是指將序列修正至符合 heap ordering 的序列。給定一個元素，假定其為非法的 heap order，而該元素之後的 subtree 視為符合 heap ordering property。欲修正這個在錯誤位置的元素，必須透過與其 children node 置換往下篩，這個往下篩的過程就稱為 <strong>sift down</strong>，在<a href="#%E5%AF%A6%E4%BD%9C">實作</a>一節會詳細解釋，這邊只要知道 sift down 會不斷將該元素與其 child node 比較，若不符合 heap order 則與 child node 置換，並繼續迭代每一個 level。所以 sift down 的時間複雜度為 $O(\lceil {\log_2(n)} \rceil) = O(\log n) $， $n $ 為陣列元素個數。</p>
<p>Heapify 從最末個元素開始反向迭代，每個元素都呼叫 <code>sift_down</code> 調整 heap 符合 heap ordering。總共要做 $n $ 次 <code>sift_down</code> 操作，但由於最後一層所以 leaf 已符合 heap order（因為沒有 child node），我們的迴圈可以跳過所有 leaf node 直接從非 leaf node 開始，因此複雜度為</p>
<p>$$\lfloor n / 2 \rfloor \cdot O(\log n) = O(n \log n)$$</p>
<blockquote>
<p>實際上，build heap 步驟的複雜度可達到 $O(n) $，可以看看 UMD 演算法課程 <a href="http://www.cs.umd.edu/%7Emeesh/351/mount/lectures/lect14-heapsort-analysis-part.pdf">Lecture note 的分析</a>。</p>
</blockquote>
<a class="header" href="#sorting-sift-down" id="sorting-sift-down"><h3>Sorting (sift down)</h3></a>
<p>講完了 heapify，就換到排序部分，所謂的排序其實就是利用 max-heap（或 min-heap）的最大值（最小值）會在首個元素的特性，與最後一個元素置換，完成排序，並將剩餘的部分透過 <strong>sift down</strong> 修正符合 heap order。所以總共需要做 $n $ 次 sift down，複雜度為 $O(n \log n) $。</p>
<a class="header" href="#sum-up" id="sum-up"><h3>Sum up</h3></a>
<p>綜合這兩部分，可以看出 Sorting part 對複雜度有決定性影響，最佳複雜度為 $O(n \log n) $。</p>
<a class="header" href="#a實作-7" id="a實作-7"><h2>實作</h2></a>
<p>Heapsort 的實作相對簡單，只需要不斷呼叫 heap 內部的 <code>sift_down</code> 方法就可以完成排序。整個演算法架構如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn heapsort(arr: &amp;mut [i32]) {
    // -- Heapify part --
    // This procedure would build a valid max-heap.
    // (or min-heap for sorting descendantly)
    let end = arr.len();
    for start in (0..end / 2).rev() {                   // 1
        sift_down(arr, start, end - 1);
    }

    // -- Sorting part --
    // Iteratively sift down unsorted part (the heap).
    for end in (1..arr.len()).rev() {                   // 2
        arr.swap(end, 0);                               // 3
        sift_down(arr, 0, end - 1);                     // 4
    }
}
#}</code></pre></pre>
<ol>
<li>這部分是 heapify，從最小 non-leaf node 開始（<code>end</code> / 2），修正序列至滿足 heap order，再反向迭代做 heapify。</li>
<li>這部分負責排序，每次迭代都將排序 heap 的 root 元素，步驟如 3 - 4：</li>
<li>不斷將 max-heap 中最大值（在 root 上）與 heap 最後一個元素 <code>end</code> 置換，</li>
<li>並利用 <code>sift_down</code> 將序列修正至 max-heap 資料結構，依照定義，此時 unsorted pile 首個元素成為 max-heap root，是最大值。</li>
</ol>
<p>Heapsort 全靠 <code>sift_down</code> 神救援，那 <code>sift_down</code> 到底有什麼神奇魔力，一探究竟吧！</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn sift_down(arr: &amp;mut [i32], start: usize, end: usize) {
    let mut root = start;
    loop {
        let mut child = root * 2 + 1; // Get the left child   // 1
        if child &gt; end {
            break;
        }
        if child + 1 &lt;= end &amp;&amp; arr[child] &lt; arr[child + 1] {  // 2
            // Right child exists and is greater.
            child += 1;
        }

        if arr[root] &lt; arr[child] {                           // 3
            // If child is greater than root, swap'em!
            arr.swap(root, child);
            root = child;
        } else {
            break;
        }
    }
}
#}</code></pre></pre>
<p><code>sift_down</code> 的功能是將 node 往下移。通常用在 heap 刪除或取代 node 時，將序列修正為有效的 heap。 這裡實作的版本有三個參數：</p>
<ul>
<li><code>arr</code>：欲修正為符合 heap 定義的序列。</li>
<li><code>start</code>：欲往下移動的 node index，可視為需要被修正的元素。</li>
<li><code>end</code>：此 node 以內（包含）的序列都會被修正為有效的 heap。</li>
</ul>
<p><code>sift_down</code> 有些假設條件：從 <code>start</code> index 出發的子樹，除了 <code>start</code> 本身以外，其他皆符合 heap ordering。</p>
<p>再來看看 <code>sift_down</code> 實作內容，<code>loop</code> 中幹的活就是不斷將 <code>start</code> index 上的元素與其子樹比較，若不符合 heap ordering，則兩者置換。</p>
<ol>
<li><strong>是否有子結點</strong>：依照 binary heap 的定義找出 root 的左子樹（left substree），若左子樹的 index <code>child</code> 比 <code>end</code> 還大，表示沒有 heap 沒有子結點，停止迭代。</li>
<li><strong>檢查右子樹值較大</strong>：若 root 下有右子樹且較大，我們會標記右子樹，並在下一步對右子樹進行處理。</li>
<li><strong>置換</strong>：若 <code>root</code> 元素比 <code>child</code> 的元素小，則置換兩者，並將 <code>child</code> 設置為下個迭代的 <code>root</code>，繼續檢查最初的 <code>start</code> 元素是否滿足 heap ordering。</li>
</ol>
<p>以上就是簡單的 <code>sift_down</code> 實作，也是整個 heapsort 的精髓。</p>
<a class="header" href="#a參考資料-9" id="a參考資料-9"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">Wiki: Heap</a></li>
<li><a href="https://en.wikipedia.org/wiki/Heapsort">Wiki: Heapsort</a></li>
<li><a href="www.cs..html">CMSC 351 Algorithms, Fall, 2011, University of Maryland.</a></li>
<li>Sorting GIF by RolandH <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a快速排序-quicksort" id="a快速排序-quicksort"><h1>快速排序 Quicksort</h1></a>
<p>Quicksort 是一個非常熱門且應用廣泛的排序法，相對簡單的實作就可達到 $O(n \log n) $ 的平均時間複雜度。雖然最差時間複雜度與 <a href="../bubble_sort">bubble sort</a> 同為 $O(n^2) $，但這種情形非常少見。簡單的最佳化實作下，Quicksort 僅需 $O(\log n) $ 的額外儲存空間，比它的競爭對手 <a href="../mergesort">mergesort</a> 來得節省。非常適合運用在真實世界中的排序法。</p>
<p>Quicksort 基本特性如下：</p>
<ul>
<li>實作簡單，速度快。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>非原地排序</strong>：除了資料本身，仍需額外花費儲存空間來排序。</li>
<li><strong>分治演算法</strong>：將主問題化作數個子問題，各個擊破。</li>
</ul>
<a class="header" href="#a步驟-7" id="a步驟-7"><h2>步驟</h2></a>
<p>Quicksort 是一個分治演算法（divide-and-conquer），不斷遞迴下列三個步驟：</p>
<ol>
<li><strong>選擇 Pivot</strong>：在序列中任意選擇一個元素，稱為 <strong>Pivot</strong>。</li>
<li><strong>分割序列</strong>：將序列重新排序，分為兩部分，比 pivot 小 的元素置換到 pivot 之前，比 pivot 大的元素置換到 pivot 之後，而 pivot 本身會座落在它最終的正確位置。</li>
<li><strong>遞迴</strong>：分別將_比 pivot 小_，以及_比 pivot 大_ 兩部分分別重複上述步驟，直到新序列的長度小於等於 1，無法繼續分割為止，此時排序完成。</li>
</ol>
<a class="header" href="#lomuto-partition-scheme" id="lomuto-partition-scheme"><h3>Lomuto partition scheme</h3></a>
<p>為了達成上述條件，Quicksort 有許多不同的分割序列實作方案（partition scheme），其中以 Lomuto partition 最易理解，常被做為教材。</p>
<ol>
<li>以序列最後一個元素當做 pivot。</li>
<li>利用兩個指標 <code>i</code> <code>j</code>，其中 <code>j</code> 從頭迭代整個序列
<ul>
<li>若有序列第 j 個元素小於 pivot，則與第 i 個元素置換。</li>
<li>第 i 個元素已落在小於 pivot 的範圍，將 i 指標往後移一個，處理下個元素。</li>
</ul>
</li>
<li>迭代完成後，小於 pivot 的元素全都置換至序列前端，此時將 pivot 與第 i 個元素置換，pivot 會剛好在最終正確位置上（符合不等式）。</li>
</ol>
<p>ASCII 畫出來的分割圖如下：</p>
<pre><code>[ values &lt;= pivot | values &gt; pivot | not checked yet | pivot ]
  low           i   i+1        j-1   j        high-1   high
</code></pre>
<ul>
<li><code>arr[low...i]</code> 包含所有小於等於 pivot 的元素。</li>
<li><code>arr[i+1...j-1]</code> 包含所有大於 pivot 的元素。</li>
<li><code>arr[j...high-1]</code> 包含所有尚未迭代的元素。</li>
<li><code>arr[high]</code> pivot 本身。</li>
</ul>
<a class="header" href="#a說明-6" id="a說明-6"><h2>說明</h2></a>
<p>以 Lomuto partition scheme 為例，使用 ASCII diagram 解釋。</p>
<p>給定一個序列，並選擇最後一個元素作為 pivot，<code>i</code> <code>j</code> 指標則在第一個元素位置。</p>
<pre><code>                      * -&gt; pivot
[17, 20, 2, 1, 3, 21, 8]
 i
 j
</code></pre>
<p>第 <code>j</code> 個元素 17 大於 pivot 8，不置換。</p>
<pre><code>17 &gt; 8, no swap
                       * -&gt; pivot
[17| 20, 2, 1, 3, 21, 8]
 i
 j
</code></pre>
<p>第 <code>j</code> 個元素 20 大於 pivot 8，不置換。</p>
<pre><code>20 &gt; 8, no swap
                      * -&gt; pivot
[17, 20| 2, 1, 3, 21, 8]
 i
     j
</code></pre>
<p>第 <code>j</code> 個元素 2 小於 pivot 8，置換 <code>i</code> <code>j</code>。<code>i</code> 往後一個位置。</p>
<pre><code>2 &lt;= 8,
swap i, j
                      * -&gt; pivot
[2, 20, 17| 1, 3, 21, 8]
 i-&gt;i
        j
</code></pre>
<p>第 <code>j</code> 個元素 1 小於 pivot 8，置換 <code>i</code> <code>j</code>。<code>i</code> 往後一個位置。</p>
<pre><code>1 &lt;= 8
swap i, j
                      * -&gt; pivot
[2, 1, 17, 20| 3, 21, 8]
    i-&gt;i
            j
</code></pre>
<p>第 <code>j</code> 個元素 3 小於 pivot 8，置換 <code>i</code> <code>j</code>。<code>i</code> 往後一個位置。</p>
<pre><code>3 &lt;= 8
swap i, j
                      * -&gt; pivot
[2, 1, 3, 20, 17| 21, 8]
       i-&gt;i
               j
</code></pre>
<p>第 <code>j</code> 個元素 21 大於 pivot 8，不置換。</p>
<pre><code>21 &gt; 8, no swap
                      * -&gt; pivot
[2, 1, 3, 20, 17, 21| 8]
           i
                   j
</code></pre>
<p>最後，將 pivot 與第 <code>i</code> 個元素置換，此時 pivot 已在最終位置上，前面的元素皆小於等於 8，其後的元素皆大於 8。</p>
<pre><code>swap pivot, i
          i    &lt;-&gt;   * -&gt; pivot
[2, 1, 3, 8, 17, 21, 20]
</code></pre>
<p>這樣就完成一次的 partition 了！</p>
<p>之後再遞迴分割 subarray 即可完成 Quicksort。</p>
<pre><code>[2, 1, 3, 8, 17, 21, 20]
 #     #     *       *
 |     |     |       |
 -------     ---------
 quicksort    quicksort
</code></pre>
<a class="header" href="#a效能-9" id="a效能-9"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $      </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $ </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(\log n) $ or $O(n) $ auxiliary </td></tr>
</tbody></table>
<a class="header" href="#time-complexity-1" id="time-complexity-1"><h3>Time complexity</h3></a>
<p>Quicksort 僅有「<strong>選擇 Pivot</strong>」與「<strong>分割序列</strong>」兩步驟，不同的實作的效能各異，也影響 Quicksort 的時間複雜度。</p>
<a class="header" href="#a最差情況" id="a最差情況"><h4>最差情況</h4></a>
<p>最差的分割序列狀況發生在挑選的 pivot 總是最大或最小值（或在 Lomuto partition 下，所有元素值都一樣）。由於 Lomuto 總是選擇最後一個元素作為 pivot，這種情形好發於已排序或接近排序完成的資料上。</p>
<p>而當每次的 partition 都是最不平衡的分割序列，就會產生最差時間複雜度的狀況。遞迴在序列長度等於 1 時停止，因此整個排序法的 call stack 需要 $n - 1 $ 的嵌套遞迴呼叫（nested call）；而第 $i $ 次分割會執行 $n - i $ 次基本操作（ $O(n) $），所以總共需執行</p>
<p>$$\sum_{i = 0}^n (n - i) = n^2 - \frac{n(n + 1)}{2}$$</p>
<p>次基本操作，最差時間複雜度為 $O(n^2) $。</p>
<a class="header" href="#a最佳情況" id="a最佳情況"><h4>最佳情況</h4></a>
<p>既然最差情況發生在 pivot 總選到最大或最小值，反之，最佳情況則發生在每次 pivot 都可以順利選到序列的中位數（median），如此一來，每次遞迴分割的序列長度都會減半（ $n / 2 $），call stack 的嵌套遞迴總共需要 $2 \log_2{n} $ 次，序列的長度就會減至 1，而每次分割同樣有 $O(n) $ 的複雜度，因此最佳情況為：</p>
<p>$$O(n \cdot 2 \log_2{n}) = O(n \log n)$$</p>
<a class="header" href="#space-complexity" id="space-complexity"><h3>Space complexity</h3></a>
<p>Quicksort 的空間複雜度取決於實作細節，由於<strong>分割序列</strong>步驟需 $O(1) $ 的空間複雜度，因此僅需分析遞迴式會在 call stack 產生多少 stack frame 即可。</p>
<p><a href="#%E6%9C%80%E5%B7%AE%E6%83%85%E6%B3%81">前面提及</a>，最 naïve 的 Lomuto partition 最糟糕的情形下，會產生 $n - 1 $ 個嵌套遞迴，也就是需額外使用 $O(n) $ 的空間儲存 call stack frame，但只要 compiler 有支援 <a href="https://en.wikipedia.org/wiki/Tail_call">尾端呼叫</a>最佳化（tail-call optimization，TCO），Quicksort 很容易最佳化至 $O(\log n) $。</p>
<a class="header" href="#a實作-8" id="a實作-8"><h2>實作</h2></a>
<p>Quicksort 實作主要分為兩部分：遞迴，以及分割序列（partition）。</p>
<a class="header" href="#recursion" id="recursion"><h3>Recursion</h3></a>
<p>遞迴函式本身實作非常簡單，分別將小於 pivot 與大於 pivot 兩部分遞迴呼叫自身即可。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Recursion helper
fn quicksort_helper(arr: &amp;mut [i32], lo: isize, hi: isize) {
    if lo &lt;= hi {                               // 1
        let pivot = partition(arr, lo, hi);     // 2
        quicksort_helper(arr, lo, pivot - 1);   // 3
        quicksort_helper(arr, pivot + 1, hi);   // 4
    }
}
#}</code></pre></pre>
<ol>
<li>利用 <code>lo</code> 與 <code>hi</code> 兩個指標決定每次的遞迴範圍，並在 <code>lo</code> 大於 <code>hi</code> 時停止遞迴，避免重複分割序列。</li>
<li>分割序列步驟，回傳該序列範圍內 pivot 的 index。</li>
<li>遞迴小於 pivot 的部分。</li>
<li>遞迴大於 pivot 的部分。</li>
</ol>
<blockquote>
<p>這邊比較特別的是，<code>lo</code> 和 <code>hi</code> 兩個指標的型別為 <code>isize</code>，因為當 pivot 可能為 0，在第三步驟 - 1 時會產生型別錯誤，故為之。有任何更好的寫法歡迎提供！</p>
</blockquote>
<p>由於外部不需知道排序法實作細節，我們將函式命名為 <code>quicksort_helper</code> ，對外再多封裝一層主函式 <code>quicksort_lomuto</code>，實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn quicksort_lomuto(arr: &amp;mut [i32]) {
    let hi = arr.len() as isize - 1;
    quicksort_helper(arr, 0, hi);
}
#}</code></pre></pre>
<a class="header" href="#partitioning" id="partitioning"><h3>Partitioning</h3></a>
<p>一般來說，分割序列的實作有下列兩個步驟：</p>
<ul>
<li>選擇 pivot</li>
<li>遍歷序列置換元素</li>
</ul>
<p>我們以 Lomuto scheme 實作 partition。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn partition(arr: &amp;mut [i32], lo: isize, hi: isize) -&gt; isize {
    // -- Determine the pivot --
    // In Lomuto parition scheme,
    // the latest element is always chosen as the pivot.
    let pivot = arr[hi as usize];               // 1
    let mut i = lo;

    // -- Swap elements --
    for j in lo..hi {                           // 2
        if arr[j as usize] &lt; pivot {
            arr.swap(i as usize, j as usize);
            i += 1;                             // 3
        }
    }
    // Swap pivot to the middle of two piles.
    arr.swap(i as usize, hi as usize);          // 4
    i // Return the final index of the pivot
}
#}</code></pre></pre>
<ol>
<li>Lomuto scheme 選擇 pivot 的方式很直接，就是選擇最後一個元素。</li>
<li>利用 <code>i</code>、<code>j</code> 兩個指標迭代指定的序列範圍，若第 j 個值小於 pivot 時，則於第 i 個元素置換。</li>
<li><code>i</code> 指標加一，繼續處理下個元素。</li>
<li>最後置換第 i 個元素於 pivot，此時 pivot 已落在最終正確的位置。</li>
</ol>
<a class="header" href="#a最佳化與變形" id="a最佳化與變形"><h2>最佳化與變形</h2></a>
<p>Quicksort 有數個方向可以探討最佳化：</p>
<ul>
<li><a href="#%E9%99%8D%E4%BD%8E%E9%A1%8D%E5%A4%96%E7%A9%BA%E9%96%93%E8%A4%87%E9%9B%9C%E5%BA%A6">降低額外空間複雜度</a></li>
<li><a href="#%E9%81%B8%E6%93%87-pivot-%E7%9A%84%E6%96%B9%E6%B3%95">選擇 Pivot 的方法</a></li>
<li><a href="#%E5%B0%8D%E4%BB%98%E9%87%8D%E8%A4%87%E7%9A%84%E5%85%83%E7%B4%A0">對付重複的元素</a></li>
<li><a href="%E9%81%B8%E6%93%87%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%86%E5%89%B2%E6%96%B9%E6%A1%88">選擇不同的分割方案</a></li>
</ul>
<a class="header" href="#a降低額外空間複雜度" id="a降低額外空間複雜度"><h3>降低額外空間複雜度</h3></a>
<p>前述提到最佳情形下（每次 pivot 都選到中位數），僅需 $\log n $ 個嵌套遞迴，額外空間複雜度僅需 $O(\log n) $。
倘若編譯器有實作 <strong>尾端呼叫最佳化</strong>，Quicksort 可以達到 $O(\log n) $ 對數級別的額外空間使用。</p>
<p>實作尾端呼叫最佳化的思路很簡單，「<strong>先遞迴較少元素的部分，再利用 tall-call 遞迴另一部分</strong>」，如此以來，較多元素的遞迴則會直接被編譯器展開，消去遞迴時需要的 call stack 空間。剩下較少元素的部分，則與最佳情形相同，最多僅需 $\log n $ 次嵌套遞迴。</p>
<p>簡單實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn quicksort_helper_optimized(arr: &amp;mut [i32], lo: isize, hi: isize) {
    if lo &lt;= hi {
        let pivot = partition(arr, lo, hi);
        if pivot - lo &lt; hi - pivot {                      // 1
          quicksort_helper_optimized(arr, lo, pivot - 1);
          quicksort_helper_optimized(arr, pivot + 1, hi); // 2
        } else {
          quicksort_helper_optimized(arr, pivot + 1, hi);
          quicksort_helper_optimized(arr, lo, pivot - 1); // 3
        }
    }
}
#}</code></pre></pre>
<ol>
<li>說穿了就只有這個判斷式，決定哪部分該先遞迴而已。</li>
<li>這是一個尾端呼叫，會展開。</li>
<li>這也是一個尾端呼叫。</li>
</ol>
<p>實際上，截至 2018.2，Rust Core Team 決定暫緩 TCO 的實作，目前 Rust 並沒有支援 TCO。但我們還是可以手動實作 TCO，減少 call stack。</p>
<p>我們先把原始的 lomuto partition 實作改成手動 TCO 版本。利用 <code>while</code> loop，將 <code>lo</code> 替換成下一個遞迴的引數，減少部分的 call stack。</p>
<pre><code class="language-diff">- fn quicksort_helper_manual_tco(arr: &amp;mut [i32], lo: isize, hi: isize) {
+ fn quicksort_helper_manual_tco(arr: &amp;mut [i32], mut lo: isize, mut hi: isize) {
-     if lo &lt;= hi {
+     while lo &lt; hi {
          let pivot = partition(arr, lo, hi);
          quicksort_helper(arr, lo, pivot - 1);
-         quicksort_helper(arr, pivot + 1, hi);
+         lo = pivot + 1;
      }
  }
</code></pre>
<p>再來，選擇性遞迴較小的部分。Iterative 版本的尾端呼叫消除（tail-call eliminate）就做完了！</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn quicksort_helper_manual_tco(arr: &amp;mut [i32], mut lo: isize, mut hi: isize) {
    while lo &lt; hi {
        let pivot = partition(arr, lo, hi);
        if pivot - lo &lt; hi - pivot {
            quicksort_helper_optimized(arr, lo, pivot - 1);
            lo = pivot + 1;
        } else {
            quicksort_helper_optimized(arr, pivot + 1, hi);
            hi = pivot - 1;
        }
    }
}
#}</code></pre></pre>
<a class="header" href="#a選擇-pivot-的方法" id="a選擇-pivot-的方法"><h3>選擇 Pivot 的方法</h3></a>
<p>選擇 pivot 的方法大致上有以下幾種：</p>
<ul>
<li>總是選擇最後一個元素。</li>
<li>總是選擇第一個元素。</li>
<li>選擇特定位置（如中位數）的元素。</li>
<li>隨機選擇任意元素。</li>
</ul>
<p>選擇第一個或最後一個元素會印序列已經接近排序完成或相反排序，造成 $O(n^2) $ 最壞的時間複雜度。隨機或選擇特定位置的方法較能避免這種情況，但實作上較困難。</p>
<p>除了選擇 pivot 的方法，近幾年來多 pivot（multi-pivot）Quicksort 也愈趨流行，可以減少 20% 的元素置換。相關的討論與證明可以參考<a href="https://cs.stanford.edu/%7Erishig/courses/ref/l11a.pdf">這篇文章</a>。</p>
<a class="header" href="#a對付重複的元素" id="a對付重複的元素"><h3>對付重複的元素</h3></a>
<p>若輸入序列有許多重複的元素，使用原本 Lomuto scheme 實作的 Quicksort 仍然會比較置換等於 pivot 的所有元素。3-way partition scheme 就是將序列多分出「等於 pivot」部分，減少重複置換相等元素的排序法。</p>
<pre><code>[ values &lt; pivot | values == pivot | value &gt; pivot ]
</code></pre>
<p>通常是使用著名的 <a href="https://en.wikipedia.org/wiki/Dutch_national_flag_problem">Dutch national flag algorithm</a> 來解決這個問題。實作上和 Lomuto 非常類似。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn partition(arr: &amp;mut [i32], lo: isize, hi: isize) -&gt; (isize, isize) {
    let pivot = arr[hi as usize];
    let mut i = lo;         // smaller
    let mut j = lo;         // equal
    let mut k = hi;         // large

    while j &lt;= k {
        if arr[j as usize] &lt; pivot {
            arr.swap(i as usize, j as usize);
            i += 1;
            j += 1;
        } else if arr[j as usize] &gt; pivot {
            arr.swap(k as usize, j as usize);
            k -= 1;
        } else {
            // No swap when identicial.
            j += 1;
        }
    }

    // Return smaller and larger pointer to avoid iterate duplicate elements.
    (i, k)
}
#}</code></pre></pre>
<a class="header" href="#a選擇不同的分割方案" id="a選擇不同的分割方案"><h3>選擇不同的分割方案</h3></a>
<p>不同的分割方案有著不同的應用場景，如上述的 3-way scheme 就適合重複元素多的序列。這裡再多介紹另一個常見的分割實作方案 Hoare partition，是 Quicksort 發明這 Hoare 自己提出的分割法，Rust 實作演算法如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn partition(arr: &amp;mut [i32], lo: usize, hi: usize) -&gt; usize {
    let pivot = arr[lo];
    let mut i = lo;
    let mut j = hi;

    loop {
        // Find element &gt;= pivot from leftmost element.
        while arr[i] &lt; pivot {                            // 1
            i += 1;
        }
        // Find element &lt;= pivot from rightmost element.
        while arr[j] &gt; pivot {                            // 2
            j -= 1;
        }
        if i &gt;= j {
            return j;
        }
        // Two elements are misplaced, swap them.
        arr.swap(i, j);                                   // 3
        i += 1;
        j -= 1;
    }
}
#}</code></pre></pre>
<ol>
<li>從最左邊開始找比 pivot 大或相等的元素。</li>
<li>從最右邊開始找比 pivot 小或相等的元素。</li>
<li>若找到這兩個元素，置換之，以符合小於 pivot 在前，大於 pivot 在後的分割準則。</li>
</ol>
<a class="header" href="#a參考資料-10" id="a參考資料-10"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Quicksort">Wiki: Quicksort</a></li>
<li><a href="https://algs4.cs.princeton.edu/23quicksort/">Algorithms, 4th Edition by R. Sedgewick and K. Wayne</a></li>
<li><a href="https://www.geeksforgeeks.org/quick-sort/">GeeksForGeeks: QuickSort</a></li>
<li><a href="https://github.com/raywenderlich/swift-algorithm-club/tree/master/Quicksort">Swift Algorithm Club: Quicksort</a></li>
</ul>
<a class="header" href="#a合併排序-mergesort" id="a合併排序-mergesort"><h1>合併排序 Mergesort</h1></a>
<p>Mergesort 是一個泛用且高效穩定的排序法，最佳與最差時間複雜都是 $O(n \log n) $。Mergesort 可謂著名「Divide and Conquer」手法的經典案例，先將序列分成更小的子序列（Divide），一個個排序後（Conquer），再合併已排序的子序列（Combine）。</p>
<ul>
<li><strong>高效穩定</strong>：最佳、平均，與最差時間複雜度皆為 $O(n \log n) $。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>非原地排序</strong>：除了資料本身，仍需額外花費儲存空間來排序。</li>
<li><strong>分治演算法</strong>：將主問題化作數個子問題，各個擊破。</li>
</ul>
<a class="header" href="#a步驟-8" id="a步驟-8"><h2>步驟</h2></a>
<p>Mergesort 演算法分為以下步驟：</p>
<ol>
<li><strong>Divide</strong>：將含有 n 個元素的序列分割成含有 n / 2 個子序列。</li>
<li><strong>Conquer</strong>：排序分割後的兩個子序列。</li>
<li><strong>Combine</strong>：合併排序完成的兩子序列，成為一個排好序的序列。</li>
</ol>
<p>其中，Conquer 步驟中的「排序」可以不斷遞迴 Mergesort 自身，因此需要停止遞迴的條件（base case），我們將條件設定為「子序列的長度小於 2」，因為長度為 1 的序列可視為已完成排序。</p>
<p>將 Mergesort 視覺化排序如下：</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/c/c5/Merge_sort_animation2.gif" alt="mergsort" /></p>
<a class="header" href="#a說明-7" id="a說明-7"><h2>說明</h2></a>
<p>以 ASCII diagram 圖解 Mergesort。</p>
<p>先將原始序列分割成數個長度為一的子序列。</p>
<pre><code>Split array into length 1 subarray.

    [8, 7, 1, 2, 4, 6, 5, 3]
                |
   [8, 7, 1, 2] | [4, 6, 5, 3]
                |
  [8, 7] [1, 2] | [4, 6] [5, 3]
                |
[8] [7] [1] [2] | [4] [6] [5] [3]
                V
              split
</code></pre>
<p>再將子序列依序合併成一個排好序的大序列。</p>
<pre><code>Recursively merge subarray respecting the order.

              Merge
                |
[8] [7] [1] [2] | [4] [6] [5] [3]
                |
  [7, 8] [1, 2] | [4, 6] [3, 5]
                |
   [1, 2, 7, 8] | [3, 4, 5, 6]
                V
    [1, 2, 3, 4, 5, 6, 7, 8]
</code></pre>
<a class="header" href="#a效能-10" id="a效能-10"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n \log n) $ </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $ </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n) $ auxiliary   </td></tr>
</tbody></table>
<a class="header" href="#time-complexity-2" id="time-complexity-2"><h3>Time Complexity</h3></a>
<p>透過遞迴關係式，很容易計算 Mergesort 的時間複雜度。假設排序長度為 $n $ 的序列最多需要 $T(n) $ 時間。可以觀察到，如果序列只有一個元素，Mergesort 僅需要常數時間就可以完成排序，寫成 $T(n) = 1 $。</p>
<p>如果 $n &gt; 2 $，Mergesort 會將序列分為 $\lceil \frac{n}{2} \rceil $ 部分，以及 $\lfloor \frac{n}{2} \rfloor $ 部分。我們可以將排序前者寫成 $T(\lceil \frac{n}{2} \rceil) $，而後者花費時間為 $ T(\lfloor \frac{n}{2} \rfloor) $。</p>
<p>最後，合併兩個子序列僅需 $n $ 個操作。可得下列遞迴關係式。<br />
（為了方便計算，把 floor 和 ceil 捨去）</p>
<p>$$
T(n) =
\begin{cases}
1                   &amp; \text{if } n = 1, \
2T(\frac{n}{2}) + n &amp; \text{otherwise}.
\end{cases}
$$</p>
<p>根據 <a href="master-theorem">Master Theorem</a>，可得複雜度為 $O(n \log n) $。</p>
<a class="header" href="#space-complexity-1" id="space-complexity-1"><h3>Space Complexity</h3></a>
<p>Mergesort 的缺點之一就是在合併子序列時，需要額外的空間依序插入排序資料；若是遞迴版本的 Mergesort 還需額外加上遞迴花費的 call stack 空間，因此額外空間複雜度為 $O(n) + O(\log n) = O(n) $（以陣列實作）。</p>
<a class="header" href="#a實作-9" id="a實作-9"><h2>實作</h2></a>
<p>一般來說，Divide and Conquer 有兩種設計、解決問題的技巧：Top-down（自上而下）與 Buttom-up（自下而上）。前者是先對問題有整體的輪廓概念，再逐步針對細節一一處理；後者則是先準備每個問題需要的基礎步驟與元件，再將這些步驟結合，解決整體的問題。</p>
<p>Mergesort 的實作分為兩部分：</p>
<ul>
<li><code>mergesort</code> 主程式：對外的接口，負責分割序列。對應 Divide 功能。</li>
<li><code>merge</code>：合併子序列，對應到 Conquer 與 Combine 功能。</li>
</ul>
<p>先來看看如何分割序列。</p>
<a class="header" href="#top-down-split" id="top-down-split"><h3>Top-down split</h3></a>
<p>自上而下的解法會不斷以類似 binary search 的方式找中點，進而分割序列。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn mergesort(arr: &amp;mut [i32]) {
    let mid = arr.len() / 2;
    if mid == 0 {                 // 1
        return;
    }

    mergesort(&amp;mut arr[..mid]);   // 2
    mergesort(&amp;mut arr[mid..]);

    // Create an array to store intermediate result.
    let mut ret = arr.to_vec();   // 3

    // Merge the two piles.
    merge(&amp;arr[..mid], &amp;arr[mid..], &amp;mut ret[..]);  // 4

    // Copy back the result back to original array.
    arr.copy_from_slice(&amp;ret);    // 5
}
#}</code></pre></pre>
<ol>
<li>設定遞迴的終止條件（base case），middle index 為 0 表示長度不大於 1。</li>
<li>利用 Rust 的 <a href="https://doc.rust-lang.org/std/ops/struct.Range.html">Range Operator</a>，可快速分割兩個 <code>slice</code>。</li>
<li>建立一個 <code>Vec</code> 儲存排序結果。</li>
<li>將兩個 <code>slice</code> 合併排序至 <code>ret</code> vector 中。</li>
<li>將 <code>ret</code> 的結果複製到原始 <code>arr</code> 中，使回傳值保有相同起始位址。</li>
</ol>
<a class="header" href="#buttom-up-split" id="buttom-up-split"><h3>Buttom-up split</h3></a>
<p>自下而上的解法則是預定好最小的子序列長度，直接使用 for 迴圈從頭開始逐一擊破。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn mergesort_bottom_up(arr: &amp;mut [i32]) {
    let mut width = 1;                                // 1
    // Create an array to store intermediate result.
    let mut ret = arr.to_vec();                       // 2
    let len = arr.len();

    while width &lt; len {
        let mut i = 0;
        while i &lt; len {
            // Check to avoid upper bound and middle index out of bound.
            let upper = ::std::cmp::min(i + 2 * width, len);  // 3
            let mid = ::std::cmp::min(i + width, len);

            merge(&amp;arr[i..mid], &amp;arr[mid..upper], &amp;mut ret[i..upper]);

            // Copy the merged result back to original array.
            arr[i..upper].copy_from_slice(&amp;ret[i..upper]);    // 4

            // Increase start index to merge next two subsequences.
            i += 2 * width;                           // 5
        }
        width *= 2;                                   // 6
    }
}
#}</code></pre></pre>
<ol>
<li>設定最小的子序列長度，這個長度以下的子序列皆視為已排序。</li>
<li>建立一個 <code>Vec</code> 儲存排序結果。</li>
<li>取最小值，避免下標超出邊界，並且維持除了最後一組，其他子序列長度恆為 <code>width</code>。</li>
<li>複製這部分排序結果 <code>ret</code> 到原始的 <code>arr</code> 中。</li>
<li>繼續下兩個子序列的合併步驟。</li>
<li>將下個迭代的子序列長度加倍，繼續合併。</li>
</ol>
<a class="header" href="#the-merge-part" id="the-merge-part"><h3>The merge part</h3></a>
<p>無論是 Top-down 還是 Buttom-up 版本的解法，皆免不了 <code>merge</code> 這個共同步驟，將子序列合併為較大的序列。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn merge(arr1: &amp;[i32], arr2: &amp;[i32], ret: &amp;mut [i32]) {
    let mut left = 0; // Head of left pile.             // 1
    let mut right = 0; // Head of right pile.
    let mut index = 0;

    // Compare element and insert back to result array.
    while left &lt; arr1.len() &amp;&amp; right &lt; arr2.len() {     // 2
        if arr1[left] &lt;= arr2[right] {                  // 3
            ret[index] = arr1[left];
            index += 1;
            left += 1;
        } else {
            ret[index] = arr2[right];
            index += 1;
            right += 1;
        }
    }

    // Copy the reset elements to returned array.
    // `memcpy` may be more performant than for-loop assignment.
    if left &lt; arr1.len() {                              // 4
        ret[index..].copy_from_slice(&amp;arr1[left..]);
    }
    if right &lt; arr2.len() {
        ret[index..].copy_from_slice(&amp;arr2[right..]);
    }
}
#}</code></pre></pre>
<ol>
<li>建立三個指標，分別給 <code>arr1</code>、<code>arr2</code> 與回傳陣列 <code>ret</code> 使用。</li>
<li>這部分依序比較兩個子序列，排序較小者先進入回傳 <code>ret</code>。直到其中一序列所有元素都進入 <code>ret</code> 就停止。</li>
<li>這邊判斷使用 <code>&lt;=</code> 小於等於確保排序穩定（相同鍵值順序不換）。</li>
<li>將剩餘未進入 <code>ret</code> 的元素，依序複製到 <code>ret</code> 中。</li>
</ol>
<blockquote>
<p><code>slice.copy_from_slice</code> 底層使用 C 的 <code>memcpy</code>，比起 for-loop 一個個賦值，直接複製整塊記憶體比較快了。</p>
</blockquote>
<a class="header" href="#a變形-2" id="a變形-2"><h2>變形</h2></a>
<a class="header" href="#timsort" id="timsort"><h3>Timsort</h3></a>
<p>在真實世界資料中，早有許多部分排序的分區（natural run），倘若跳過排序這些分區的步驟，就可減少許多不必要的操作，<a href="../timsort">Timsort</a> 就是為了完全利用榨乾這些分區的混合排序法。</p>
<a class="header" href="#a參考資料-11" id="a參考資料-11"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Merge_sort">Wiki: Merge sort</a></li>
<li><a href="www.cs..html">CMSC 351 Algorithms, Fall, 2011, University of Maryland.</a></li>
<li>Sorting GIF was created By CobaltBlue <a href="https://creativecommons.org/licenses/by-sa/2.5">CC BY-SA 2.5</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a混合排序" id="a混合排序"><h1>混合排序</h1></a>
<ul>
<li><a href="introsort">內省排序 Introsort</a></li>
<li><a href="timsort">自適應合併排序 Timsort</a></li>
<li><a href="pdqsort">模式消除快速排序 Pdqsort</a></li>
</ul>
<a class="header" href="#a內省排序-introsort" id="a內省排序-introsort"><h1>內省排序 Introsort</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<a class="header" href="#a自適應合併排序-timsort" id="a自適應合併排序-timsort"><h1>自適應合併排序 Timsort</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<a class="header" href="#a效能-11" id="a效能-11"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n \log n) $ </td></tr>
<tr><td> Best         </td><td> $O(n) $        </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n) $ auxiliary   </td></tr>
</tbody></table>
<a class="header" href="#a實作-10" id="a實作-10"><h2>實作</h2></a>
<a class="header" href="#a參考資料-12" id="a參考資料-12"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Timsort">Wiki: Timsort</a></li>
<li>http://blog.csdn.net/yangzhongblog/article/details/8184707</li>
<li>https://github.com/rust-lang/rust/pull/38192</li>
<li>https://github.com/python/cpython/blob/master/Objects/listsort.txt</li>
<li>https://youtu.be/uVWGZyekGos</li>
</ul>
<a class="header" href="#a模式消除快速排序-pattern-defeating-quicksort" id="a模式消除快速排序-pattern-defeating-quicksort"><h1>模式消除快速排序 Pattern-defeating Quicksort</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<ul>
<li>Unstable</li>
<li>Adopted in libcore in Rust</li>
</ul>
<a class="header" href="#a參考資料-13" id="a參考資料-13"><h2>參考資料</h2></a>
<ul>
<li>https://news.ycombinator.com/item?id=14661659</li>
<li>https://redd.it/5qa8h6</li>
<li>https://github.com/orlp/pdqsort</li>
<li>https://github.com/stjepang/pdqsort</li>
<li>https://github.com/rust-lang/rust/pull/40601</li>
</ul>
<a class="header" href="#a特殊排序" id="a特殊排序"><h1>特殊排序</h1></a>
<ul>
<li><a href="counting_sort">計數排序 Counting sort</a></li>
<li><a href="bucket_sort">桶排序 Bucket sort</a></li>
<li><a href="radix_sort">基數排序 Radix sort</a></li>
</ul>
<a class="header" href="#a計數排序-counting-sort" id="a計數排序-counting-sort"><h1>計數排序 Counting sort</h1></a>
<p><a href="https://en.wikipedia.org/wiki/Counting_sort">Counting sort</a> 是一個特殊的整數排序法，被視為 <a href="../bucket_sort">Bucket sort</a> 的特例。原理是在已知整數範圍內，計算每個鍵值出現次數，並用額外的陣列保存（Count array）。最後將 Count array 的元素值作為排序資料的新 index。</p>
<p>Counting sort 基本特性如下：</p>
<ul>
<li><strong>非原地排序</strong>：額外花費較大量、非固定的空間來排序。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>整數排序</strong>：以整數作為排序的鍵值。</li>
<li><strong>分配式排序</strong>：不透過兩兩比較，而是分析鍵值分佈來排序。特定情況下可達線性執行時間。</li>
<li><strong>線型執行時間</strong>：當輸入資料量 <strong>n</strong> 與已知範圍上下界之差值相近，執行時間接近線型（<strong>O(n)</strong>）</li>
<li><strong>預期分佈</strong>：預期輸入資料是落在已知範圍內的整數（例如 0 到 k）。</li>
<li><strong>適用範圍</strong>：僅適用於小範圍整數（額外空間需求大）。</li>
</ul>
<a class="header" href="#a步驟-9" id="a步驟-9"><h2>步驟</h2></a>
<ol>
<li><strong>Count occurrence</strong>：計算每個 key 的出現次數。</li>
<li><strong>Prefix sum as start index</strong>：計算前綴和（Prefix sum），並作為該元素的 start index。</li>
<li><strong>Copy output</strong>：利用步驟二的前綴和，遍歷輸入資料，取得元素排序後的索引。</li>
</ol>
<a class="header" href="#a說明-8" id="a說明-8"><h2>說明</h2></a>
<p>這裡有資料需要透過正整數的 key 來排序。key 的範圍在 0 - 9 之間，格式為 <code>(key, value)</code>。</p>
<pre><code>Input: (1, A) (5, B) (8, C) (2, D) (2, E) (9, F)
</code></pre>
<p><strong>1. Count occurrence</strong>：首先，先計算每個 key 的出現頻率，儲存在額外的 count array 中。</p>
<pre><code>Key  : 0 1 2 3 4 5 6 7 8 9
Count: 0 1 2 0 0 1 0 0 1 1
</code></pre>
<p><strong>2. Prefix sum as start index</strong>：再計算 prefix sum，也就是將當前 index 前累計的 key 數量加總。例如 <strong>key 5</strong> 的 prefix sum <strong>1 + 2 = 3</strong>。</p>
<p>這裡的 prefix sum 等同於每筆資料排序後的位置（index）。例如排序後，<strong>8</strong> 位於陣列第四位。</p>
<pre><code>Key       : 0 1 2 3 4 5 6 7 8 9
Prefix Sum: 0 0 1 3 3 3 4 4 4 5
</code></pre>
<p><strong>3. Copy output</strong>：透過 key 與 prefix sum 的映射關係，找到原始資料對應的位置。</p>
<p>實作上，每筆資料找到對應的 start index（prefix sum） 後，要將<strong>該 index 之值 +1</strong>，使得重複的元素可取得正確的 index offset（對唯一的 key 沒有影響）。</p>
<pre><code>(1, A)
--&gt; prefix sum 為 0，寫入 array[0]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) |        |        |        |        |        |
+--------+--------+--------+--------+--------+--------+

(5, B)
--&gt; prefix sum 為 3，寫入 array[3]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) |        |        | (5, B) |        |        |
+--------+--------+--------+--------+--------+--------+

(8, C)
--&gt; prefix sum 為 4，寫入 array[4]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) |        |        | (5, B) | (8, C) |        |
+--------+--------+--------+--------+--------+--------+

(2, D)
--&gt; prefix sum 為 2，寫入 array[4]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) | (2, D) |        | (5, B) | (8, C) |        |
+--------+--------+--------+--------+--------+--------+

(2, E)
--&gt; prefix sum 為 3（前一步驟 + 1），寫入 array[3]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) | (2, D) | (2, E) | (5, B) | (8, C) |        |
+--------+--------+--------+--------+--------+--------+

(9, F)
--&gt; prefix sum 為 5，寫入 array[5]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) | (2, D) | (2, E) | (5, B) | (8, C) | (9, F) |
+--------+--------+--------+--------+--------+--------+
</code></pre>
<p>這樣就完成排序了。此外，觀察 <strong>(2, D)</strong> 與 <strong>(2, E)</strong> 排序前後的位置，會發現 counting sort 是個實實在在的穩定排序，很棒。</p>
<a class="header" href="#a效能-12" id="a效能-12"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity      </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n + k) $ </td></tr>
<tr><td> Best         </td><td> $O(n + k) $ </td></tr>
<tr><td> Average      </td><td> $O(n + k) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n + k) $ auxiliary </td></tr>
</tbody></table>
<blockquote>
<p>k 為資料已知範圍上下界之差。</p>
</blockquote>
<a class="header" href="#time-complexity-3" id="time-complexity-3"><h3>Time Complexity</h3></a>
<p>Counting sort 沒有用到任何遞迴，可以直觀地分析複雜度。在步驟一，建立 count array 與步驟三輸出排序結果，都需要遍歷 $n $ 個輸入的資料，因此複雜度為 $O(n) $；步驟二計算 prefix sum，，以及 count array 自身的初始化則需執行 $k + 1 $ 次（給定的資料範圍），這部分的複雜度為 $O(k) $。由於 $n $ 與 $k $ 的權重會因輸入資料及實作的不同而有所改變，我們無法捨棄任何一個因子，可得知 counting sort 的複雜度為 $O(n + k) $。</p>
<a class="header" href="#space-complexity-2" id="space-complexity-2"><h3>Space complexity</h3></a>
<p>Counting sort 並非 in-place sort，排序後的結果會另外輸出為新的記憶體空間，因此 $O(n) $ 的額外（auxiliary）空間複雜度絕對免不了。再加上需要長度為 $k $ 的 count array 保存每個 key 的出現次數，因此需再加上 $O(k) $。除了原始的輸入 array，總共需花費 $O(n + k) $ 的額外空間複雜度。</p>
<blockquote>
<p>如果欲排序資料就是整數鍵值自身，可以將「計算前綴和」與「複製輸出」兩步驟最佳化，直接覆寫原始陣列，額外空間複雜度會下降至 $O(k) $，但也因此成為不穩定排序法。</p>
</blockquote>
<a class="header" href="#a實作-11" id="a實作-11"><h2>實作</h2></a>
<p>由於 Counting sort 屬於分布式排序（Distribution sort），這裡使用泛型，以彰顯分布式排序的特色。</p>
<a class="header" href="#function-signature" id="function-signature"><h3>Function Signature</h3></a>
<p>首先，我們先看函式如何宣告（function signature）。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn counting_sort&lt;F, T&gt;(arr: &amp;mut [T], min: usize, max: usize, key: F) 
    where F: Fn(&amp;T) -&gt; usize, 
          T: Clone,
#}</code></pre></pre>
<p>這裡使用了四個參數：</p>
<ul>
<li><code>arr</code>：待排序陣列。</li>
<li><code>min</code>、<code>max</code>：整數排序的上下界。</li>
<li><code>key</code>：由於資料不一定是整數，需要一個 function 從資料擷取鍵值做排</li>
</ul>
<p>另外，也使用兩個泛型型別：</p>
<ul>
<li><code>F</code>：<code>key</code> extactor 的型別，回傳的 <code>usize</code> 必須落在 <code>[min, max)</code> 之間。</li>
<li><code>T</code>：陣列元素的型別，實作 <code>Clone</code> 是由於 Counting sort 需要將 output 再複製回原本的參數 <code>arr</code> 上，達成「偽」原地排序。</li>
</ul>
<a class="header" href="#prefix-sums-array" id="prefix-sums-array"><h3>Prefix Sums Array</h3></a>
<p>再來，了解如何建立一個元素出現次數的陣列。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn counting_sort() {
    // ...

    let mut prefix_sums = {
        // 1. Initialize the count array with default value 0.
        let len = max - min;
        let mut count_arr = Vec::with_capacity(len);
        count_arr.resize(len, 0);

        // 2. Scan elements to collect counts.
        for value in arr.iter() {
            count_arr[key(value)] += 1;
        }

        // 3. Calculate prefix sum.
        count_arr.into_iter().scan(0, |state, x| {
                *state += x;
                Some(*state - x)
            }).collect::&lt;Vec&lt;usize&gt;&gt;()
    };
    // ...
}
#}</code></pre></pre>
<ol>
<li>建立一個長度為上下界之差的 count array。注意，這裡使用了 <code>Vec.resize</code>，因為 Rust initialize 空的 <code>Vec</code> 時並不會插入 0 或其他預設值。</li>
<li>遍歷整個輸入資料，利用 <code>key</code> function 取出每筆資料的鍵值，出現一次就 +1。</li>
<li>利用 Iterator 上的 <code>scan</code> method 計算每個鍵值的 prefix sum。需要注意的是，每個元素對應的 prefix sum 不包含自身，例如 key 3 的計算結果就是 1 與 2 的出現總次數，如此一來，prefix sum 才會直接對應到排序後的位置。</li>
</ol>
<a class="header" href="#prefix-sums-as-start-index" id="prefix-sums-as-start-index"><h3>Prefix Sums as Start Index</h3></a>
<p>最後一步就是將 prefix sum 當作每個 element 的正確位置，把資料重頭排序。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn counting_sort() {
    // ...

    for value in arr.to_vec().iter() {            // 1
        let index = key(value);
        arr[prefix_sums[index]] = value.clone();  // 2
        prefix_sums[index] += 1;                  // 3
    }
}
#}</code></pre></pre>
<ol>
<li>將輸入資料透過 <code>to_vec</code> 複製起來迭代，需要複製 <code>arr</code> 是因為之後要直接在 <code>arr</code> 插入新值，需要另一份原始輸入的拷貝。</li>
<li>利用 <code>key</code> 擷取鍵值後，把資料複製給 <code>arra</code> 上對應 <code>prefix_sums[index]</code> 的位置。</li>
<li>將該 <code>prefix_sums[index]</code> 的值加一，以便元素重複時，可以正常複製到下一個位置。</li>
</ol>
<p>完成了！這裡再貼一次完整的程式碼。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn counting_sort&lt;F, T&gt;(arr: &amp;mut [T], min: usize, max: usize, key: F) 
    where F: Fn(&amp;T) -&gt; usize,
          T: Clone,
{
    let mut prefix_sums = {
        // 1. Initialize the count array with default value 0.
        let len = max - min;
        let mut count_arr = Vec::with_capacity(len);
        count_arr.resize(len, 0);

        // 2. Scan elements to collect counts.
        for value in arr.iter() {
            count_arr[key(value)] += 1;
        }

        // 3. Calculate prefix sum.
        count_arr.into_iter().scan(0, |state, x| {
                *state += x;
                Some(*state - x)
            }).collect::&lt;Vec&lt;usize&gt;&gt;()
    };

    // 4. Use prefix sum as index position of output element.
    for value in arr.to_vec().iter() {
        let index = key(value);
        arr[prefix_sums[index]] = value.clone();
        prefix_sums[index] += 1;
    }
}
#}</code></pre></pre>
<a class="header" href="#a參考資料-14" id="a參考資料-14"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Counting_sort">Wiki: Counting sort</a></li>
<li><a href="http://www.growingwiththeweb.com/2014/05/counting-sort.html">Growing with the web: Counting sort</a></li>
</ul>
<a class="header" href="#a桶排序-bucket-sort" id="a桶排序-bucket-sort"><h1>桶排序 Bucket sort</h1></a>
<p><a href="https://en.wikipedia.org/wiki/Bucket_sort">Bucket sort</a>，是一個非比較排序。原理是建立一些桶子，每個桶子對應一資料區間，在將待排序資料分配到不同的桶中，桶子內部各自排序。由於並非<a href="https://en.wikipedia.org/wiki/Comparison_sort">比較排序</a>，使用 Bucket sort 需要事先知道資料的範圍與分佈，才能決定桶子對應的區間。</p>
<p>Bucket sort 基本特性如下：</p>
<ul>
<li>又稱 <strong>bin sort</strong>。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>分配式排序</strong>：不透過兩兩比較，而是分析鍵值分佈來排序。特定情況下可達線性執行時間。</li>
<li><strong>預期分佈</strong>：資料為<strong>均勻分佈</strong>。</li>
</ul>
<a class="header" href="#a步驟-10" id="a步驟-10"><h2>步驟</h2></a>
<p>假設要排序 $n $ 個元素的陣列，這些元素的值平均散落在某個<strong>已知的預期範圍內</strong>，例如 1 到 100。</p>
<ol>
<li><strong>Create buckets</strong>：建立 $k $ 個桶子（bucket）的陣列。每個桶子<strong>對應預期範圍的某區間</strong>，如第一個桶子放 1 到 10，第二個放 11 到 20。</li>
<li><strong>Scatter</strong>：將每個元素依照該值放入對應的桶子中。</li>
<li><strong>Inner sort</strong>：排序所有非空的桶子。</li>
<li><strong>Gather</strong>：依序走訪所有桶子，將桶內的元素放回原本的陣列中。</li>
</ol>
<a class="header" href="#a說明-9" id="a說明-9"><h2>說明</h2></a>
<p>以下用 ASCII diagram 視覺化解釋：</p>
<p>這裡有一些整數，落在 1 至 100 之間。我們有 $n = 10 $ 的陣列要排序。</p>
<pre><code>Original array

+-------------------------------------------------+
|  6 | 28 | 96 | 14 | 74 | 37 |  9 | 71 | 91 | 36 |
+-------------------------------------------------+
</code></pre>
<p><strong>1. Create buckets</strong>：建立一定數量的桶子，這裡我們建立與原始陣列相同數量的桶子（10）。每個桶子對應 $n - 1 * 10 $ 到 $n * 10 $ 的區間。</p>
<pre><code>Bucket array

+-------------------------------------------------+
|    |    |    |    |    |    |    |    |    |    |
+-------------------------------------------------+
  ^    ^
  |    |
  |    |
  |    holds values in range 11 to 20
  holds values in range 1 to 10
</code></pre>
<p><strong>2. Scatter</strong>：將原始陣列中的元素，放入對應的桶中。</p>
<pre><code>Bucket array

  6,9  14   28   37,36               74,71     96,91
  |    |    |    |                   |         |
+-v----v----v----v-------------------v---------v--+
|    |    |    |    |    |    |    |    |    |    |
+-------------------------------------------------+
</code></pre>
<p><strong>3. Inner sort</strong>：排序所有非空桶子中的元素，桶內排序可用任意排序法，通常選用「insertion sort」，可確保排序穩定性，並降低額外開銷。</p>
<pre><code>Bucket array

  sort sort sort sort                sort      sort
  ---  --   --   -----               -----     -----
  6,9  14   28   36,37               71,74     91,96
  |    |    |    |                   |         |
+-v----v----v----v-------------------v---------v--+
|    |    |    |    |    |    |    |    |    |    |
+-------------------------------------------------+
</code></pre>
<p><strong>4. Gather</strong>：排序完後，再將所有桶中元素依序放回原始的陣列。</p>
<pre><code>Original array
+-------------------------------------------------+
|  6 |  9 | 14 | 28 | 36 | 37 | 71 | 74 | 91 | 96 |
+-------------------------------------------------+
</code></pre>
<a class="header" href="#a效能-13" id="a效能-13"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity      </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $   </td></tr>
<tr><td> Best         </td><td> $O(n + k) $ </td></tr>
<tr><td> Average      </td><td> $O(n + k) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n + k) $ auxiliary </td></tr>
</tbody></table>
<blockquote>
<p>$k $ = 桶子的數量（number of buckets）
$n $ = 資料筆數</p>
</blockquote>
<a class="header" href="#worst-case" id="worst-case"><h3>Worst case</h3></a>
<p>Bucket sort 是一個分配式排序法，對資料分佈有既定的預期：「<strong>所有元素平均分佈在每個 bucket 的區間內</strong>」。可想而知，最差的狀況是所有元素都聚集（clustering）在同一個 bucket 中，整個 bucket sort 的會退化成單一一個 inner sort 的複雜度。而桶內排序通常選用 insertion sort（最差 $O(n^2) $），所以最差的時間複雜度為「 $O(n^2) $」。</p>
<a class="header" href="#best-case" id="best-case"><h3>Best case</h3></a>
<p>最佳的狀況則是完全符合預期的平均分佈，一個蘿蔔一個坑，每個桶內排序的最佳時間複雜度為 $O(n / k) $，再乘上桶子總數 $k $，僅需 $O(k \cdot (n / k)) = O(n) $。計算結果看起來非常合理，但實際上最佳時間複雜度為 $O(n + k) $，為什麼呢？</p>
<p>無庸置疑，桶內排序最佳時間複雜度為 $O(n / k) $，但別忘了這是省略常數項過後式子，進行符號運算時，較精確的表達是 $c_0 O(n / k) + c_1 $，對於實作層面的常數 $c_0 $ 和 $c_1 $ 則予以保留。</p>
<p>當我們乘上 $k $，試著算出總運算量時，</p>
<p>$$k \cdot (c_0(n / k) + c_1) $$</p>
<p>會得到：</p>
<p>$$ c_0n + c_1k $$</p>
<p>可以得知，整個計算與 $k $ 有關，所以需要耗時 $O(n + k) $。</p>
<p>撇開數學，我們從 pseudo code 來看。最佳情況下，將所有元素蒐集回陣列的步驟（Gather）如下：</p>
<pre><code>for (each bucket b in all k buckets)
  for (each element x in b)
    append x to the array
</code></pre>
<p>最外層的迴圈依桶子數 $k $ 而定，至少需要執行 $k $ 次，複雜度為 $O(k) $。內層的迴圈則是每個桶內的元素都會執行，而我們的資料時均勻分布，因此執行時間與元素總數 $n $ 相關，為 $O(n) $。兩者加起來就是我們所說的 $O(n + k) $ 的最佳複雜度。</p>
<p><strong>那 $k $ 究竟會是多少，影響會比 $n $ 大嗎？</strong></p>
<p>端看桶子總數而定，若桶子總數很大，比元素個數 $n $ 大得多，則桶子總數對執行時間的影響恐較劇烈，就算大多數為空桶子，仍須挨家挨戶查看是否需要執行桶內排序。</p>
<a class="header" href="#space-complexity-3" id="space-complexity-3"><h3>Space Complexity</h3></a>
<p>Bucket sort 須額外建立 $k $ 個桶子，每個桶子需要配置長度為 $n $ 的 array，因此空間複雜度為 $O(n \cdot k) $。如果以 dynamic array 實作 bucket，並考慮平攤分析（Amortized analysis），則空間複雜度降至 $O(n + k) $，這也是大多數人接受的分析結果，畢竟不會有人無聊到預先配置 $n \cdot k $ 個 empty bucket。</p>
<a class="header" href="#a實作-12" id="a實作-12"><h2>實作</h2></a>
<a class="header" href="#bucket" id="bucket"><h3>Bucket</h3></a>
<p>Bucket sort 有許多種各異的實作法，差異最大之處就是桶子 bucket 這部分。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Bucket to store elements.
struct Bucket&lt;H, T&gt; {
    hash: H,
    values: Vec&lt;T&gt;,
}

impl&lt;H, T&gt; Bucket&lt;H, T&gt; {
    /// Create a new bucket and insert its first value.
    ///
    /// * `hash` - Hash value generated by hasher param of `bucket_sort`.
    /// * `value` - Value to be put in the bucket.
    pub fn new(hash: H, value: T) -&gt; Bucket&lt;H, T&gt; {
        Bucket {
            hash: hash,
            values: vec![value],
        }
    }
}
#}</code></pre></pre>
<p>這裡的桶子實作兩個 struct fields：</p>
<ul>
<li><code>values</code>：使用 <a href="https://doc.rust-lang.org/stable/std/vec/struct.Vec.html"><code>Vec</code></a> 儲存對應範圍內的元素</li>
<li><code>hash</code>：Bucket Sort 主函式有一個 <code>hasher</code> 函式，會計算出對應各個桶子的雜湊值，因此要確保桶子的雜湊值有唯一性。</li>
</ul>
<a class="header" href="#sorting" id="sorting"><h3>Sorting</h3></a>
<p>接下來就是排序主函式。依照慣例，先看看函式的宣告（function signature）。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bucket_sort&lt;H, F, T&gt;(arr: &amp;mut [T], hasher: F)
    where H: Ord,
          F: Fn(&amp;T) -&gt; H,
          T: Ord + Clone,
#}</code></pre></pre>
<p>這個 <code>bucket_sort</code> 函式使用了不少泛型：</p>
<ul>
<li><code>H</code>：<code>hasher</code> 函式的回傳型別，用來辨識不同的桶子。</li>
<li><code>F</code>：<code>hasher</code> 函式自身，只需要一個參數 <code>&amp;T</code>，回傳一個 <code>H</code>。</li>
<li><code>T</code>：欲排序資料的型別。</li>
</ul>
<p>函式自身稍微複雜一點，但仍不脫離<a href="#%E6%AD%A5%E9%A9%9F">四步驟</a>：Create buckets、Scatter、Inner sort，還有 Gather。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bucket_sort() {
    // ...

    // 1. Create buckets.
    let mut buckets: Vec&lt;Bucket&lt;H, T&gt;&gt; = Vec::new();

    // 2. Scatter
    for value in arr.iter() {
        let hash = hasher(&amp;value); // 2.1.

        let value = value.clone();
        // 2.2.
        match buckets.binary_search_by(|bucket| bucket.hash.cmp(&amp;hash)) {
            // If exists, push the value to the bucket.
            Ok(index) =&gt; buckets[index].values.push(value),
            // If none, create and new bucket and insert value in.
            Err(index) =&gt; buckets.insert(index, Bucket::new(hash, value)),
        }
    }

    // 3. Inner sort and gather
    let ret = buckets.into_iter().flat_map(|mut bucket| {
        bucket.values.sort(); // 3.1.
        bucket.values
    }).collect::&lt;Vec&lt;T&gt;&gt;();   // 3.2.

    arr.clone_from_slice(&amp;ret); // 4 Copy to original array
}
#}</code></pre></pre>
<ol>
<li>一般來說，第一步會配置完所有桶子，但這裡實作僅建立儲存桶子們的容器 <code>buckets</code>，這是由於實作了 <code>hasher</code> 函式，元素對應桶子的邏輯交由外部決定，因此桶子不需事先配置，而是交給第二步驟時 <strong>on-the-fly</strong> 建立。</li>
<li>迭代輸入的 <code>arr</code>，將元素散佈到桶子中。
<ol>
<li>使用元素值 <code>value</code> 取得雜湊值。</li>
<li>從一堆桶子內 <code>buckets</code> 尋找對應雜湊值的桶子，如有對應桶子，則將待排序元素插入桶中；若無對應桶子，則馬上建立桶子，並插入待排序元素。</li>
</ol>
</li>
<li>由於桶子們 <code>buckets</code> 是一個二維陣列集合，我們使用 <code>flat_map</code> 將之壓平。
<ol>
<li>使用 Rust 內建 sort（Timsort 的變形）作為我們 inner sort 的實作，將桶內所有元素排好序</li>
<li>別忘了 Rust 的 Iterator 很 lazy，記得要使用 <code>collect</code> 蒐集 iterator 實作後的結果。</li>
</ol>
</li>
<li>由於要模擬 in-place 原地排序法的特性，將排序好的資料再次拷貝到 <code>arr</code> 上。這也是為什麼函式元素泛型 <code>T</code> 需要 <code>Clone</code> trait 的原因了。</li>
</ol>
<p>有關於步驟 2.2.，這部分可以用 <code>HashMap</code> 的變形 <a href="https://github.com/bluss/indexmap">IndexMap</a>（一個保存插入順序的有序 HashMap）保存雜湊值對應桶子的資訊，使得外界更容易依雜湊值找到桶子。但為了保持範例程式的簡潔，決定不引入第三方的 crate（Rust 語言第三方模組的代稱），且 <code>binary_search_by</code> 的複雜度為 $O(\log n) $，對 Bucket sort 最差複雜度並無影響。</p>
<a class="header" href="#a參考資料-15" id="a參考資料-15"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bucket_sort">Wiki: Bucket sort</a></li>
<li><a href="https://en.wikipedia.org/wiki/Amortized_analysis">Wiki: Amortized analysis</a></li>
<li><a href="https://stackoverflow.com/questions/7311415">How is the complexity of bucket sort is O(n+k) if we implement buckets using linked lists?</a></li>
<li><a href="https://codereview.stackexchange.com/questions/145113/bucket-sort-in-rust">Bucket sort in Rust</a></li>
</ul>
<a class="header" href="#a基數排序-radix-sort" id="a基數排序-radix-sort"><h1>基數排序 Radix sort</h1></a>
<p>如果你對 <a href="../counting_sort">Counting sort</a> 與 <a href="../bucket_sort">Bucket sort</a> 有認識，應該知道這兩個排序都能突破比較排序法複雜度 $O(n \log n) $ 限制的特殊排序法。<a href="https://en.wikipedia.org/wiki/Radix_sort">Radix sort</a> 同樣是個特殊的<a href="https://en.wikipedia.org/wiki/Integer_sorting">整數排序法</a>，效能同樣可達突破限制。差別在於，前兩者僅依據一個鍵值排序，而 Radix sort 則是依據多個鍵值排序。</p>
<p>舉例來說，欲排序一群範圍在 0 - 999 的整數，若以 Counting sort 排序，則需建立一個「1000 元素的陣列」來計算每個整數的出現次數；若使用以 10 為基數的 Radix sort，則僅需以個位數、十位數、百位數作為鍵值分別排序三次。通常 Radix sort 的排序副程式（Sorting subroutine）會選用 Counting sort 或 Bucket sort，而以 10 為基數的鍵值範圍僅 0 - 9，這種小範圍整數非常適合 Counting sort 作為排序副程式，節省了配置 <code>int arr[1000]</code> 的 count array 的時空間。</p>
<p>Radix sort 基本特性如下：</p>
<ul>
<li><strong>整數排序法</strong>：以整數作為排序的鍵值。</li>
<li><strong>分配式排序法</strong>：不透過兩兩比較，而是分析鍵值分佈來排序。特定情況下可達線性執行時間。</li>
<li><strong>穩定性</strong>：採用 LSD 的 Radix sort 屬穩定排序法（Stable sort）；透過優化，採用 MSD 也可以是穩定排序法。</li>
</ul>
<a class="header" href="#a步驟-11" id="a步驟-11"><h2>步驟</h2></a>
<p>常見的 Radix sort 依據整數的每個位數來排序，依照位數排序的先後順序，可分為兩種：</p>
<ul>
<li><strong>Least significant digit (LSD)</strong>：從最低有效鍵值開始排序（最小位數排到大）。</li>
<li><strong>Most significant digit (MSD)</strong>：從最高有效鍵值開始排序（最大位數排到小）。</li>
</ul>
<p>簡單的 LSD Radix sort 步驟如下：</p>
<ol>
<li><strong>LSD of each key</strong>：取得每個資料鍵值的最小位數（LSD）。</li>
<li><strong>Sorting subroutine</strong>：依據該位數大小排序資料。</li>
<li><strong>Repeating</strong>：取得下一個有效位數，並重複步驟二，至最大位數（MSD）為止。</li>
</ol>
<p>而 MSD Radix sort 的步驟相似，但取得資料鍵值的方向相反。</p>
<ol>
<li><strong>MSD of each key</strong>：取得每個資料鍵值的最大位數（MSD）。</li>
<li><strong>Sorting subroutine</strong>：依據該位數大小排序資料。</li>
<li><strong>Repeating</strong>：取得下一個有效位數，並重複步驟二，至最小位數（LSD）為止。</li>
</ol>
<blockquote>
<p>由於 MSD Radix sort 先排序最大位數，會出現 <strong>8 &gt; 126</strong> 的結果，這種順序通常稱為 <a href="https://en.wikipedia.org/wiki/Lexicographical_order">Lexicographical order</a>，有如字典一般，越前面的字母排序權重越重，也因此，基本版的 MSD Radix sort 並非穩定排序法。</p>
</blockquote>
<a class="header" href="#a說明-10" id="a說明-10"><h2>說明</h2></a>
<p>我們選用 LSD Radix sort 示範，並且為了增加可讀性，將基數設為 10。需注意在現實場景中，有時使用 bytes 作為基數可能更適合。</p>
<p>待排序的數列如下。</p>
<pre><code>[170, 45, 75, 90, 802, 2, 24, 66]
</code></pre>
<blockquote>
<p>Radix sort 的排序副程式，通常選用 counting sort 或 bucket sort，因此，開始排序前，需建立供其使用的 buckets（或 count array）。這屬於其他排序法的範疇，有興趣可看 <a href="../counting_sort">Counting sort</a> 或 <a href="../bucket_sort">Bucket sort</a>。</p>
</blockquote>
<p>首先，從最小位數開始排序。
注意，同樣鍵值的資料，相對位置不會改變（穩定排序）。</p>
<pre><code>   0   5   5   0    2  2   4   6
   _   _   _   _    _  _   _   _
[170, 45, 75, 90, 802, 2, 24, 66]

sort by rightmost digit --&gt;

   0   0    2  2   4   5   5   6
   _   _    _  _   _   _   _   _
[170, 90, 802, 2, 24, 45, 75, 66]
</code></pre>
<p>再來，對下一個位數排序資料。位數不足的資料，予以補 0。</p>
<pre><code>  7   9    0   0  2   4   7   6
  _   _    _      _   _   _   _
[170, 90, 802, 2, 24, 45, 75, 66]

sort by next digit --&gt;

  0   0  2   4   6    7   7   9
  _      _   _   _    _   _   _
[802, 2, 24, 45, 66, 170, 75, 90]
</code></pre>
<p>最終，對最後一個位數進行排序。大功告成！</p>
<pre><code> 8    0  0   0   0   1    0   0
 _                   _
[802, 2, 24, 45, 66, 170, 75, 90]

sort by leftmost digit --&gt;

 0  0   0   0   0   0   1    8
                        _    _
[2, 24, 45, 66, 75, 90, 170, 802]
</code></pre>
<a class="header" href="#a效能-14" id="a效能-14"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity   </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(dn) $ </td></tr>
<tr><td> Best         </td><td> $O(dn) $ </td></tr>
<tr><td> Average      </td><td> $O(dn) $ </td></tr>
<tr><td> Worst space  </td><td> $O(d + n) $ auxiliary </td></tr>
</tbody></table>
<blockquote>
<p>$n $：資料筆數。<br />
$d $：number of digit，資料中最多有幾個位數（或鍵值）。<br />
$k $：基數，就是一個位數最多有幾種可能的值。</p>
</blockquote>
<a class="header" href="#time-complexity-4" id="time-complexity-4"><h3>Time complexity</h3></a>
<p>欲分析 Radix sort 的時間複雜度，我們可以逐一擊破，先從排序副程式開始分析。</p>
<p>Radix sort 的 subroutine 通常採用 Counting sort 或 Bucket sort，因此每個 subroutine 的複雜度為 $O(n + k) $， $k $ 為 key 的範圍，以 10 為基數，就是 0 - 9 之間 $k = 10 $。</p>
<p>再來，我們分析整個主程式，Radix sort 每個位數各需排序一次，若最多位數的資料有 $d $ 位數，時間複雜度需乘上 $d $，為 $O(d (n + k)) $，那這個 $k $ 是否可以捨去呢？</p>
<p>分析 Counting sort 或 Bucket sort 時，範圍 $k $ 會隨輸入資料而變化，若 $k $ 過大，對複雜度的影響甚至會超過 $n $，因此分析複雜度時無法將 $k $ 捨去。而在 Radix sort， $k $ 通常為一個已知的常數，例如以 bytes 為基數 $k = 8 $， $k $ 可以捨去。最後可得 Radix sort 的時間複雜度為 $O(d \cdot n) $。</p>
<a class="header" href="#space-complexity-4" id="space-complexity-4"><h3>Space complexity</h3></a>
<p>Radix sort 的空間複雜度同樣取決於排序副程式，Counting sort 與 Bucket sort 的空間複雜度皆為 $O(n \cdot k) $。Radix sort 的 $k $ 是常數，予以捨去。再乘上 $d $ 個位數，最差的空間複雜度為 $O(d \cdot n) $。</p>
<a class="header" href="#a實作-13" id="a實作-13"><h2>實作</h2></a>
<p>這裡示範實作以 10 為基數，用來排序非負整數的 Radix sort。</p>
<p>首先，我們的排序副程式使用 Counting sort。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// 0. Include counting sort.
use ::sorting::counting_sort;
#}</code></pre></pre>
<p>再來，就是 Radix sort 本體了。為了凸顯 Radix sort 的概念，簡化了函式參數數量，除去泛型宣告，並將基數選擇寫死在函式裡。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn radix_sort(arr: &amp;mut [i32]) {
    let radix = 10;             // 1
    let mut digit = 1;          // 2
    let max_value = arr         // 3
      .iter()
      .max()
      .unwrap_or(&amp;0)
      .clone();
    while digit &lt;= max_value {  // 4
        counting_sort(arr, 0, 9, |t| (t / digit % radix) as usize); // 5
        digit *= radix;         // 6
    }
}
#}</code></pre></pre>
<ol>
<li>設定基數為 10。</li>
<li>設定一個旗標，記錄當前在排序哪一位數，1 表示從最小位數（個位數）開始。</li>
<li>先找到輸入資料的最大值，作為之後副程式迴圈結束的條件。尋找最大值的複雜度為 $O(n)$，因此不影響 Radix Sort 的複雜度。如果 <code>arr</code> 為空序列，則最大值設為 0，在第四步驟就會自動結束排序。</li>
<li>判斷當前排序的位數是否大於最大值，例如當前排序百分位，<code>digit</code> 為 <code>100</code>，而最大值 <code>x</code> 為 26，則不需再排序百分位。</li>
<li>使用 Counting sort 作為排序副程式，只需要有 0 - 9 十個桶子。而 <code>key</code> 參數則取出當前欲比較的位數。</li>
<li>位數乘上基數，移至下一個位數繼續比較。</li>
</ol>
<blockquote>
<p>小提醒：這是簡單又容易理解的實作，相對有許多額外的運算開銷（例如尋找最大值）。實務上，會在對資料有些了解才採用 Radix sort，因此實作並不會這麼 naive。</p>
</blockquote>
<a class="header" href="#a參考資料-16" id="a參考資料-16"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Radix_sort">Wiki: Radix sort</a></li>
<li><a href="https://www.cs.princeton.edu/%7Ers/AlgsDS07/18RadixSort.pdf">Princeton University DSA Course: Radix sort</a></li>
<li><a href="https://www.byvoid.com/zht/blog/sort-radix">ByVoid: 三種線性排序算法 計數排序、桶排序與基數排序</a></li>
</ul>
<a class="header" href="#data-structures" id="data-structures"><h1>Data Structures</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<a class="header" href="#a堆疊與佇列-1" id="a堆疊與佇列-1"><h1>堆疊與佇列</h1></a>
<ul>
<li><a href="stack">🚧 堆疊 Stack</a></li>
<li><a href="queue">🚧 佇列 Queue</a></li>
<li><a href="deque">🚧 雙端佇列 Deque</a></li>
</ul>
<a class="header" href="#a堆疊-stack" id="a堆疊-stack"><h1>堆疊 Stack</h1></a>
<a class="header" href="#a參考資料-17" id="a參考資料-17"><h2>參考資料</h2></a>
<a class="header" href="#a佇列-queue" id="a佇列-queue"><h1>佇列 Queue</h1></a>
<a class="header" href="#a參考資料-18" id="a參考資料-18"><h2>參考資料</h2></a>
<a class="header" href="#a雙端佇列-deque" id="a雙端佇列-deque"><h1>雙端佇列 Deque</h1></a>
<a class="header" href="#a參考資料-19" id="a參考資料-19"><h2>參考資料</h2></a>
<a class="header" href="#a鏈結串列-linked-list" id="a鏈結串列-linked-list"><h1>鏈結串列 Linked list</h1></a>
<p>鏈結串列是一種基本線性資料集合，每一個資料元素都是獨立的物件。儲存資料的方式和一般陣列配置連續物理記憶體空間不同，而是在各節點儲存額外的指標指向下一個節點。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Singly-linked-list.svg/612px-Singly-linked-list.svg.png" alt="" /></p>
<p><em>(單向鏈結串列示意圖）</em></p>
<a class="header" href="#a特性" id="a特性"><h2>特性</h2></a>
<p>鏈結串列有以下特性與優點：</p>
<ul>
<li>不需事先知道資料型別大小，充分利用動態記憶體管理。</li>
<li>以常數時間插入／刪除，不需重新配置記憶體（reallocation）。</li>
<li>不同的串列若有資料相同時，可以共享節點或資料，節省空間。</li>
</ul>
<p>但也因動態配置記憶體等因素，連帶產生一些缺陷：</p>
<ul>
<li><strong>空間開銷大</strong>：每個元素需儲存額外的指標空間。</li>
<li><strong>較差的 CPU 快取</strong>：不連續存取的特性，不利於 <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU 快取</a>。</li>
<li><strong>不允許隨機存取（random access）</strong>：搜尋特定索引下的節點仍需線性時間。</li>
</ul>
<a class="header" href="#a適用場景" id="a適用場景"><h2>適用場景</h2></a>
<p>大多數的場景其實不太常使用鏈結串列，Rust 內建的 <a href="https://doc.rust-lang.org/std/collections/struct.LinkedList.html"><code>LinkedList</code></a> 文件也建議，除非肯定要用鏈結串列，不然建議優先考慮其他類似的資料結構如 <a href="https://doc.rust-lang.org/std/collections/vec_deque/struct.VecDeque.html"><code>VecDeque</code></a>。話雖如此，鏈結串列仍有不少應用場景：</p>
<ul>
<li>需要頻繁地插入與刪除資料。</li>
<li>需要頻繁分離與合併（split and merge）資料。</li>
<li>不需要隨機存取的資料。</li>
<li>遞迴友好，因此成為大多函數式語言中基本資料型別之一。</li>
<li>教學上，常用於實作抽象資料型別，如<a href="../stack">堆疊</a>與<a href="../queue">佇列</a>等等。</li>
</ul>
<a class="header" href="#a術語" id="a術語"><h2>術語</h2></a>
<a class="header" href="#node" id="node"><h3>Node</h3></a>
<p>又稱「節點」，為組成鏈結串列的基本元素，節點包含資料儲存區與指標儲存區，指標儲存區用以儲存指向其他節點位址的變數。此外，最後一個節點的不指向其他節點位址的指標成為 null pointer，慣例以 NULL 表示。</p>
<p><img src="../singly_linked_list/node-box.svg" alt="node-box" /></p>
<p><em>（節點示意圖）</em></p>
<a class="header" href="#head-and-tail" id="head-and-tail"><h3>Head and tail</h3></a>
<p>Head 為指向整個串列第一個節點的指標。而 tail 則為指向最後一個節點的指標。用 ASCII 圖表示如下：</p>
<pre><code>   head                      tail
    |                         |
    v                         v
+--------+   +--------+   +--------+
|        |   |        |   |        |
| node 0 |--&gt;| node 1 |--&gt;| node 2 |--&gt; NULL
|        |   |        |   |        |
+--------+   +--------+   +--------+
</code></pre>
<a class="header" href="#sentinel-node" id="sentinel-node"><h3>Sentinel node</h3></a>
<p>Sentinal node 一個特殊的節點，資料值為 NULL 的節點，用意代表鏈結串列的端點。也就是說，sentinel node 指向串列第一個節點，而串列最後一個節點也會指向 sentinel node，就像哨兵一樣守著串列前後，因而得名。</p>
<p>實作鏈結串列時，常常因為判斷節點是否為 NULL 而讓程式變得複雜，而 sentinel node 可減少程式操作步驟，也能增加程式可讀性。詳細資訊可以參考這篇 <a href="https://stackoverflow.com/questions/5384358/">NULL 與 sentinel node 的比較討論</a>。</p>
<pre><code>    +-----------------------------------------------+
    |                                               |
    v                                               |
+---------+   +--------+   +--------+   +--------+  |
|sentinel |   |        |   |        |   |        |  |
|         |--&gt;| node 0 |--&gt;| node 1 |--&gt;| node 3 |--+
|  node   |   |        |   |        |   |        |
+---------+   +--------+   +--------+   +--------+
</code></pre>
<a class="header" href="#a種類" id="a種類"><h2>種類</h2></a>
<p>依據每個節點的鏈結多寡，可分為</p>
<p><a href="../singly_linked_list">單向鏈結串列</a>，每個節點只有一個指標，指向下一個節點。</p>
<pre><code>+--------+   +--------+   +--------+
|        |   |        |   |        |
| node 0 |--&gt;| node 1 |--&gt;| node 2 |--&gt; NULL
|        |   |        |   |        |
+--------+   +--------+   +--------+
</code></pre>
<p><a href="../doubly_linked_list">雙向鏈結串列</a>，每個節點有兩個指標，分別指向前後一個節點。</p>
<pre><code>        +--------+   +--------+   +--------+
        |        |--&gt;|        |--&gt;|        |--&gt; NULL
        | node 0 |   | node 1 |   | node 2 |
NULL &lt;--|        |&lt;--|        |&lt;--|        |
        +--------+   +--------+   +--------+
</code></pre>
<p>倘若該鏈結串列末端節點的指標指向第一個的節點，形成一個循環，則稱之為「<a href="../circular_linked_list">循環鏈結串列</a>」。</p>
<pre><code>Singly linked list as circular

+-----------------------------------------+
|                                         |
|   +--------+   +--------+   +--------+  |
|   |        |   |        |   |        |  |
+--&gt;| node 0 |--&gt;| node 1 |--&gt;| node 3 |--+
    |        |   |        |   |        |
    +--------+   +--------+   +--------+
</code></pre>
<p>詳細說明與實作請點選各個連結。</p>
<a class="header" href="#a參考資料-20" id="a參考資料-20"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Linked_list">Wiki: Linked list</a></li>
<li>Singly linked list SVG By Lasindi [Public domain], via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a單向鏈結串列-singly-linked-list" id="a單向鏈結串列-singly-linked-list"><h1>單向鏈結串列 Singly linked list</h1></a>
<p>單向鏈結串列是鏈結串列家族中最簡單的版本，特色是每兩個節點間只有一個單向的鏈結。</p>
<pre><code>   head
    |
    v
+--------+   +--------+   +--------+
|        |   |        |   |        |
| node 0 |--&gt;| node 1 |--&gt;| node 2 |--&gt; NULL
|        |   |        |   |        |
+--------+   +--------+   +--------+
</code></pre>
<a class="header" href="#a架構設計" id="a架構設計"><h2>架構設計</h2></a>
<a class="header" href="#node-1" id="node-1"><h3>Node</h3></a>
<p>先建立最基本的節點 Node。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// cannot compile
struct Node&lt;T&gt; {
    elem: T,
    next: Node&lt;T&gt;,
}
#}</code></pre></pre>
<p><code>Node.elem</code> 很直觀地儲存實際資料。而 <code>Node.next</code> 則是指向下個 Node。但這樣編譯不會成功，Rust 編譯時需要決定每個型別該配置多少記憶體空間，這種遞迴型別使得編譯器無限循環，無法決定配置大小。</p>
<p><img src="node-recursive.svg" alt="node-recursive" /></p>
<p>很簡單，我們使用 <a href="https://doc.rust-lang.org/std/boxed/index.html"><code>Box&lt;T&gt;</code></a> 這個<a href="https://doc.rust-lang.org/stable/book/2018-edition/ch15-00-smart-pointers.html">智慧指標</a>，直接將 Node 配置在記憶體 heap 上。如此以來，編譯器就會知道 <code>next</code> 只佔了一個指標的空間。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct Node&lt;T&gt; {
    elem: T,
    next: Box&lt;Node&lt;T&gt;&gt;,
}
#}</code></pre></pre>
<p><img src="node-box.svg" alt="node-box" /></p>
<p>由於 Rust 沒有 null pointer，但照鏈結串列的定義，<code>Node.next</code> 可以是 NULL，因此我們使用 <a href="https://doc.rust-lang.org/std/option/index.html"><code>Option&lt;T&gt;</code></a> 模擬 null pointer 的行為。最後，Node 的定義如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct Node&lt;T&gt; {
    elem: T,
    next: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;,
}
#}</code></pre></pre>
<a class="header" href="#singlylinkedlist" id="singlylinkedlist"><h3>SinglyLinkedList</h3></a>
<p>在開始實作各種增刪節點的操作之前，我們需要建立一個 struct 存放指向鏈結串列 head 的指標，同時，各種操作也會實作在這個 struct 上。事實上，這個 struct 就是對外公開的資料結構。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct SinglyLinkedList&lt;T&gt; {
    head: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;,
}
#}</code></pre></pre>
<p>選擇把操作串列的函式寫在另一個 struct 而非 Node 上有幾個原因，1）外部並不需知道串列內部如何實作，公開 Node 會暴露實作。2）每個 Node 都帶有成員函式的話，函式指標會佔用太多額外資源。</p>
<a class="header" href="#a基本操作" id="a基本操作"><h2>基本操作</h2></a>
<p>串列的基本操作如下：</p>
<ul>
<li><code>new</code>：初始化一個空串列。</li>
<li><code>push_front</code>：新增節點到開頭的位置。</li>
<li><code>pop_front</code>：將開頭第一個節點移除。</li>
<li><code>insert_after</code>：在指定索引位置後插入一個新節點。</li>
<li><code>remove</code>：移除任意索引下的節點。</li>
<li><code>clear</code>：清除所有節點。</li>
<li><code>is_empty</code>：檢查串列是否沒有任何節點。</li>
<li><code>reverse</code>：反轉整個串列（head 變成 tail）。</li>
</ul>
<a class="header" href="#a初始化與清除資料" id="a初始化與清除資料"><h3>初始化與清除資料</h3></a>
<p>實做初始化與清除資料非常直觀。其中清除其實就只是將 <code>self</code> 指向新的串列實例。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T&gt; SinglyLinkedList&lt;T&gt; {
    pub fn new() -&gt; Self {
        Self { head: None }
    }

    pub fn clear(&amp;mut self) {
        *self = Self::new();
    }
}
#}</code></pre></pre>
<p>你可能會想，在清除所有資料時，資源需不需要手動釋放？</p>
<p>和 C++ 的 RAII 一樣，Rust 有一個名叫 <code>drop</code> 的解構式，只要程式執行離開了資源擁有者的可視範圍（out of scope），就會自動呼叫 <code>drop</code>。我們在 <a href="#drop-trait">Drop trait</a> 一節會再深入探討。</p>
<a class="header" href="#a增刪首個節點" id="a增刪首個節點"><h3>增刪首個節點</h3></a>
<p>單向鏈結串列在第一個節點前增加新節點，或是刪除第一個節點，都可以在常數時間完成。新增節點 <code>push_front</code> 的概念很簡單，1）建立新的節點，並把新節點 <code>next</code> 指標指向串列第一個節點。2）把串列的 head 指向新建立的節點。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn push_front(&amp;mut self, elem: T) {
    let next = self.head.take(); // 1
    self.head = Some(Box::new(Node { elem, next })); // 2
}
#}</code></pre></pre>
<ol>
<li>釋放 SinglyLinkedList 對第一個節點的所有權</li>
<li>建立一新節點，並將原本第一個節點所有權轉移給新節點。再將新節點所有權轉移到串列本身。</li>
</ol>
<p>刪除第一個節點 <code>pop_front</code> 的實作步驟如下：首先取得第一個節點的所有權，再將 head 指向第一個節點 <code>Node.next</code> 下一個節點，再返回第一個節點的資料給呼叫端。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn pop_front(&amp;mut self) -&gt; Option&lt;T&gt; {
    let head = self.head.take(); // 1
    match head {
        Some(node) =&gt; {
            self.head = node.next;  // 2
            Some(node.elem)         // 3
        }
        None =&gt; None,
    }
}
#}</code></pre></pre>
<ol>
<li>取得第一個元素的所有權。</li>
<li>將 head 指向下一個節點。</li>
<li>返回即將刪除節點的資料。</li>
</ol>
<a class="header" href="#a插入刪除任意節點" id="a插入刪除任意節點"><h3>插入刪除任意節點</h3></a>
<p>鏈結串列新增和刪除第一個節點都可以在 $O(1)$ 時間內做完，那為什麼插入刪除任意節點沒有辦法呢？原因是鏈結串列不支援隨機存取（random access），就是無法透過索引在常數時間內取得資料，每次的搜尋都只能從 head 開始。因此，當我們需要在某個索引的節點後新增一筆資料，我們會需要最差 $O(n)$ 的複雜度。</p>
<p>實作插入 <code>insert_after</code> 分為幾個步驟：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn insert_after(&amp;mut self, pos: usize, elem: T) -&gt; Result&lt;(), usize&gt; {
    let mut curr = &amp;mut self.head;
    let mut pos_ = pos;

    while pos_ &gt; 0 {                        // 1
        curr = match curr.as_mut() {
            Some(node) =&gt; &amp;mut node.next,
            None =&gt; return Err(pos - pos_),
        };
        pos_ -= 1;
    }

    match curr.take() {                     // 2
        Some(mut node) =&gt; {   // Node A
            let new_node = Box::new(Node {  // 3: Node B
                elem,
                next: node.next,
            });
            node.next = Some(new_node);     // 4
            *curr = Some(node);             // 5
        }
        None =&gt; return Err(pos - pos_)
    }
    Ok(())
}
#}</code></pre></pre>
<ol>
<li>找到對應索引值的節點 A，若找不到則回傳這個串列的資料長度。</li>
<li>先取得節點 A 的所有權，才能修改它的值。</li>
<li>建立新節點 B，同時將節點 B 的 <code>next</code> 指向 A 的後一個節點。</li>
<li>將新節點 B 做為節點 A 後一個節點 <code>next</code>。</li>
<li>把修改過的節點 A，重新賦值給指向節點 A 的指標 <code>curr</code>（可視為歸還所有權）。</li>
</ol>
<p>而實作刪除任意索引下的節點 <code>remove</code> 和插入非常相似。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn remove(&amp;mut self, pos: usize) -&gt; Option&lt;T&gt; {
    let mut curr = &amp;mut self.head;
    let mut pos = pos;

    while pos &gt; 0 {                // 1
        curr = match curr.as_mut() {
            Some(node) =&gt; &amp;mut node.next,
            None =&gt; return None,
        };
        pos -= 1;
    }

    match curr.take() {            // 2
        Some(node) =&gt; { // Node A
            *curr = node.next;     // 3: node.next is Node B
            Some(node.elem)        // 4
        }
        None =&gt; None
    }
}
#}</code></pre></pre>
<ol>
<li>找到對應索引值的節點 A，若找不到則回傳 <code>None</code>。</li>
<li>先取得節點 A 的所有權，才能修改它的值。</li>
<li>把節點 A 的後一個節點 B 賦值給原本指向節點 A 的指標 <code>curr</code>。</li>
<li>回傳節點 A 的值。</li>
</ol>
<a class="header" href="#a反轉" id="a反轉"><h3>反轉</h3></a>
<p>反轉鏈結串列是工作面試時很常見的考題，這裡來實作看看。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn reverse(&amp;mut self) {
    let mut prev = None;              // 1: prev -&gt; Node P
    let mut curr = self.head.take();  // 2
    while let Some(mut node) = curr { // 3: node -&gt; Node A
        let next = node.next;         // 3-1: next -&gt; Node B
        node.next = prev.take();      // 3-2
        prev = Some(node);            // 3-3
        curr = next;                  // 3-4
    }
    self.head = prev.take(); // 4
}
#}</code></pre></pre>
<ol>
<li>先建立一個暫時變數 <code>prev</code>，儲存迭代時的前一個節點。</li>
<li>從串列 head 取得第一個節點的所有權。</li>
<li>依序迭代整個串列
<ol>
<li>將節點 A 的後一個節點 B 暫存起來。</li>
<li>節點 A 的 <code>next</code> 指向暫存在變數 <code>prev</code> 的節點 P。</li>
<li>節點 A 暫存在變數 <code>prev</code> 內，保留到下一個迭代使用。</li>
<li>將節點 B 儲存在變數 <code>curr</code> 內。此時<br />
<code>prev</code>：節點 A，A 的 <code>next</code> 指向 P，<br />
<code>curr</code>：節點 B，B 的 <code>next</code> 指向 A。</li>
</ol>
</li>
<li>最後一次迭代時，變數 <code>prev</code> 會儲存原始串列末端節點，這時轉移所有權到 head，完成反轉。</li>
</ol>
<a class="header" href="#traits" id="traits"><h2>Traits</h2></a>
<p>除了基本操作，<code>SinglyLinkedList</code> 實作了許多 trait，使用上更方便更符合 Rust 的慣例。</p>
<a class="header" href="#drop-trait" id="drop-trait"><h3>Drop trait</h3></a>
<p>如果一個 struct 有許多成員，則會遞迴呼叫 struct 的 <code>drop</code> 成員函式。因此，一個串列的解構式很可能發生深層的巢狀遞迴：</p>
<pre><code># a linked list
a -&gt; b -&gt; c -&gt; x -&gt; y -&gt; z

# call stack when `drop` being called

(a.drop
  (b.drop
    (c.drop
      (x.drop
        (y.drop
          (z.drop
          (z.dropped
        (y.dropped
      (x.dropped
    (c.dropped
  (b.dropped
(a.dropped
</code></pre>
<p>如果節點一多，肯定會 stack overflow，太可怕了！</p>
<p>既然如此，那麼就透過 <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html">Drop trait</a>，實作一個迭代版本的解構式，消弭可怕的 call stack 吧。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T&gt; Drop for SinglyLinkedList&lt;T&gt; {
    fn drop(&amp;mut self) {
        let mut link = self.head.take();  // 1
        while let Some(mut node) = link { // 2
            link = node.next.take();      // 3
        }                                 // 4
    }
}
#}</code></pre></pre>
<ol>
<li>取得 head 的所有權。</li>
<li>透過 pattern matching 取得 Node 裡面 Box 的所有權。</li>
<li>取得下一個 Node 的所有權，並將它指向共用的變數 <code>link</code>。</li>
<li>離開了 <code>node</code> 的 scope，<code>node</code> 呼叫 <code>drop</code> 釋放自身資源。</li>
</ol>
<blockquote>
<p>詳細思路過程可查看 Learning Rust With Entirely Too Many Linked Lists 的 <a href="http://cglab.ca/%7Eabeinges/blah/too-many-lists/book/first-drop.html">Drop</a> 章節，該章完整闡述為什麼不能用 tail recursive 來實作，但最大的原因是 Rust core team 暫時延緩實踐 <a href="https://github.com/rust-lang/rfcs/pull/1888">tail call optimization</a>。</p>
</blockquote>
<a class="header" href="#iterator-and-intoiterator-traits" id="iterator-and-intoiterator-traits"><h3>Iterator and IntoIterator traits</h3></a>
<p>既然鏈結串列是一種序列（sequence，有序的資料結構），少不了實作 <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html">Iterator</a>、<a href="https://doc.rust-lang.org/std/iter/trait.IntoIterator.html">IntoIterator</a> 等 trait，使串列可以輕鬆使用 for-in loop 遍歷（traverse）。</p>
<p>首先，先定義幾個迭代器的 struct。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct IntoIter&lt;T&gt;(SinglyLinkedList&lt;T&gt;);

pub struct Iter&lt;'a, T: 'a&gt; {
    next: Option&lt;&amp;'a Node&lt;T&gt;&gt;,
}

pub struct IterMut&lt;'a, T: 'a&gt; {
    next: Option&lt;&amp;'a mut Node&lt;T&gt;&gt;,
}
#}</code></pre></pre>
<p>建立這三個 iterator struct 是常見的 Rust 設計模式。</p>
<ul>
<li><code>IntoIter</code>：產生 <code>T</code>，實作會吃掉元素所有權的 <code>IntoIterator</code> trait</li>
<li><code>Iter</code>：產生 <code>&amp;T</code>，實作提供 immutable borrow 的 <code>Iterator</code> trait。</li>
<li><code>IterMut</code>：產生 <code>&amp;mut T</code>，實作提供 mutable borrow 的 <code>Iterator</code> trait。</li>
</ul>
<p>相對應的，<code>SinglyLinkedList</code> 則新增三個成員函式：</p>
<ul>
<li><code>fn into_iter(self) -&gt; IntoIter&lt;T&gt;</code>：轉移所有權的迭代器。<em>Into</em> 一詞慣例上指涉所有權移轉。</li>
<li><code>fn iter(&amp;self) -&gt; Iter&lt;T&gt;</code>：以 immutable reference 迭代串列。</li>
<li><code>fn iter_mut(&amp;mut self) -&gt; IterMut&lt;T&gt;</code>：以 mutable reference 迭代串列。</li>
</ul>
<p>先來看 <code>IntoIter</code> 實作。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct IntoIter&lt;T&gt;(SinglyLinkedList&lt;T&gt;);      // 1

impl&lt;T&gt; Iterator for IntoIter&lt;T&gt; {                // 2
    type Item = T;
    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        self.0.pop_front()
    }
}

impl&lt;T&gt; IntoIterator for SinglyLinkedList&lt;T&gt; {    // 3
    type Item = T;
    type IntoIter = IntoIter&lt;T&gt;;
    fn into_iter(self) -&gt; Self::IntoIter {
        IntoIter(self)
    }
}
#}</code></pre></pre>
<ol>
<li>宣告一個 tuple struct，唯一的成員是 <code>SinglyLinkedList</code>。</li>
<li>實作 <code>Iterator</code> trait 的 required method <code>next</code>，為了達成 <em>Into</em> 會消耗原始資料，轉換所有權的特性，我們利用 <code>pop_front()</code> 將節點的資料依序刪除（pop）。</li>
<li><code>IntoInterator</code> 的 required method 傳遞 <code>self</code> 進來，所以無論怎麼實作 <code>IntoIter</code> struct，呼叫 <code>into_iter()</code> 後，外部就無法再次存取此 <code>SinglyLinkedList</code> 實例，達到所有權轉移的目標。</li>
</ol>
<blockquote>
<p>可能有人會疑惑，<code>IntoIter</code> 並沒有內部狀態記錄欄位，迭代器如何依據狀態產生下一筆資料？受惠於 <code>IntoIterator</code> 傳遞所有權的特性，<code>IntoIter</code> 可直接改變原始串列的內部狀態，例如 <code>pop_front</code> 會移除原始串列的節點。因此，相較於 <code>Iter</code>、<code>IterMut</code> 額外記錄狀態，<code>IntoIter</code> 不需自行記錄迭代器的迭代狀態。</p>
</blockquote>
<p>再來看看 <code>Iter</code> 怎麼實踐。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct Iter&lt;'a, T: 'a&gt; {                    // 1
    next: Option&lt;&amp;'a Node&lt;T&gt;&gt;,
}

impl&lt;T&gt; Iterator for Iter&lt;'a, T&gt; {
    type Item = &amp;'a T;                          // 2
    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        match self.next {
            Some(node) =&gt; {
                self.next = node.next.as_ref().map(|node| &amp;**node); // 3, 4
                Some(&amp;node.elem)
            }
            None =&gt; None,
        }
    }
}

impl&lt;T&gt; SinglyLinkedList&lt;T&gt; {
    // ...

    pub fn iter(&amp;self) -&gt; Iter&lt;T&gt; {             // 5
        Iter { next: self.head.as_ref().map(|node| &amp;**node) } // 6
    }
}
#}</code></pre></pre>
<ol>
<li>這個 struct 的 <code>next</code> 是為了儲存 <code>Node</code> 資訊，方便記錄迭代器當前的狀態。加上生命週期 <code>'a</code> 是因編譯器無法推敲 <code>Option&lt;&amp;Node&lt;T&gt;&gt;</code> 會活多久，需要顯著標明 <code>&amp;Node</code> 至少與該迭代器同生共死。</li>
<li>由於 <code>Iter</code> 是為了實作產生 <code>&amp;T</code> 的迭代器，associated type 設為  <code>&amp;'a T</code>。</li>
<li>將當前節點的後一個節點設為 <code>Iter</code> 迭代器的狀態。並回傳當前節點的資料。<br />
這邊用了 <code>as_ref()</code> 肇因於 <code>Option.map</code> 的泛型型別與 <code>Option&lt;T&gt;</code> 一樣，所以會產生所有權轉移至 <code>map</code> 的 <code>FnOnce</code> 內部。<code>as_ref()</code> 將 <code>Option&lt;T&gt;</code> 轉換成 <code>Option&lt;&amp;T&gt;</code>，<code>map</code> 就不會發生所有權的問題。</li>
<li>此外，<code>map</code> 連續使用兩個 deref 與一個轉為 reference 的操作，是將型別以下列順序轉換。
<ul>
<li><code>Option&lt;&amp;Box&lt;Node&lt;T&gt;&gt;&gt;</code> → <code>map</code></li>
<li>→ <code>&amp;Box&lt;Node&lt;T&gt;&gt;</code> → <code>*node</code></li>
<li>→ <code>Box&lt;Node&lt;T&gt;&gt;</code> → <code>**node</code></li>
<li>→ <code>Node&lt;T&gt;</code> → <code>&amp;**node</code></li>
<li>→ <code>&amp;Node&lt;T&gt;</code>（至此型別才符合回傳值）</li>
</ul>
</li>
<li>在 <code>SinglyLinkedList</code> 上加 <code>iter()</code> 成員函式回傳 <code>Iter</code> 迭代器。</li>
<li>產生迭代器初始化狀態，和第三步一模一樣。</li>
</ol>
<p>最後，<code>IterMut</code> 與 <code>Iter</code> 迭代器實作上大同小異。把 <code>Iter</code> 用到 <code>Option.as_ref()</code> 改為 <code>Option.as_mut()</code>，其他 <code>&amp;</code> 改成 <code>&amp;mut</code> 即可。</p>
<a class="header" href="#partialeq-trait" id="partialeq-trait"><h3>PartialEq trait</h3></a>
<p><a href="https://doc.rust-lang.org/std/cmp/trait.PartialEq.html">PartialEq trait</a> 是用來實現兩個串列是否能夠比較，而我們在此定義如下：</p>
<p>有兩個 <code>SinglyLinkedList</code> Sa、Sb，Sa、Sb 的元素皆符合 <code>PartialEq</code> trait。當</p>
<ul>
<li>Sa 的總節點數 等於 Sb 的總節點數，</li>
<li>Sa 所有元素依序等於 Sb 所有元素，</li>
</ul>
<p>則稱 Sa 與 Sb 有 partial equiavalence（<code>Sa == Sb</code>）。</p>
<p>實作上我們用了 <code>iter</code> 成員函式把兩個串列 <code>zip</code> 在一起，在用 <code>all</code> 確認元素兩兩相等，十分 Rust 風格的作法。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T: PartialEq&gt; PartialEq for SinglyLinkedList&lt;T&gt; {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        if self.len() != other.len() {
            return false;
        }
        self.iter()
            .zip(other.iter())
            .all(|pair| pair.0 == pair.1)
    }
}
#}</code></pre></pre>
<a class="header" href="#debug-trait" id="debug-trait"><h3>Debug trait</h3></a>
<p>為了方便修復臭蟲，通常會實作 <a href="https://doc.rust-lang.org/std/fmt/trait.Debug.html">Debug trait</a> 印出有助於解決問題的資料。歸功於 <code>Iterator</code> 的實踐，我們可以快速用 <code>self.iter()</code> 印出所有節點內的元素，客製化 <code>Debug</code> 的顯示方式。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T: std::fmt::Debug&gt; std::fmt::Debug for SinglyLinkedList&lt;T&gt; {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter) -&gt; std::fmt::Result {
        for elem in self.iter() {
            write!(f, &quot;{:?} -&gt; &quot;, elem)?
        }
        Ok(())
    }
}
#}</code></pre></pre>
<a class="header" href="#a效能-15" id="a效能-15"><h2>效能</h2></a>
<table><thead><tr><th> Operation </th><th> Complexity                                      </th></tr></thead><tbody>
<tr><td> get       </td><td> $O(n)$                                      </td></tr>
<tr><td> insert    </td><td> 節點已知：$O(1)$ ；節點未知：$O(n - i)$ </td></tr>
<tr><td> remove    </td><td> 節點已知：$O(1)$ ；節點未知：$O(n - i)$ </td></tr>
<tr><td> append    </td><td> $O(n)$                                      </td></tr>
<tr><td> prepend   </td><td> $O(1)$                                      </td></tr>
<tr><td> pop first </td><td> $O(1)$                                      </td></tr>
<tr><td> pop last  </td><td> $O(n)$                                      </td></tr>
<tr><td> space     </td><td> $O(n)$ + 各節點額外一個指標 $n$ 個      </td></tr>
</tbody></table>
<blockquote>
<p>$n$：資料筆數。<br />
$i$：相對於整個容器的索引位置。</p>
</blockquote>
<p>值得觀察的是，許多操作因為單向鏈結串列只能從 head 開始搜索的緣故，執行時間都呈線性，使用上要特別注意。</p>
<a class="header" href="#a參考資料-21" id="a參考資料-21"><h2>參考資料</h2></a>
<ul>
<li><a href="https://doc.rust-lang.org/src/alloc/linked_list.rs.html">Rust Documentation: LinkedList</a></li>
<li><a href="http://cglab.ca/%7Eabeinges/blah/too-many-lists/book/README.html">Learning Rust With Entirely Too Many Linked Lists</a></li>
<li><a href="https://stackoverflow.com/questions/51134192/">Duscussions at Stackoverflow</a></li>
<li><a href="https://codereview.stackexchange.com/questions/150906">StackExchange: Reversal of a singly-linked list in Rust</a></li>
<li>SVG of node memory representation modified from <a href="https://doc.rust-lang.org/book/2018-edition">The Rust Programming Language</a></li>
</ul>
<a class="header" href="#a雙向鏈結串列-doubly-linked-list" id="a雙向鏈結串列-doubly-linked-list"><h1>雙向鏈結串列 Doubly linked list</h1></a>
<a class="header" href="#a操作" id="a操作"><h2>操作</h2></a>
<a class="header" href="#a效能-16" id="a效能-16"><h2>效能</h2></a>
<a class="header" href="#a循環鏈結串列-circular-linked-list" id="a循環鏈結串列-circular-linked-list"><h1>循環鏈結串列 Circular linked list</h1></a>
<a class="header" href="#a操作-1" id="a操作-1"><h2>操作</h2></a>
<a class="header" href="#a效能-17" id="a效能-17"><h2>效能</h2></a>
<a class="header" href="#a關聯容器-associative-container" id="a關聯容器-associative-container"><h1>關聯容器 Associative Container</h1></a>
<p>關聯容器是一種抽象資料型別，儲存鍵與值配對關係（key-value pair）的集合，並透過鍵存取元素，所謂「鍵值對」好比身份證字號與公民，戶政單位知道一個人證號，就可在關聯容器內，透過證號查找是否有這個公民，以及此證號對應的公民基本資訊。</p>
<p>關聯容器有許多別名，例如字典（dictionary）、關聯陣列（associative array）、映射（map）、表（table）等。在大多數程式語言函式庫中，關聯容器通常是最基本的容器型別之一，如 Python 的 <code>dict</code>，JavaScript 的 <code>Map</code>，以及 Rust 的 <code>HashMap</code>。</p>
<p>方便起見，本文以「<strong>映射表</strong>」統稱這類集合型別。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Hash_table_5_0_1_1_1_1_0_LL.svg/1280px-Hash_table_5_0_1_1_1_1_0_LL.svg.png" alt="" /></p>
<p><em>（雜湊表示意圖）</em></p>
<a class="header" href="#a特性-1" id="a特性-1"><h2>特性</h2></a>
<p>一般來說，映射表有以下特性：</p>
<ul>
<li><strong>鍵值對為單向關係</strong>：可透過鍵取得其唯一值；但無法確保一值僅對應唯一的鍵。</li>
<li><strong>鍵值唯一性</strong>：同個映射表內，同個鍵不重複，只會出現一次。</li>
<li><strong>元素組合性</strong>：映射表內每個元素都是「鍵值對」，鍵或值無法單獨存在。</li>
<li><strong>操作開銷小</strong>：合理實作下，基本操作開銷相對較小，不高於線性時間。</li>
</ul>
<blockquote>
<p>註：多重映射表為一對多的例外。</p>
</blockquote>
<p>映射表會有以下幾種基本操作：</p>
<ul>
<li><strong>新增</strong>：配對鍵值關聯，又稱為綁定 binding。</li>
<li><strong>修改</strong>：修改任意鍵之下的值。</li>
<li><strong>移除</strong>：透過任意鍵移除該鍵值對，又稱 unbinding。</li>
<li><strong>查找</strong>：透過任意鍵搜尋該鍵值對。</li>
</ul>
<p>不難看出，基本操作都是透過鍵取得值。事實上，合理實作的映射表，只要透過鍵來操作，就能有良好效能，甚至上述操作能達到 $O(1)$ 複雜度。</p>
<a class="header" href="#a適用場景-1" id="a適用場景-1"><h2>適用場景</h2></a>
<p>雖然映射表依實作不同，效能有所權衡。但其最大優勢仍是可「高效地透過鍵尋找值」，只要有映射關係的資料，都非常適合使用映射表。例如，快取暫存機制需透過特定鍵快速查找暫存值。此外，現代常用的 JSON、TOML 等資料交換格式，都是「鍵—值對」的形式，非常適合使用映射表處理。而應用映射表最有名的實際案例莫過於資料庫的索引，透過索引，我們可以大大降低搜尋的成本，從線性時間直落到對數甚至常數時間，不過相對就需要付出額外時空間建立索引。</p>
<p>我們再次把應用場景條列出來，方便懶人帶著走。</p>
<ul>
<li>有映射關係，處理「鍵—值」配對的資料結構。</li>
<li>處理 JSON、TOML 等資料交換，資料序列化。</li>
<li>實作快取（cache）機制。</li>
<li>資料庫索引的實作方法之一。</li>
<li>查找操作頻率遠高於其他操作時。</li>
</ul>
<p>總的來說，只要資料有對應綁定關係，就可以考慮使用映射表處理。</p>
<a class="header" href="#a種類-1" id="a種類-1"><h2>種類</h2></a>
<p>以下簡單介紹常見的映射表，詳情請點擊各連結。</p>
<a class="header" href="#a雜湊表-hash-map" id="a雜湊表-hash-map"><h3>雜湊表 Hash Map</h3></a>
<p><a href="../hash_map">雜湊表</a>是以雜湊函數實作的映射表。透過<a href="../../hash">雜湊函數</a>將任意資料轉換為固定長度的雜湊值，並將此鍵與一筆資料綁定，再映射到內部資料結構的某位置。理論上，只要雜湊函數品質過得去，雜湊表的基本操作都能在常數時間完成。</p>
<a class="header" href="#a有序映射表-ordered-map" id="a有序映射表-ordered-map"><h3>有序映射表 Ordered Map</h3></a>
<p><a href="../ordered_map">有序映射表</a>係一種有特定排序方式的映射表。常見兩種排序方式，其一是依照插入映射表的先後順序；其二則是依照鍵的大小。不同排序的底層資料結構各異，操作複雜度也不盡相同，如依鍵大小排序的映射表通常使用搜索樹實作，因此「新增」操作的複雜度為較差的 $O(\log n)$。</p>
<a class="header" href="#a多重映射表-multimap" id="a多重映射表-multimap"><h3>多重映射表 Multimap</h3></a>
<p><a href="../multimap">多重映射表</a>允許鍵值對重複，一個鍵可對應多個值（一對多）。類似於映射表內放入陣列，但能以較方便輕鬆的接口操作或迭代整張映射表。</p>
<a class="header" href="#a集合-set" id="a集合-set"><h3>集合 Set</h3></a>
<p><a href="set">集合</a>實際上並無鍵值「關聯」，可將其想像成普通的映射表。只關心鍵而值不重要。集合借用了數學<a href="https://en.wikipedia.org/wiki/Set_theory">集合論（set theory）</a>中有限集合的概念，常應用於需要操作交集、聯集、差集等集合運算場景。</p>
<a class="header" href="#a參考資料-22" id="a參考資料-22"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Associative_array">Wiki: Associative array</a></li>
<li><a href="https://en.wikipedia.org/wiki/Associative_containers">Wiki: Associative containers</a></li>
<li><a href="https://en.cppreference.com/w/cpp/container/map">cpprefernce.com: std::map</a></li>
<li><a href="https://doc.rust-lang.org/stable/std/collections/">Rust documentation: std::colledtion</a></li>
<li>Map graph by Jorge Stolfi <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a雜湊表-hash-map-1" id="a雜湊表-hash-map-1"><h1>雜湊表 Hash Map</h1></a>
<p>雜湊表是以雜湊函數實作的關聯容器。透過雜湊函數，計算鍵（key）對應到容器內部的索引位置，進而找到對應的值（value）。一般來說，雜湊表最常見的實作是以一個簡單陣列儲存資料。</p>
<p>雜湊表的優勢是：</p>
<ul>
<li>在資料量大時，仍然維持常數時間的高效能。</li>
<li>若資料數量上限已知，就可避免重新配置記憶體，效能更佳。</li>
<li>若資料形態已知，就可針對該資料形態找尋適合的雜湊函數最佳化。</li>
</ul>
<p>而雜湊表相對有以下短處：</p>
<ul>
<li>資料量不夠大時，單一操作需要雜湊計算，開銷相對高。</li>
<li>效能與雜湊函數息息相關，較差的函數容易雜湊碰撞，較佳函數計算成本通常較高。</li>
<li>只能以某種偽隨機的順序迭代雜湊表。</li>
</ul>
<a class="header" href="#a概念" id="a概念"><h2>概念</h2></a>
<p>建立雜湊表的第一步，就是配置一定大小的陣列（通常稱為 bucket array），來儲存對應索引的鍵值對。我們以建立電話簿為例，儲存人名與號碼的對應關係。</p>
<pre><code>Create an empty phone book with some blank slots.

          +--------------+
          | 0:           |
          +--------------+
          | 1:           |
          +--------------+
          | 2:           |
          +--------------+
          | 3:           |
          +--------------+
</code></pre>
<p>我們嘗試插入第一筆資料，記錄 Frodo 以及他的手機號碼 88-7-666。</p>
<ol>
<li>透過雜湊函數，計算出 Frodo 的索引值為 1。</li>
<li>將 88-7-666 插入 table[1] 的位置上。</li>
</ol>
<blockquote>
<p>table[1] 這種 bucket array 下的個別索引空間，通常稱為一個 slot 或 bucket。</p>
</blockquote>
<pre><code>Fordo: hash_function(Frodo) --&gt; 1

          +-------------+
          | 0:          |
          +-------------+
Frodo --&gt; | 1: 88-7-666 |
          +-------------+
          | 2:          |
          +-------------+
          | 3:          |
          +-------------+
</code></pre>
<p>嘗試插入另外二筆資料，記錄 Sam 的手機 11-2-333，以及 Gollum 的手機 00-0-000。</p>
<ol>
<li>透過雜湊函數，計算出 Sam 的索引值為 2。</li>
<li>將 11-2-333 插入 table[2] 的位置上。</li>
<li>透過雜湊函數，計算出 Gollumn 的索引值為 0。</li>
<li>將 00-0-000 插入 table[0] 的位置上。</li>
</ol>
<pre><code>Sam: hash_function(Sam) --&gt; 2

          +-------------+
          | 0:          |
          +-------------+
          | 1: 88-7-666 |
          +-------------+
Sam   --&gt; | 2: 11-2-333 |
          +-------------+
          | 3:          |
          +-------------+


Gollum: hash_function(Gollum) --&gt; 0

          +-------------+
Gollum -&gt; | 0: 00-0-000 |
          +-------------+
          | 1: 88-7-666 |
          +-------------+
          | 2: 11-2-333 |
          +-------------+
          | 3:          |
          +-------------+
</code></pre>
<p>若需要取得 Sam 的手機號碼，只要</p>
<ol>
<li>透過雜湊函數，計算出 Sam 的索引值為 2。</li>
<li>從 table[2] 的索引位置上，找到 Sam 的手機號碼</li>
</ol>
<pre><code>Sam: hash_function(Sam) --&gt; 2

          +-------------+
          | 0: 00-0-000 |
          +-------------+
          | 1: 88-7-666 |
          +-------------+
Sam   --&gt; | 2: 11-2-333 | --&gt; Sam's phone number
          +-------------+
          | 3:          |
          +-------------+
</code></pre>
<p>這就是最基本，以陣列實作的雜湊表了。</p>
<p>然而，你可能已經開始好奇了。</p>
<ul>
<li>雜湊是什麼？怎麼知道要映射到哪個索引位置？</li>
<li>雜湊函數是否會計算出相同的索引值？要如何解決？</li>
<li>若預先配置的陣列填滿了，該如何處理？</li>
</ul>
<p>接下來，將探討這幾個魔術般的因子，從簡單介紹雜湊函數，到如何解決雜湊碰撞，最後探討陣列塞滿重配置解決方案。</p>
<blockquote>
<p>註：雜湊表也可以搜尋樹等其他資料結構實作，在此不深入討論。</p>
</blockquote>
<a class="header" href="#a雜湊" id="a雜湊"><h3>雜湊</h3></a>
<p>所謂的雜湊函數，就是一種將「較寬的定義域映射到較窄值域」的函數。簡單來說，就是輸入任意值到此函數，則輸出值會落在一已知範圍。再白話一點，雜湊函數就是用來「化繁為簡」，把複雜多變的東西，透過函數生成簡化版本。此外，相同的輸入鍵，必須得到相同的輸出雜湊值，這是雜湊函數很重要的一個特性，以虛擬碼表示：</p>
<pre><code>key1 == key2 -&gt; hash(key1) == hash(key2)
</code></pre>
<p>「映射」這部分只是使用雜湊的一小步。雜湊表根據程式實作的不同，底層儲存資料的形式也不盡相同，為了完全放入陣列中，通常會對雜湊值（雜湊函數的計算結果）取模（modulo）。也就是說：假設有長度為 <em>n</em> 的陣列。1）先對 key 取雜湊值。2）再對雜湊值取模，確認索引值落在陣列內部。</p>
<pre><code>Assumed: array_size = n

hash_value = hash_function(key) // 1

index = hash_value % array_size // 2
</code></pre>
<p>如此一來，所有可能的值都會落在陣列內，這就是最簡單普遍的雜湊兩步驟：計算雜湊值﹢取模。</p>
<a class="header" href="#a選擇雜湊函數" id="a選擇雜湊函數"><h3>選擇雜湊函數</h3></a>
<p>接下來，你會緊接著向問第二個問題「函數計算出相同索引值該怎麼辦？」不同輸入產生相同雜湊值，多個值映射到同個索引上，這種狀況科學家稱之<strong>雜湊碰撞（hash collision）</strong>。</p>
<p>首先，要瞭解雜湊函數本身就是時空間的權衡，如果記憶體空間夠多，那讓輸入值與雜湊值呈一對一的完美關係，就不會出現碰撞；大多數情況，尤其是實作泛用的雜湊函式庫，無法預期輸入資料的範圍，實務上會鎖定一個輸出雜湊值的範圍，僧多粥少，難免碰撞。</p>
<p>好的雜湊函數還必須符合一些條件：</p>
<ol>
<li>同一筆輸入資料，必須得到相同的雜湊值。</li>
<li>結果必須能夠高效的計算出來（預期為常數時間）。</li>
<li>任意輸入資料所得之雜湊值在值域內需接近<a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">均勻分佈（uniform distribution）</a>，才能減少碰撞機率。</li>
</ol>
<p>但總歸一句，欲達成上述條件，就是一種權衡取捨，例如，<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function">加密雜湊函數（cryptographic hash function）</a>即是非常優秀的雜湊函數，但相對需付出更高的計算成本。</p>
<p>更多雜湊函數相關的討論，會另撰<a href="../../hash">專文</a>。</p>
<a class="header" href="#a處理雜湊碰撞" id="a處理雜湊碰撞"><h3>處理雜湊碰撞</h3></a>
<p>既然雜湊函數人生在世難免碰撞，科學家也研究幾個處理雜湊碰撞的策略，分別是 separate chaining 與 open addressing。</p>
<p><strong>Separate chaining</strong> 可以說是最直觀的做法，就是設法讓同一個索引下，可以儲存多個碰撞的值。依據儲存資料的形式，可分為幾種實作：</p>
<ul>
<li><strong>鏈結串列</strong>：以<a href="../linked_list">鏈結串列（linked list）</a>儲存元素。發生碰撞時，新的元素串接在既有元素之後。</li>
<li><strong>動態陣列</strong>：新增元素時，在該位址配置<a href="../dynamic_array">動態陣列（dynamic array）</a>儲存元素。發生碰撞時，直接將新元素加在陣列尾端。</li>
</ul>
<p>不同實作方式有各自優缺點，例如串列版本容易實作，但需額外儲存指標資訊；用動態陣列，則會有更好的 CPU caching，但相對地碰撞過多則需要重配置陣列。</p>
<p>以 ASCII 表述使用串列實作 separate chaining 示意圖如下：</p>
<pre><code>... assumed hash values of Gimli and Gollum collided.

                          +----------------+
                      +-&gt; |Gollum, 00-0-000| (linked list)
                      |   +----------------+
                      |            |
Gimli -+              |            v
       |              |   +---------------+
       |  +--------+  |   |Gimli, 99-9-999|
Gollum --&gt;|0: ptr  |--+   +---------------+
          +--------+
Frodo  --&gt;|1: ptr  |----&gt; +---------------+ 
          +--------+      |Frodo, 88-7-666|
Sam    --&gt;|2: ptr  |--+   +---------------+
          +--------+  |
          |3: null |  +-&gt; +---------------+
          +--------+      | Sam, 11-2-333 |
     (main bucket array)  +---------------+
</code></pre>
<p>而這邊也有精美的實作示意圖，將串列首個元素 head 直接放置在 slot 中的作法，減少一次指標操作。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Hash_table_5_0_1_1_1_1_0_LL.svg/1280px-Hash_table_5_0_1_1_1_1_0_LL.svg.png" alt="" /></p>
<p><em>(利用 separate chaining 實作的雜湊表，並將串列第一個元素放在 bucket array 中)</em></p>
<p>另一方面 <strong>Open addressing</strong> 則走完全不同的套路，不額外配置儲存空間給碰撞的元素，而是繼續在同個陣列內「探測」其他可用的 slot，再把資料塞進尚未被佔據的 slot 中。而 Open addressing 依據不同探測序列（probe sequence）有不同實作，常見的有：</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Linear_probing"><strong>Linear probing</strong></a>：從發生碰撞索引開始，依序往下一個 slot 探測是否可用，因此得名「線性」。</li>
<li><a href="https://en.wikipedia.org/wiki/Quadratic_probing"><strong>Quadratic probing</strong></a>：從碰撞索引開始，間隔以二次式增加往下探測可用 slot，如 $i + 1^2, i + 2^2, i + 3^2$。</li>
<li><a href="https://en.wikipedia.org/wiki/Double_hashing"><strong>Double hashing</strong></a>：以固定間隔大小 $k$（probe distance），依序探測 $i + k, i + k \cdot 2 ...$ 的 slot 是否為空。而這個間隔是以另外一個雜湊函數計算所得，因此得名「雙雜湊」。</li>
</ul>
<blockquote>
<p>$i$ 為發生碰撞的索引位置。</p>
</blockquote>
<p>這些方法的差異主要在於 CPU caching 的效能，以及 HashMap 資料的群聚效應（clustering）的敏感程度。當然，論 caching 絕對非 linear probing 莫屬，但 linear probing 以線性一個挨一個探勘，效能較容易受雜湊值群聚影響。</p>
<p>以下是 linear probing（間隔 = 1）的示意圖。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/HASHTB12.svg/1280px-HASHTB12.svg.png" alt="" /></p>
<a class="header" href="#a動態調整雜湊表大小" id="a動態調整雜湊表大小"><h3>動態調整雜湊表大小</h3></a>
<p>若資料的筆數已知，那初始配置的陣列大小設定與資料筆數成比例，就不必擔心雜湊表空間不夠，需要重新配置（reallocate）儲存空間的困擾。倘若資料量未知，而最初配置的 bucket array 滿了，該如何重新配置呢？</p>
<p>動態調整大小對雜湊表來說，不同於一般動態陣列，舊的雜湊表若要對應到新雜湊表，是每個鍵都需要重新計算雜湊值（rehash），成本相對較高。因此，減少動態調整的次數，可說是調教雜湊表的重點之一。說到調教雜湊表，必定要瞭解一個重要指標：<em>load factor</em>。</p>
<p>$$\text{load factor} = \frac{n}{k}$$</p>
<blockquote>
<p>$n$：已放入雜湊表內的資料總數。<br />
$k$：雜湊表配置的儲存空間（bucket 總數）。</p>
</blockquote>
<p>Load factor 代表目前雜湊表的「使用率」，若三筆資料放在四個 bucket 內，則 load factor 為 $3/4 = 75%$。Load factor 太大會更容易碰撞，會有效能上的影響；太小則代表過多冗餘空間沒有使用。如何維持 load factor 在一定範圍內至關重要。一般來說，75% 的 load factor 就可以準備重新配置雜湊表了，當然，這個門檻仍要以實作經驗為主，例如 Rust 的 <a href="https://doc.rust-lang.org/stable/std/collections/hash_map/index.html"><code>HashMap</code></a> 使用了 <a href="https://doc.rust-lang.org/stable/src/std/collections/hash/map.rs.html#82-103">Robin Hood Hashing</a>，將 load factor 調教到 90%。</p>
<p>重配置雜湊表與動態陣列的動態調整大小雷同，達到某個門檻值，就會將底層陣列大小翻倍。為了避免開銷過高，通常元素減少時，不會主動調整大小，而是提供一個 <code>shrink_to_fit</code> 一類的方法，讓呼叫端自行決定釋放多餘空間的時機。</p>
<a class="header" href="#a架構設計-1" id="a架構設計-1"><h2>架構設計</h2></a>
<p>在介紹架構設計之前，我們先來瞭解 Rust 雜湊相關的觀念與 trait。</p>
<a class="header" href="#hash-and-eq" id="hash-and-eq"><h3>Hash and Eq</h3></a>
<p>要實作雜湊函數，當然可以自幹計算雜湊值的函式來用，那為什麼還要使用 Rust 定義好的 <a href="https://doc.rust-lang.org/std/hash/trait.Hash.html"><code>Hash</code></a> 呢？當然是希望將雜湊的介面抽象化，只要型別宣告符合 <code>Hash</code> trait，任何人都可以輕鬆計算雜湊值。而實作 <a href="https://doc.rust-lang.org/std/hash/trait.Hash.html"><code>Hash</code></a> 很簡單，只要寫一個 <code>fn hash()</code>，呼叫端就能透過它計算雜湊，例如：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
use std::hash::{Hash, Hasher};

struct Car {
  brand: String,
}

impl Hash for Car {
    fn hash&lt;H: Hasher&gt;(&amp;self, state: &amp;mut H) {
        self.brand.hash(state);
    }
}
#}</code></pre></pre>
<p>光是計算雜湊值還不夠，要確定「當鍵相等時，其雜湊值也相等」這極為重要的雜湊特性，這時候除了實作 <code>Hash</code> trait，<code>Eq</code> trait 也要同時實作，該型別才能夠「被比較」，標準函式庫的 <code>HashMap</code> 的鍵就是實作 <code>Hash + Eq</code> 的型別，詳情請參閱 trait 的文件說明。</p>
<p>綜合以上，可以大膽定論，我們將實作的雜湊表的 key 一定符合 <code>K: Hash + Eq</code>，key 本身才能相互比較（實作 <code>Eq</code>），並開放呼叫端自定義型別實作不同的雜湊計算方式（實作 <code>Hash</code>）。</p>
<p>為了方便計算雜湊值，我們寫了一個輔助函式，以達成雜湊兩步驟：<strong>計算雜湊值﹢取模</strong>。其中，我們使用了 Rust 預設的雜湊演算法 <a href="https://doc.rust-lang.org/std/collections/hash_map/struct.DefaultHasher.html">DefaultHasher</a>，省下實作雜湊函數的功夫。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn make_hash&lt;X&gt;(x: &amp;X, len: usize) -&gt; usize
    where X: Hash + ?Sized,                   // 1
{
    let mut hasher = DefaultHasher::new();    // 2
    x.hash(&amp;mut hasher);
    hasher.finish() as usize % len
}
#}</code></pre></pre>
<ol>
<li><code>X</code> 泛型參數除了 <code>Hash</code>，還必須是 <a href="https://doc.rust-lang.org/book/2018-edition/ch19-04-advanced-types.html#dynamically-sized-types-and-the-sized-trait">Dynamically sized type</a>（DSTs，型別記作 <code>?Sized</code>）</li>
<li>Rust 的 hasher 是一狀態機，每餵他吃資料，<code>hasher.finish()</code> 產生的雜湊值就不同，為了確保雜湊相同，這裡每次呼叫就建立一個全新的 hasher。</li>
</ol>
<blockquote>
<p>所謂 <strong>Dynamically sized type</strong> 是指無法靜態得知大小的型別，例如 slice，或是一個函式的參數接受實作某個 trait 型別（<a href="https://doc.rust-lang.org/book/2018-edition/ch17-02-trait-objects.html">trait object</a>），而在 Rust 幾乎所有基礎型別預設都是 <code>Sized</code> 編譯期就可得知大小。而在這裡我們不關心知道實作該型別可否靜態決定大小，只需知道它是否實作 <code>Hash</code>，所以明確添加 <code>?Sized</code> 表示接受 DST。</p>
</blockquote>
<a class="header" href="#a記憶體佈局" id="a記憶體佈局"><h3>記憶體佈局</h3></a>
<p>我們嘗試建立可以儲存 key-value pair 的結構體，裡面配置一個 bucket array <code>buckets</code>。其中 <code>K</code> 泛型參數是準備計算雜湊的鍵，而 <code>V</code> 則是與鍵配對的資料。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct HashMap&lt;K, V&gt; where K: Hash + Eq {
    buckets: Vec&lt;(K, V)&gt;,
}
#}</code></pre></pre>
<p>可是，用單一 <code>Vec</code> 儲存所有資料，萬一雜湊碰撞，不同鍵指向同個索引值該如何？這次先挑選相對容易的方案 separate chaining 處理碰撞，並以 <code>Vec</code> 動態陣列作為每個 bucket 儲存碰撞元素的容器，因此，<code>buckets</code> 陣列裡面改存 <code>Bucket</code> 陣列，而 <code>Bucket</code> 則儲存真正的 key-value pair。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
type Bucket&lt;K, V&gt; = Vec&lt;(K, V)&gt;;              // 1

pub struct HashMap&lt;K, V&gt; where K: Hash + Eq {
   buckets: Vec&lt;Bucket&lt;K, V&gt;&gt;,                // 2
   len: usize,                                // 3
}
#}</code></pre></pre>
<ol>
<li>宣告 bucket 的型別 <code>Bucket</code>，實際上是一個 type alias 指向儲存鍵值 <code>(K, V)</code> 的動態陣列。</li>
<li>將 <code>HashMap.buckets</code> 改為儲存 <code>Bucket</code> 的動態陣列。</li>
<li>新增 <code>len</code> 記錄容器當前鍵值對數目，在增刪資料時， <code>len</code> 都會同步更新。</li>
</ol>
<p>之所以使用額外的成員記錄資料數目，是為了計算數目能在 O(1) 時間內完成，nested array 動態迭代每個 <code>Bucket</code> 計算的成本太高。</p>
<p>這就是 <strong>Vector-based separate chaining HashMap</strong> 的記憶體佈局，來看張精美的雜湊表架構佈局圖吧！</p>
<p><img src="layout.svg" alt="" /></p>
<a class="header" href="#a基本操作-1" id="a基本操作-1"><h2>基本操作</h2></a>
<p>雜湊表有以下幾個基本操作：</p>
<ul>
<li><code>new</code>：初始化一個空雜湊表。</li>
<li><code>with_capacity</code>：配置特定數量 bucket 的雜湊表。</li>
<li><code>get</code>：取得指定鍵對應的資料。</li>
<li><code>get_mut</code>：取得指定鍵對應的資料，並可寫入修改（mutable）。</li>
<li><code>insert</code>：在任意位置插入一組鍵值對。</li>
<li><code>remove</code>：移除任意位置下的鍵值對。</li>
<li><code>clear</code>：清除所有鍵值對。</li>
<li><code>is_empty</code>：檢查雜湊表是否沒有任何鍵值對。</li>
<li><code>len</code>：檢查目前鍵值對的數目。</li>
<li><code>bucket_count</code>：檢查目前 bucket 的數目。</li>
</ul>
<p>以及幾個內部方法：</p>
<ul>
<li><code>try_resize</code>：根據給定條件，決定調整 bucket 數目的時機，讓 load factor 維持最適狀態。</li>
<li><code>make_hash</code>：從輸入資料產生雜湊值，再模除 bucket 數，得到輸入資料對應的索引位置。</li>
</ul>
<p>接下來解釋實作的重點。</p>
<a class="header" href="#a初始化與預設值" id="a初始化與預設值"><h3>初始化與預設值</h3></a>
<p>雜湊表初始化相對容易，一樣慣例使用 <code>new</code>。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;K, V&gt; HashMap&lt;K, V&gt; where K: Hash + Eq {
    pub fn new() -&gt; Self {
        Default::default()
    }
    /// ...
}

impl&lt;K, V&gt; Default for HashMap&lt;K, V&gt; 
    where K: Hash + Eq 
{
    fn default() -&gt; Self { 
        Self { buckets: Vec::&lt;Bucket&lt;K, V&gt;&gt;::new(), len: 0 }
    }
}
#}</code></pre></pre>
<p>這裡為了符合人因工程，使用了 <a href="https://doc.rust-lang.org/std/default/trait.Default.html"><code>Default</code></a> trait 設定初始值。此外，由於 Rust 的容器型別慣例上沒有任何元素時，不會配置任何記憶體空間，僅有初始的 pointer。 HashMap 初始化後，記憶體空間僅需</p>
<ul>
<li><code>buckets</code> 的 <code>Vec</code> 佔據 3 個 usize 大小（一個 heap 指標，兩個記錄容量與長度的 usize。</li>
<li><code>len</code> 本身佔據 1 個 usize 大小。</li>
</ul>
<p>所以預設初始化的 HashMap 在 64bit machine 上佔 4 * usize = 32 bytes。</p>
<p>為了後續實作 resize 容易些，同時實作了指定 bucket 數目的建構式。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn with_capacity(cap: usize) -&gt; Self {
    let mut buckets: Vec&lt;Bucket&lt;K, V&gt;&gt; =  Vec::new();
    for _ in 0..cap {
        buckets.push(Bucket::new());
    }
    Self { buckets, len: 0 }
} 
#}</code></pre></pre>
<p>很清楚地，同樣建立一個空的 bucket array，再預先配置給定數量的 <code>Bucket</code> 。<code>len</code> 則因為沒有開始增加新值，而設定為 0。</p>
<a class="header" href="#a存取單一元素" id="a存取單一元素"><h3>存取單一元素</h3></a>
<p>存取元素的實作也非常直觀，</p>
<ol>
<li>使用 <code>make_hash</code> 計算出 key 對應的索引位置，</li>
<li>再透過 <code>Vec::get</code> 取得該索引下的 bucket，找不到時則返回 <code>None</code>，</li>
<li>找到 bucket 後則對整個 bucket 線性搜索與 key 相同的鍵值對。</li>
</ol>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn get(&amp;self, key: &amp;K) -&gt; Option&lt;&amp;V&gt; {
    let index = self.make_hash(key);
    self.buckets.get(index).and_then(|bucket|
        bucket.iter()
            .find(|(k, _)| *k == *key)
            .map(|(_, v)| v)
    )
}
#}</code></pre></pre>
<p>事實上，這個 <code>get</code> 不是非常方便使用，當我們透過 <code>HashMep::get</code> 搜尋特定鍵時，必須傳入一模一樣的型別，例如 <code>HashMap&lt;&amp;str, u8&gt;</code> 就只能透過相同的 borrowed value <code>&amp;str</code> 搜索，而不能透過 owned value <code>&amp;String</code> 尋找，就算兩個型別可無痛轉換也無法。</p>
<p>因此我們可以參考 Rust 標準函式庫為泛型參數 <code>K</code> 實作 <a href="https://doc.rust-lang.org/stable/std/borrow/trait.Borrow.html">Borrow</a> trait，抽象化 owned 與 borrowed 間的型別，讓呼叫端無論傳 owned 或 borrowed 型別都可以有相同的行為。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn get&lt;Q&gt;(&amp;self, q: &amp;Q) -&gt; Option&lt;&amp;V&gt;
    where
        K: Borrow&lt;Q&gt;,
        Q: Hash + Eq + ?Sized
{
    let index = self.make_hash(q);
    self.buckets.get(index).and_then(|bucket|
        bucket.iter()
            .find(|(k, _)| q == k.borrow())
            .map(|(_, v)| v)
    )
}
#}</code></pre></pre>
<blockquote>
<p><code>fn get_mut()</code> 與 <code>fn get()</code> 的差異只在於呼叫了 <code>self.bucket.get_mut</code> 取得 mutable reference，這裡就不多做說明。</p>
</blockquote>
<a class="header" href="#a插入與刪除元素" id="a插入與刪除元素"><h3>插入與刪除元素</h3></a>
<p>插入與刪除比較特別，需要做些額外的功夫：</p>
<ul>
<li>在操作完成之後需依據操作結果增減 <code>HashMap.len</code>，確保 <code>len</code> 永遠記錄正確的鍵值對數目。</li>
<li>在執行插入之前，需額外「動態調整」儲存空間，確保記憶體配置足夠空間新增元素。</li>
</ul>
<p>先來看看刪除怎麼實作。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn remove&lt;Q&gt;(&amp;mut self, q: &amp;Q) -&gt; Option&lt;V&gt;
    where
        K: Borrow&lt;Q&gt;,
        Q: Hash + Eq + ?Sized
{
    let index = self.make_hash(q);                      // 1
    self.buckets.get_mut(index).and_then(|bucket| {     // 2
        bucket.iter_mut()
            .position(|(k, _)| q == (*k).borrow())
            .map(|index| bucket.swap_remove(index).1)
    }).map(|v| {                                        // 3
        self.len -= 1; // Length decreases by one.
        v
    })
}
#}</code></pre></pre>
<ol>
<li>所有涉及搜尋的操作，第一步一定是計算雜湊值。</li>
<li>建立 mutable 的迭代器，利用 <a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.position"><code>posiion</code></a> 找到對應的鍵值對，再呼叫 <code>Vec::swap_remove</code> 移除。</li>
<li>前一步驟若有 return value 產生，表示移除一個元素，因此 <code>self.len</code> 需手動減一。</li>
</ol>
<blockquote>
<p><code>Vec::swap_remove</code> 不需要 resize array，而是取得最後一個元素填補該空間，由於雜湊表的排序不重要，我們選擇 <code>swap_remove</code> 減少一點開銷。</p>
</blockquote>
<p>而插入與移除非常相似。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn insert(&amp;mut self, key: K, value: V) -&gt; Option&lt;V&gt; {
    self.try_resize();                                      // 1
    let index = self.make_hash(&amp;key);                       // 2
    self.buckets.get_mut(index).and_then(|bucket|
        match bucket.iter_mut().find(|(k, _)| *k == key) {  // 3
            Some((_ , v)) =&gt;  Some(mem::replace(v, value)), // 3.1
            None =&gt; {                                       // 3.2
                bucket.push((key , value));
                None
            }
        }
    ).or_else(|| { //  Length increase by one.              // 4
        self.len += 1;
        None
    })
}
#}</code></pre></pre>
<ol>
<li>嘗試調整雜湊表大小，以確保 load factor 在閾值之間。</li>
<li>同樣地，根據鍵計算雜湊值，以取得對應的內部 bucket 位置。</li>
<li>迭代整個 bucket 尋找鍵相同的鍵值對。
<ol>
<li>若找到，使用 <a href="https://doc.rust-lang.org/stable/std/mem/fn.replace.html"><code>mem::replace</code></a> 取代資料部分，不需取代整個鍵值對。</li>
<li>若找無，則新增一組新鍵值對到該 bucket 中。</li>
</ol>
</li>
<li>決定是否該將長度記錄加一。若插入操作實際上是更新（update）原有鍵值對的資料，則會回傳被更新的舊資料 <code>Some((K, V))</code>；若是實際新增元素（push），我們回傳一個 <code>None</code>，<code>or_else</code> 就可以根據 <code>None</code> 判斷需要將長度加一。</li>
</ol>
<a class="header" href="#a動態調整儲存空間" id="a動態調整儲存空間"><h3>動態調整儲存空間</h3></a>
<p>動態調整儲存空間大概是整個實作中最詭譎的一部分。首先，我們需要知道</p>
<ul>
<li>容器內鍵值對的總數：透過 <code>self.len</code>，我們將取得 <code>self.len</code> 的邏輯包裝在 <code>fn len(&amp;self)</code>，以免未來長度移動至別處儲存計算。</li>
<li>容器內 bucket 的總數：計算 <code>self.bucket.len()</code>，同樣地，將之包裝在 <code>fn bucket_count(&amp;self)</code>，並開放給外界呼叫。</li>
<li>Load factor 閾值：記錄在 <code>const LOAD_FACTOR</code>，設定為 0.75。</li>
</ul>
<p>前情提要完畢，接下來就是程式碼的部分了。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn try_resize(&amp;mut self) {
    let entry_count = self.len();                               // 1
    let capacity = self.bucket_count();

    // Initialization.
    if capacity == 0 {                                          // 2
        self.buckets.push(Bucket::new());
        return
    }

    if entry_count as f64 / capacity as f64 &gt; LOAD_FACTOR {     // 3
        // Resize. Rehash. Reallocate!
        let mut new_map = Self::with_capacity(capacity &lt;&lt; 1);   // 4
        self.buckets.iter_mut()                                 // 5
            .flat_map(|bucket| mem::replace(bucket, vec![]))
            .for_each(|(k, v)| { new_map.insert(k, v); });
        *self = new_map;                                        // 6
    }
}
#}</code></pre></pre>
<ol>
<li>取得所有需要用到的長度資料。</li>
<li>若當前容量為 0，表示尚未新增任何元素，我們 push 一個空 bucket 進去，讓其他操作可以正常新增鍵值對。</li>
<li>判斷 load factor，決定需不需要動態調整大小。</li>
<li>透過 <code>HashMap::with_capacity</code> 建立容量兩倍大的空雜湊表。</li>
<li>開始迭代舊的 bucket，並利用 <a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.flat_map"><code>flat_map</code></a> 打平 nested vector，再利用 <a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.for_each"><code>for_each</code></a> 將每個元素重新 insert 到新雜湊表。</li>
<li>把 <code>self</code> 的值指向新雜湊表，舊雜湊表的記憶體空間會被釋放。</li>
</ol>
<a class="header" href="#a實作迭代器方法" id="a實作迭代器方法"><h3>實作迭代器方法</h3></a>
<p>一個集合型別當然少不了簡易的產生迭代器實作。</p>
<p>根據之前其他方法的實作，要迭代整個雜湊表非常簡單，就是迭代所有 bucket，並利用 <code>flat_map</code> 打平 nested vector。簡單實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn iter() -&gt; std::slice::Iter&lt;(&amp;k, &amp;v)&gt; {
    self.buckets.iter_mut()
        .flat_map(|b| b)
        .map(|(k, v)| (k, v))
}
#}</code></pre></pre>
<p>但最終會發現，我們的程式完全無法編譯，也無法理解這麼長的閉包（closure）究竟要如何寫泛型型別。得了吧 Rust，老子學不動了！</p>
<pre><code>error[E0308]: mismatched types
   --&gt; src/collections/hash_map/mod.rs:253:9
    |
253 | /         self.buckets.iter()
254 | |             .flat_map(|b| b)
255 | |             .map(|(k, v)| (k, v))
    | |_________________________________^ expected struct `std::slice::Iter`, found struct `std::iter::Map`
    |
    = note: expected type `std::slice::Iter&lt;'_, (&amp;K, &amp;V)&gt;`
               found type `std::iter::Map&lt;std::iter::FlatMap&lt;std::slice::Iter&lt;'_, std::vec::Vec&lt;(K, V)&gt;&gt;, &amp;std::vec::Vec&lt;(K, V)&gt;, [closure@src/collections/hash_map/mod.rs:254:23: 254:28]&gt;, [closure@src/collections/hash_map/mod.rs:255:18: 255:33]&gt;`
</code></pre>
<p>幸好，在 Rust 1.26 釋出時，大家期待已久的 <strong>impl trait</strong> 穩定了。如同字面上的意思，impl trait 可以用在函式參數與回傳型別的宣告中。代表這個型別有 impl 對應的 trait，所以不必再寫出落落長的 Iterator 泛型型別。impl trait 有另一個特點是以靜態分派（static dispatch）來呼叫函式，相較於 trait object 的<a href="https://en.wikipedia.org/wiki/Dynamic_dispatch">動態分派（dynamic dispatch）</a>，impl trait 毫無效能損失。</p>
<p>實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn iter(&amp;self) -&gt; impl Iterator&lt;Item = (&amp;K, &amp;V)&gt; {
    self.buckets.iter()
        .flat_map(|b| b)
        .map(|(k, v)| (k, v))
}
#}</code></pre></pre>
<p>更多 impl trait 相關資訊可以參考：</p>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md">Rust RFC: impl trait</a></li>
<li><a href="https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#impl-trait">Rust 1.26: impl trait</a></li>
<li><a href="https://doc.rust-lang.org/reference/types.html#trait-objects">Rust Reference: Trait objects</a></li>
<li><a href="https://doc.rust-lang.org/book/second-edition/ch17-02-trait-objects.html">The Rust Programming Language 2nd Edition: Trait objects</a></li>
</ul>
<a class="header" href="#a效能-18" id="a效能-18"><h2>效能</h2></a>
<p>以陣列實作的雜湊表各操作複雜度如下</p>
<table><thead><tr><th> Operation    </th><th> Best case    </th><th> Worst case </th></tr></thead><tbody>
<tr><td> add(k, v)    </td><td> $O(1)$~  </td><td> $O(n)$ </td></tr>
<tr><td> update(k, v) </td><td> $O(1)$   </td><td> $O(n)$ </td></tr>
<tr><td> remove(k)    </td><td> $O(1)$~  </td><td> $O(n)$ </td></tr>
<tr><td> search(k)    </td><td> $O(1)$   </td><td> $O(n)$ </td></tr>
</tbody></table>
<blockquote>
<p>$n$：資料筆數。<br />
$k$：欲綁定資料的鍵。<br />
$v$：欲與鍵綁定的資料。<br />
<strong>~</strong>：平攤後的複雜度（amortized）。</p>
</blockquote>
<a class="header" href="#a時間複雜度" id="a時間複雜度"><h3>時間複雜度</h3></a>
<p>在預期情況下，只要雜湊函數品質穩定，大部分操作都可達到在常數時間， 但由於部分操作，尤其是新增或刪除元素的操作，會需要調整 bucket array 的空間，重新配置記憶體空間，所以需要平攤計算複雜度。</p>
<p>而最差複雜度出現在每個元素都發生雜湊碰撞。若使用 open addressing 處理碰撞，則會把雜湊表配置的每個位置都填滿，而所有操作都從同個位置開始，搜尋對應的鍵，複雜度與陣列的線性搜索相同為 $O(n)$；若使用 separate chaining，碰撞代表所有元素都會在同一個 bucket 裡面，也就是只有一個 bucket 上會有一個長度為 <em>n</em> ，被塞滿的陣列或鏈結串列，結果同樣是線性搜索的 $O(n)$。</p>
<p>我們嘗試使用數學表示搜索的複雜度。另</p>
<ul>
<li>$n$：已放入雜湊表內的資料總數。</li>
<li>$k$：雜湊表配置的儲存空間（bucket 總數）。</li>
<li>$\text{load factor} = \frac{n}{k}$：預期每個 bucket 儲存的資料筆數。</li>
</ul>
<p>則預期執行時間為</p>
<p>$$\Theta(1+\frac{n}{k}) = O(1) \ \text{ if } \frac{n}{k} = O(1)$$</p>
<p>而 <strong>1</strong> 為計算雜湊與取得索引（random access）的執行時間，$\frac{n}{k}$ 則是搜尋陣列的執行時間。只要 load factor 越接近 $n$，執行時間就相對增加。</p>
<a class="header" href="#a空間複雜度" id="a空間複雜度"><h3>空間複雜度</h3></a>
<p>雜湊表的空間複雜度取決於實作預先配置的陣列大小，並與維持 <em>load factor</em> 息息相關。一般來說，仍與資料筆數成線性關係，因此空間複雜度只有資料本身 $O(n)$。而以 separate chaining 會額外配置陣列或鏈結串列儲存碰撞元素，理論上需負擔更多額外的指標儲存空間。</p>
<a class="header" href="#a參考資料-23" id="a參考資料-23"><h2>參考資料</h2></a>
<ul>
<li><a href="https://doc.rust-lang.org/stable/std/collections/hash_map/index.html">Rust Documentation: HashMap</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hash_table">Wiki: Hash table</a></li>
<li><a href="https://en.wikipedia.org/wiki/Open_addressing">Wiki: Open addressing</a></li>
<li><a href="https://algs4.cs.princeton.edu/34hash/">Algorithms, 4th Edition by R. Sedgewick and K. Wayne: 3.4 Hash Tables</a></li>
<li><a href="https://courses.csail.mit.edu/6.006/fall11/notes.shtml">MIT 6.006: Introduction to Algorithms, fall 2011: Unit 3 Hashing</a></li>
<li>Map graph by Jorge Stolfi <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a有序映射表-ordered-map-1" id="a有序映射表-ordered-map-1"><h1>有序映射表 Ordered Map</h1></a>
<p>有特定排序方式的映射表。</p>
<a class="header" href="#a多重映射表-multimap-1" id="a多重映射表-multimap-1"><h1>多重映射表 Multimap</h1></a>
<p>允許鍵值對重複，一個鍵可對應多個值（一對多）映射表。</p>
<a class="header" href="#a集合-set-1" id="a集合-set-1"><h1>集合 Set</h1></a>
<p>只有鍵沒有值的映射表。</p>
<a class="header" href="#a貢獻指南" id="a貢獻指南"><h1>貢獻指南</h1></a>
<p>感謝您有興趣貢獻 Rust 演算法俱樂部。我們歡迎各種形式的協助。這裡列出幾種任務供你挑選。</p>
<ul>
<li>增加新的演算法</li>
<li>修正已知的漏洞</li>
<li>改善文件的品質</li>
</ul>
<p>接下來，將介紹幾個貢獻的注意事項。</p>
<a class="header" href="#a開始貢獻之前" id="a開始貢獻之前"><h2>開始貢獻之前</h2></a>
<p>若您決定著手做些厲害的事，請先在<a href="https://github.com/weihanglo/rust-algorithm-club/search?q=&amp;type=Issues&amp;utf8=%E2%9C%93">已知 issues 與 pull requests</a> 搜尋，那裡可能已有回報相似的問題。</p>
<p>若沒有重複的問題，請發起一個「進行中（work-in-progress）」的 issue，告知其他人你正在做這項功能。你的時間很寶貴，必須防止重工發生。維護團隊也會追蹤這些 issue 以利管理俱樂部。</p>
<p>有些 meta issue 專門追蹤尚未完成的工作 🚧，可以去看看是否有感興趣的主題。</p>
<a class="header" href="#a提交你的成果" id="a提交你的成果"><h2>提交你的成果</h2></a>
<p>在提交你的貢獻之前，確認成果滿足下列需求：</p>
<ul>
<li>不要搞壞既有測試。發起 pull request 前執行 <code>cargo test</code>。新的演算法也需包含自身的單元測試。</li>
<li>每個對外接口都需要有文件。這個文件不需要完美無缺，但至少清楚說明它的目的與用法。</li>
<li>儘量維持文章間寫作風格與結構一致。例如：首段需包含簡扼的敘述、解釋效能時請愛用漸進符號。</li>
<li>程式碼撰寫風格應貼近 Rust 的慣例，例如：涉及所有權轉移請使用 <code>into</code>、替額外建構式命名請添加 <code>with</code> 前綴。目前為止，並不強制使用 <a href="https://github.com/rust-lang-nursery/rust-clippy">Clippy</a> 與 <a href="https://github.com/rust-lang-nursery/rustfmt">rustfmt</a>。</li>
</ul>
<a class="header" href="#a歡迎加入-rust-演算法俱樂部願演算法與你同在" id="a歡迎加入-rust-演算法俱樂部願演算法與你同在"><h3>歡迎加入 Rust 演算法俱樂部，願演算法與你同在！</h3></a>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        
        <script src="ace.js" type="text/javascript" charset="utf-8"></script>
        <script src="editor.js" type="text/javascript" charset="utf-8"></script>
        <script src="mode-rust.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-dawn.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-tomorrow_night.js" type="text/javascript" charset="utf-8"></script>
        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
